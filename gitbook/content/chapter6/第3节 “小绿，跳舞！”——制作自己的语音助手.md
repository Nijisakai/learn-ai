# 第3节 “小绿，跳舞！”——制作自己的语音助手

---

>通过深度学习的方式训练自己的声音模型，制作自己的语音助手，用语音来控制小绿的行动。

### 原理图

```sequence
麦克风阵列->树莓派: GPIO
树莓派-->小绿: WiFi
Note right of 树莓派: 处理麦克风语音数据\n如“前进”、“跳舞”
树莓派-->小绿: 发送处理结果
Note right of 小绿: 动作执行
树莓派-->小白: WiFi
Note right of 树莓派: 处理麦克风语音数据\n如“左转”、“停车”
树莓派-->小白: 发送处理结果
Note right of 小白: 动作执行
树莓派-->RGB彩灯: 使用MQTT传递指令\n“开灯”、“关灯”
```

### 硬件准备

#### 1.连接麦克风扩展板

通过对齐GPIO将扩展板固定在树莓派上

#### 2.连接扬声器

将扬声器通过3.5mm耳机线连接到麦克风扩展板

#### 3.设置基于ESP8266的RGB彩灯

使用基于WS2812的RGB彩灯，ESP8266通过MQTT（一种物联网轻量级通讯协议）与HomeAssistant通信
程序烧录过程略，程序源文件见`learn-ai\codes\chapter6\moon-lamp`
接通电源，使用杜邦线将彩灯的`Data`接到ESP8266的`D3`，`GND`和`VCC`分别接到对应位置

#### 4.通过HDMI或ssh或远程桌面连接到树莓派

### 参数配置

>参数配置时，可以使用命令行文本编辑工具**nano**或**vim**
>Nano：用法是`nano 文件名`。退出时候按`ctrl+w`，需要保存按`y`,否则按`n`，然后按回车。
>Vim：用法是`vi 文件名`。先按`insert`键，然后进行输入。要退出vi编辑器，按`esc`键，然后输入`:wq`，回车

#### 1.调用参数配置`~/rapiro/config.yaml`

```bash
# 在http://yuyin.baidu.com/注册语音识别应用，获取ak、sk和id
baidu_yuyin:
  api_key: 'qW5HLj4Ks6DfsCV2K9If5O80'
  secret_key: '37riCUCmGj1lfrhaGcyu11wWqCjvZbZR'
  app_id: '9217941'

homeassistant:
  url: 'http://localhost'
  port: '8123'
  password: 'welcome'

# 在http://www.turingapi.com/注册机器人，获取key
tuling:
  key: 'be4efe7298b24d0d8c9b5542dd56671a'
```

#### 2.机器人网络配置`~/rapiro/opiro.py`

```python
#!coding:utf-8
import os
import time
import requests
class rapiro:
    def __init__(self,ip):
#把双引号里的地址替换为小绿的ip地址
        self.ip = "http://192.168.123.184"
        self.actions = {
            "停止":'/otto-home',
            "小绿前进":'/otto-walk',
            "小绿后退":'/otto-walk-back',
            "小绿挥手":'/wave-hands',
            "小绿左转":'/otto-turn',
            "小绿右转":'/otto-turn-right',
            """
            适用于小白的命令
            "小白前进":'/get?command=forward'
            "小白后退":'/get?command=backward'
            """
            }
    def get(self,url):
        r = requests.get(self.ip+url)
        print(r.text)
    def do(self,action):
        method = self.actions.get(action,None)
        if(method):
            self.get(method)
            print("rapiro " + action)
    def isValid(self,text):
        for key in self.actions.keys():
            if(key in text):
                return key
        return None

if __name__ == '__main__':
    #把双引号里的地址替换为小绿的ip地址
    rap = rapiro('http://192.168.123.184')
    action = rap.isValid('前进')
    print(action)
    if action:
        rap.do(action)
        #rap.do("前进")
    time.sleep(4)
    rap.do("挥手")
    time.sleep(4)
    rap.do("停止")
```

#### 3.核心文件配置`~/rapiro/server.py`

```python
……
# 第84行 把引号里的地址替换为小绿的ip地址
rap = rapiro('http://192.168.123.184')
……
```

#### 4.关键词触发优化`~/rapiro/handle.py`

```python
#!coding:utf-8
from rapiro import *
rap = rapiro()
def handle(str):
# 仿照下一行的格式，补充更多的关键词，优化小绿的智力
# 如果语句命令中包含关键词，则将会识别为对应的机器人指令
    cmds = ["前进","后退","左转","右转","停止"]
    for cmd in cmds:
        if(cmd in str):
            rap.do(cmd)
            break
```

#### 5.声音设备配置`~/.asoundrc`

```bash
# 使用`aplay -l`和`arecord -l`查看wm8960soundcard对应的card和device号码。
# 例如，如果aplay对应的card和device分别是1和0，
# 则在playback.pcm处的双引号内填入`hw:1,0`，
# arecord则在capture.pcm处填写。

pcm.!default {
    type asym
    playback.pcm {
        type plug
        slave.pcm "hw:1,0"
    }

capture.pcm {
    type plug
    slave.pcm "hw:1,0"
    }
}
```

#### 6.语音助手设置`~/homeassistant/configuration.yaml`

```bash
……
……
……

conversation:
  intents:
    # 意图类型（名称），以及对应的语法匹配规则
    OpenLight:
      - 打开{item}灯
      - 把{item}灯打开
    CloseLight:
      - 关上{item}灯
      - 关闭{item}灯

intent_script:
  # 意图类型（名称）
  OpenLight:
    # speech返回
    speech:
      text: 已打开{{ item }}灯
    # 执行动作
    action:
      service: light.turn_on
      data_template:
        entity_id: >
          {% if item=="教室" %}
            light.classroom_light_rgb
          {% endif %}

  CloseLight:
    speech:
      text: 已关闭{{ item }}灯
    action:
      service: light.turn_off
      data_template:
        entity_id: >
          {% if item=="教室" %}
            light.classroom_light_rgb
          {% endif %}

mqtt:
  broker: 127.0.0.1
  port: 1883

light:
  - platform: mqtt
    name: "Classroom Light RGB"
    state_topic: "classroom/rgb1/light/status"
    command_topic: "classroom/rgb1/light/switch"
    brightness_state_topic: "classroom/rgb1/brightness/status"
    brightness_command_topic: "classroom/rgb1/brightness/set"
    rgb_state_topic: "classroom/rgb1/rgb/status"
    rgb_command_topic: "classroom/rgb1/rgb/set"
    state_value_template: "{{ value_json.state }}"
    brightness_value_template: "{{ value_json.brightness }}"
    rgb_value_template: "{{ value_json.rgb | join(',') }}"
    qos: 0
    payload_on: "ON"
    payload_off: "OFF"
    optimistic: false
```

### 训练自己的语音模型

>语音唤醒模型的训练是基于深度神经网络的训练。采用神经网络作为特征提取器，把声波信息转化为多维特征向量输入到深度神经网络（DNN）中，进行训练，得到模型。

![微信截图_20190827155220](https://md.hass.live/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190827155220.png)

**嘿，Siri！**
**OK，Google！**
**小爱同学！**
**小度小度！**

这些是主流的语音助手的唤醒词。小绿也有自己的唤醒词。
当我们呼唤他**小绿**的时候，他就会回应。这是因为已经提前训练好的识别文件`green.pmbl`

当然，我们可以训练自己独特的唤醒词。你想要叫他什么？叫什么都可以~只需要稍微的训练一下，得到一个识别文件就可以了。

#### 1.登陆网址[叫我的机器人什么好呢](https://snowboy.kitt.ai/)

你需要有一个GitHub账号，然后在右上角选择`Login with GitHub`

- 登陆后的界面：
![微信截图_20190827153711](https://md.hass.live/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190827153711.png)

#### 2.Create Hotword

![微信截图_20190827153845](https://md.hass.live/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190827153845.png)

#### 3.选择右下角的Record my voice

![微信截图_20190827154111](https://md.hass.live/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190827154111.png)

#### 4.录制3个样本后，点击右下角的按钮进行模型训练

![sssss](https://md.hass.live/sssss.png)

在左侧选择你的性别和年龄段，这是为了更加准确的调整模型。
然后在右侧说出唤醒词，通过调整灵敏度，逐渐调节到最优状态。然后点击`Save and download`

#### 5.将下载好的模型文件放在项目文件夹

可以命名为myrobot.pmbl

### 启动小绿的语音助手系统

```bash
//先启动HomeAssistant
sudo docker start home-assistant
//启动小绿
cd ~/rapiro
python server.py green.pmdl
//或者使用自己训练的myrobot.pmbl
//python server.py myrobot.pmbl
```

对着麦克风说`小绿`，听到提示音后，说出你的问题。

你可以说`今天的天气怎么样？`、`讲个笑话`、`小绿前进/后退/跳舞`、`小白前进/左转/停车`、`把灯打开/关闭`等。

试着用你的唤醒词来叫醒机器人吧
