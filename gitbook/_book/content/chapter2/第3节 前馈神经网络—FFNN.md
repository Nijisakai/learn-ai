# 第3节 前馈神经网络—FFNN

---

>前馈神经网络是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层，信息仅在一个方向上移动。是目前应用最广泛、发展最迅速的人工神经网络之一。研究从20世纪60年代开始，目前理论研究和实际应用达到了很高的水平。

### MNIST手写数字识别

一个基于MNIST训练的手写数字识别系统。**[点击这里](https://transcranial.github.io/keras-js/#/mnist-cnn)来体验。**

![MNISTWeb](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/MNISTWeb.webp)

在学习机器学习的时候，首要的任务的就是准备一份通用的数据集，方便与其他的算法进行比较。

MNIST数据集是一个手写数字数据集，每一张图片都是0到9中的单个数字，比如下面几个：

![MNISTSample](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/MNISTSample.webp)

MNIST数据库是一个大型数据库的手写数字是通常用于训练各种图像处理系统。该数据库还广泛用于机器学习领域的培训和测试。它是通过**重新混合**来自MNIST原始数据集的样本而创建的。

MNIST数据库包含60000个训练图像和10000个测试图像。训练集的一半和测试集的一半来自NIST的训练数据集，而训练集的另一半和测试集的另一半来自MNIST的测试数据集。

### 前馈神经网络解读

先来看这样一组数据：

|    序号     | 输入 x | 输出 y |
| :---------: | :----: | :----: |
|  第1条数据  |   4    |   36   |
|  第2条数据  |   9    |   81   |
|     ...     |  ...   |  ...   |
| 第n-1条数据 |   1    |   9    |
|  第n条数据  |   3    |   27   |
| 第n+1条数据 |   10   |   90   |

这只是我们随机编写的一些数字，它很简单，不使用任何模型算法，你也能轻而易举地找到 x-y 之间的规律：

```bash
输出y = 9 × 输入x
```

但是如果，我们一定要用神经网络来计算的话。那么，这个神经网络可以简单地搭建为：

![简单示例](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片1.webp)

我们以第一条数据输入4，输出36为例：

![第一条数据例子](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片2.webp)

- 输入层，让模型读入第 1 条数据 **4**
- 输出层，告诉模型其结果为 **36**
- 隐藏层，就像连接 **输入** 和 **输出** 之间的桥梁

这个模型的核心：就是努力找到 x 与 y 之间的联系。

比如，

![fig3](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片3.webp)

图中的 **1** 和 **9**，就是模型找到的其中一种连接方法。

更一般的，如果你拥有数据（X,Y），神经网络算法就会去寻找最佳的参数 W：

![fig4](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片4.webp)

求解 W，就是这条神经网络会替我们努力完成的工作。

上面的图，写成公式为：

![fig5](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片5.webp)

这就是一条最简单的神经网络。

当然，更多的时候，你在教材上看到的是这样的：

![fig6](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片6.webp)

如果我们将参数 b 暂时遮挡住：

![fig7](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片7.webp)

**公式二** 与 **公式一** 之间，仅仅多出一个 f () 函数。

这个 f () 函数，在学术上被称为 **激活函数**，通常是一个非线性的函数。例如：

![激活函数](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/activationFunction.jpg)

像上面这些，均可以作为激活函数来使用。你会问：**为什么我们要使用激活函数？**这是因为，(w\*X) 和 (w\*h) 仅仅是线性运算。而我们在现实中遇到的问题，更多都是非线性的。这就好比，家到学校，理论上是两点一线的距离；但现实中，你要曲曲弯弯走很多路，才能抵达终点。因而，在 w*X 的外面，包裹上一层激活函数，f(w\*X)。可以将线性问题转化为非线性问题，这样更接近真实的世界，也能使我们模型预测的准确度，得到大幅提升。

现在，如果我们把 n+1 条数据，全部考虑进来：

|    序号     | 输入 x | 输出 y |
| :---: | :---: | :---: |
|  第1条数据  |   4    |   36   |
|  第2条数据  |   9    |   81   |
|     ...     |  ...   |  ...   |
| 第n-1条数据 |   1    |   9    |
|  第n条数据  |   3    |   27   |
| 第n+1条数据 |   10   |   90   |

那么此时，神经网络的形态变为：

![fig8](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片8.webp)

由图可以看出，它是 n+1 条数据的 **堆叠**。你会发现，像这样的神经网络，它只有横向箭头，并没有纵向箭头。即 ****第n条数据，并不受之前数据的影响****。你可以视它为一条 **一直向前，永不回望** 的神经网络，也因此而得名 **前馈神经网络**。

我们单拎出第 n 条数据：

![fig9](http://pic-learn-ai.oss-cn-beijing.aliyuncs.com/幻灯片9.webp)

此时，hn 仅受 Xn 的影响。

在实际工作中，它适用于**上一条数据与下一条数据，彼此之间没有任何关联**的情形。
