{"./":{"url":"./","title":"关于本课程","keywords":"","body":"人工智能课程介绍 概述 本项目包含一个在线文档以及配套的教学材料（PPT、教案、学习单）。 包含6个有所关联、逐步递进的项目构成的章节。分别涉及物联网、机器人、机器视觉、语音识别和控制等内容。 包含背景知识学习、环境准备和资源下载部分。 本课程通过6个有所关联、逐步递进的章节，探究人工智能的基本原理，了解人工智能、机器学习基本概念，参与计算机视觉、语音技术等人工智能领域相关项目，利用人工智能解决学习和生活中的实际问题。 课程涉及人工智能基本概念、计算机视觉、语音技术、机器人等内容。通过一系列动手实验，制作小车和机器人，完成物体检测、自动追踪、无人驾驶、机器人姿态模仿、语音助手等项目。 课程包含详细的在线操作文档、配套代码、小车及机器人3D打印零件及全部硬件器材，学生无需自行准备任何设备，即可顺利完成全部项目。 完成课程学习后，将会对人工智能的基本概念有一定了解；对图像分类，目标检测，自然语言处理、语音识别等技术有直观体会；掌握开源硬件的基本操作，并通过开源硬件构建人工智能应用。 分章节介绍 第1章 基础知识 介绍： 第2章 人工智能体验 介绍： 通过本章内容，学生对人工智能的数学基础、概率论和博弈论、人工智能在图形图像和语言处理、电子游戏及其他领域的应用有感性认识。 使用在线的积木编程（google blockly/scratch）来控制 涉及软硬件： PC或树莓派（Raspberry Pi）或NVIDIA Jetson Nano 第3章 智能车“小白” 介绍： 主要使用ESP8266提供Web服务，来控制电机、舵机、传感器等，实现远程遥控、远程视频监控、巡线、避障、控制机械臂抓取等功能 可以通过积木编程的方式来对小车的功能进行编程 涉及软硬件： ESP8266，ESP32-CAM，小车套件（可3D打印），舵机，灰度传感器、超声波传感器等 自行开发的物联网控制平台，MIT App Inventor 第4章 自动追踪小车“大白” 介绍： 从机器视觉出发，让学生理解机器视觉的相关概念和原理，辨别OpenCV和深度学习的异同点。 使用OpenCV来处理视觉信号，并通过蓝牙或串口来将处理过的视觉信号发送给小车，从而实现物体追踪，人脸追踪，智能机械臂抓取等功能 学生通过使用Python，完成信息采集：爬虫、多文件处理；信息处理：训练采集的数据，形成分类器，从而让计算机视觉系统能够对特定的物体进行分辨 涉及软硬件： 树莓派、Arduino、舵机、USB摄像头、小车套件、3D打印机、电磁传感器、蓝牙接收器 OpenCV、Python 第5章 无人驾驶小车“老白” 介绍： 采用深度学习的方式，通过采集无人驾驶的数据，并进行训练，来实现无人驾驶的功能 涉及软硬件： 树莓派、摄像头、小车套件 Python 第6章 机器人“小绿” 介绍： 组装一个机器人，作为物联网的一个节点，实现多种物联网功能，包括网页遥控：通过自行开发的物联网平台来对它进行遥控；语音助手：可以通过自己训练的热词来进行唤醒、通过语音来控制机器人执行各种动作；控制其他设备：比如控制前几个章节的小车，读取各种传感器的数据等；人脸解锁：通过实时的人脸识别和红外线发射装置，实现人脸解锁，也可以通过Google Assistant、Siri、Alexa等远程控制；实时姿态模仿：通过单目摄像头拍摄实时画面，采用OpenPose姿态识别软件进行处理，将关节姿态数据通过蓝牙或串口传递给机器人，机器人进行实时的姿态模仿。 涉及软硬件： 树莓派、ESP8266、麦克风阵列、舵机、3D打印机、摄像头等 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-02-26 "},"content/chapter0/第0章简介.html":{"url":"content/chapter0/第0章简介.html","title":"开始之前","keywords":"","body":"开始之前 课程说明 课程的目标、大纲、时间地点、学分授予等的说明 课前读物 同学们在学习之前对计算机和人工智能的相关概念等应具有一定的了解 环境准备 详细说明了课程实施的全程中需要的软硬件环境配置 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-24 "},"content/chapter0/课程说明.html":{"url":"content/chapter0/课程说明.html","title":"课程说明","keywords":"","body":"课程说明 课程目标 了解计算机基本知识 了解人工智能、机器学习基本概念 体验人工智能在实际中的应用，会使用开源硬件解决实际问题 课程时间和开课形式 由于新冠肺炎造成的影响，本课程采用远程授课形式开展。开课时间是第9-16周。 北师大珠海校区：周三第7-8节。励教楼C407 北师大珠海分校：周四第5-6节。励教楼C407 远程授课采用Zoom直播形式。Zoom软件下载地址：https://cernet.zoom.com.cn/client/latest/ZoomInstaller.exe下载安装后，点击加入会议 然后输入会议号：2641642171，以及个人姓名，点击加入会议即可 通过网络浏览器打开直播地址，也会自动跳转到Zoom软件。 课程直播地址：https://cernet.zoom.com.cn/j/2641642171 课程大纲 章节 主题 时间分配 前导 课程综述 2课时 第1章 基础知识 2课时 第2章 人工智能体验 2课时 第3章 硬件基础 2课时 第4章 机器视觉 2课时 第5章 深度学习 2课时 第6章 综合进阶 2课时 尾声 小组汇报 2课时 预备要求 掌握计算机基本操作 对编程语言有简单的了解 少量内容需要一定的英文阅读能力 学分授予 本课程学分1分。 根据学生学习的总评成绩认定学分： 总评成绩超过60分给予课程学分，此外总评成绩在60-84分发放合格证书，总评成绩大于84分发放优秀证书。总评成绩的计算公式如下： 总评成绩 = 平时成绩 x 10% + 出勤 x 20% + 小组综合作业 x 70% 其中： 平时成绩：参照平时表现，按照比例计入总分； 出勤：按照出勤情况给予打分，全勤则为满分，按照比例计入总分； 小组综合作业：形式为综合创意，由完成和汇报情况打分，按照比例计入总分。 主讲教师 黄荣怀教授 北京师范大学教授，长江学者。主要从事智慧学习环境、人工智能与教育、教育技术、知识工程、技术支持的创新教学模式等领域研究。现任北京师范大学智慧学习研究院院长、互联网教育智能技术及应用国家工程实验室主任、联合国教科文组织国际农村教育研究与培训中心主任。目前担任国家教材委员会科学学科专家委员会委员、教育部教育信息化专家组成员、教育部人工智能科技创新专家组工作组专家、普通高中信息技术课标组联席组长、中国教育技术协会副会长、中国教育装备行业协会副会长、北京市教育信息化专家委员会副主任委员、全球华人计算机应用学会（GSECE）主席、国际智慧学习环境协会副主席、国际期刊 Smart Learning Environment（Springer出版）主编、国际期刊 Journal of Computers in Education（Springer出版）主编等。曾获国家精品课程、国家精品资源共享课、国家规划教材、国家教学成果奖、北京市优秀教学团队、北京市教学名师、北京市优秀教师等。承担国家、省部级等横向纵向课题100余项，现已发表学术论文近400篇，出版著作、杂志40余本。 朱立新高级工程师 朱立新博士，籍贯山东省临沂市沂南县, 中国科学院自动化所博士 & 美国密歇根州立大学（MSU, Michigan State University）Research Associate、博士后。曾任法国斯伦贝谢公司嵌入式软件工程师、美国科胜讯（Conexant）公司中国研发中心研发经理、美国英特尔（Intel）公司中国研发中心研发经理、美国微软公司移动部门系统软件首席架构师(Principle Architect)、美国超导加速器实验室（FRIB）控制部门助理研究员、中国和芯星通公司嵌入式软件研发负责人、网龙网络公司高级技术总监、爱奇艺智能硬件研发总监。目前担任北京师范大学互联网教育智能技术及应用国家工程实验室高级工程师，学习环境构建与测评实验室主任，主要负责人工智能与STEM的教育、中国教育机器人研发、AI与教育大数据的结合、智能教室、边缘计算与学习环境的研究和产业化等工作。兼任中国科学院高能物理研究所客座研究员，中国洪泰智造公司技术顾问。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-30 "},"content/chapter0/课前读物.html":{"url":"content/chapter0/课前读物.html","title":"课前读物","keywords":"","body":"课前读物 计算机概述 计算机的发展 第一代：真空管 ENICA ENICA（电子数值积分计算机，Electronic Numerical Integrator And Computer）是世界上第一台通用计算机。它是图灵完全的电子计算机，能够重新编程，解决各种计算问题。 ENIAC为美国陆军的弹道研究实验室（Ballistic Research Laboratory，BRL）所使用，用于计算火炮的外弹道。美国军方要求该实验室每天为陆军炮弹部队提供6张射表以便对导弹的研制进行技术鉴定。事实上每张射表都要计算几百条弹道，而每条弹道的数学模型是一组非常复杂的非线性方程组。这些方程组是没有办法求出准确解的，因此只能用数值方法近似地进行计算。按当时的计算工具，实验室即使雇用200多名计算员加班加点工作也大约需要二个多月的时间才能算完一张射表。 当时任职宾夕法尼亚大学莫尔电机工程学院的约翰・莫奇利（John Mauchly）和他的研究生约翰・埃卡特（John Eckert）提出了使用真空管制造电子计算机的设想。1934年，代号PX项目的计算机研制工作在宾夕法尼亚大学的电气工程摩尔商学院秘密展开。但由于ENICA使用真空管制作，使得ENICA计算机十分巨大，重达30吨，占地1500平方英尺，包含超过18000个真空管，在运行时需要消耗140千瓦的功率。同时它也比任何机电计算机快得多，每秒可以计算5000次加法运算。ENIAC可以在30秒内计算出人类计算20小时的导弹轨迹。 ENIAC于1946年完成，已无法用于战争。相反，它的首要任务是执行一系列复杂的计算，用于帮助确定氢弹的可行性。ENIAC用于其他目的之外的目的证明了其通用性。ENIAC继续在弹道研究实验室（BRL）管理下运营，直到1955年被拆解。 冯・诺伊曼结构 启动和改变ENIAC程序的任务非常繁琐。但是假设程序可以以适合与数据一起存储在存储器中的形式表示。然后，计算机可以通过从存储器中读取它们来获得其指令，并且可以通过设置一部分存储器的值来设置或改变程序。 这个被称为存储程序概念的想法通常归功于ENIAC设计师，最著名的是数学家冯・诺依曼（John von Neumann），他是ENIAC项目的顾问。阿兰・图灵（Alan Mathison Turing）几乎同时发明了这个想法。这个想法首次发表于冯・诺依曼在1945年提出的一种新计算机 EDVAC（电子离散可变计算机）的提案。 1946年，冯・诺伊曼和他的同事开始在普林斯顿高等研究院开设一种新的存储程序计算机，称为IAS计算机。IAS计算机虽然直到1952年才完成，但它是所有后续通用计算机的原型。 第二代：晶体管 电子计算机的第一个重大变化是用晶体管替换真空管。与真空管相比，晶体管更小，更便宜并且散热更少，但是可以以与真空管相同的方式用于构造计算机。与需要电线，金属板，玻璃胶囊和真空的真空管不同，晶体管是由硅制成的固态器件。 该晶体管于1947年在贝尔实验室被发明，并在20世纪50年代引发了电子革命。然而，直到20世纪50年代后期，完全晶体管化的计算机才被商业化。随后IBM推出了著名的7000系列计算机。 晶体管的使用定义了第二代计算机。基于所采用的基本硬件技术，将计算机分类为几代已被广泛接受。每一代新产品的特点是处理性能更高，内存容量更大，并且尺寸比前一代更小。 除此之外，第二代计算机在结构上也有了一些其他变化。第二代计算机引入了更复杂的算术和逻辑单元和控制单元，使用高级编程语言，以及与计算机一起提供系统软件。从广义上讲，系统软件提供了加载程序，将数据移动到外围设备和库以执行常见计算的能力，类似Windows和Linux等现代操作系统。 第二代也值得注意的是数字设备公司（DEC）的出现。DEC成立于 1957年，并在那一年交付了第一台计算机PDP-1。 第三代：集成电路 单个独立的晶体管称为分立元件。在20世纪50年代和60年代早期，电子设备主要由分立元件组成——晶体管，电阻器，电容器等。分立元件分别制造，封装在自己的容器中，焊接或连接在一起形成类似绝缘纤维板的电路板，然后安装在计算机、示波器和其他电子设备中。每当一个电子设备需要一个晶体管时，一个含有针头大小的硅片的小管子必须焊接到电路板上。从晶体管到电路板的整个制造过程既昂贵又麻烦。 早期的第二代计算机包含大约10000个晶体管。这个数字增长到数十万，使得制造更新，更强大的机器变得越来越困难。 1958年取得了革命性的电子技术并开创了微电子时代的成就：集成电路的发明。它是定义第三代计算机的集成电路。集成电路利用了诸如晶体管，电阻器和导体之类的部件可以由诸如硅的半导体制造的事实。它仅仅是固态技术的延伸，用于在一小块硅中制造整个电路，而不是将由单独的硅片制成的分立元件组装到同一电路中。许多晶体管可以在单个硅晶片上同时生产。同样重要的是，这些晶体管可以通过金属化工艺连接以形成电路。 最初，只有少数门或存储单元可以可靠地制造和封装在一起。这些早期的集成电路称为小规模集成电路（Small Scale Integration, SSI）。随着时间的推移，可以在同一芯片上打包越来越多的组件，晶体管的密度的增长如图所示。 这个数字也反映了1965年英特尔联合创始人戈登・摩尔（Gordon Moore）提出的着名的摩尔定律。摩尔观察到可以放在单个芯片上的晶体管数量每年翻倍并预测这种速度会继续到不久的将来。令包括摩尔在内的许多人惊讶的是，这种速度一年又一年，十年后持续不断。在 20世纪70年代，节奏减缓到每18个月翻一番，但此后一直保持这一速度。 摩尔定律 摩尔定律（Moore's law）是由英特尔创始人之一戈登・摩尔（Gordon Moore）提出的。其内容为：集成电路上可容纳的晶体管数目，约每隔两年便会增加一倍。经常被引用的18个月，是由英特尔首席执行官大卫・豪斯（David House）提出：预计18个月会将芯片的性能提高一倍（即更多的晶体管使其更快），是一种以倍数增长的观测。 尽管摩尔定律的现象已经被观察到了数十年，摩尔定律仍应该被视为是对现象的观测或对未来的推测，而不是一个物理定律或自然界的规律。从另一角度看，未来的增长率在逻辑上无法保证会跟过去的数据一样，也就是逻辑上无法保证摩尔定律会持续下去。虽然预计摩尔定律将持续到至少2020年，然而2010年国际半导体技术发展路线图的更新增长已经在2013年年底放缓；又比如说英特尔在22纳米跟14纳米的CPU制程上已经放慢了技术更新的脚步。 之后的几代 在第三代之后，关于定义几代计算机的一致意见较少。随着大规模集成（Large Scale Integration, LSI）的引入，可以在单个集成电路芯片上放置1000多个元件。超大规模集成（Very Large Scale Integration, VLSI）每个芯片实现了10000多个组件，而目前的超大规模集成（Ultra Large Scale Integration, ULSI）芯片可以包含超过10亿个组件。 半导体储存器 集成电路技术首次应用于计算机是集成电路芯片中处理器（控制单元和算术和逻辑单元）的构造，但人们也发现这种技术可用于构建储存器。 在20世纪50年代和60年代，大多数计算机存储器由铁磁材料的微小环构成，每个直径约为十六分之一英寸。这些环被悬挂在计算机内部小屏幕上的细线网格上。单向磁化，一个环（称为核心）代表1， 另一方向磁化，它代表0。 磁芯存储器相当快，读取存储在存储器中的一点只花了百万分之一秒，但它昂贵，笨重，并且使用了破坏性读数——读取核心的简单行为会删除存储在其中的数据。因此，需要安装额外的电路以便在提取数据后立即恢复数据。 然后，在1970年，仙童半导体（Fairchild）产生了第一个半导体存储器。这个芯片大小只有一个内核，可以容纳 256 位数据，访问速度比核心储存器快得多，只需要 700 亿分之一秒的读取时间。 1974年，发生了一个重大事件：半导体存储器的每比特价格降至核心存储器的每比特价格之下。在此之后，存储器成本持续快速下降，伴随着物理存储密度的相应增加。这导致了更小、更快的机器，其内存尺寸更大，更昂贵的机器从几年前开始。内存技术的发展以及接下来要讨论的处理器技术的发展，在不到十年的时间里改变了计算机的性质。虽然笨重，昂贵的计算机仍然是这一领域的一部分，但计算机也已经被用于办公机器和个人计算机的最终用户。 微处理器 正如存储器芯片上的元件密度持续上升一样，处理器芯片上的元件密度也在不断增加。随着时间的推移，越来越多的元件被放置在每个芯片上，因此构建单个计算机处理器所需的芯片越来越少。 1971年英特尔开发出4004时取得了突破性进展。4004是第一款在单芯片上集成CPU所有组件的芯片——微处理器诞生了。 1972年英特尔推出了8008处理器。这是第一个8位微处理器，性能几乎是4004的两倍。 1974年英特尔8080的推出。这是第一个通用微处理器，与4004和 8008是为特定应用而设计的不同，8080被设计成通用微型计算机的CPU。与8008一样，8080是一个8位微处理器。然而，8080更快，具有更丰富的指令集，并具有大的寻址能力。 同时16位微处理器的开发开始了。但是直到20世纪70年代末才出现了功能强大的通用16位微处理器，其中之一是8086。微处理器的下一次重大升级是发生在1981年，贝尔实验室和惠普公司都开发了32位单芯片微处理器。英特尔于1985年推出了自己的32位微处理器80386。 计算机的操作系统 操作系统是管理计算机硬件的程序，它还为应用程序提供基础，并且充当计算机硬件和计算机用户的中介。令人惊奇的是操作系统完成这些任务的方式多种多样。大型机的操作系统设计的主要目的是为了充分优化硬件的使用率，个人计算机的操作系统是为了能支持从复杂游戏到商业应用的各种事物，手持计算机的操作系统是为了给用户提供一个可以与计算机方便地交互并执行程序的环境。因此，有的操作系统设计是为了方便，有的设计是为了高效，而有的设计目标则是兼而有之。 操作系统做了什么 操作系统是几乎所有计算机系统的一个重要部分。计算机系统可以大致分为4个组成部分：计算机硬件、操作系统、系统程序与应用程序和用户。 硬件，如中央处理单元（Central Processing Unit，CPU）、内存（memory）输入输出设备（input/output devices，I/O devices），为系统提供基本的计算资源。应用程序如字处理程序、电子制表软件、编译器、网络浏览器规定了用户按何种方式使用这些资源。操作系统控制和协调各用户的应用程序对硬件的使用。 计算机系统的组成部分包括硬件、软件及数据。在计算机系统的操作过程中，操作系统提供了正确使用这些资源的方法。操作系统类似于政府。与政府一样，操作系统本身并不能实现任何有用的功能。它只不过提供了一个方便其他程序做有用工作的环境。 为了更加全面地理解操作系统所担当的角色，接下来从两个视角探索操作系统:即从用户的视角和系统的视角来讨论。 用户视角 计算机的用户观点因所使用接口的不同而异。绝大多数计算机用户坐在一台这样的PC前，PC由显示器、键盘、鼠标和主机组成。这类系统设计是为了让单个用户单独使用其资源，其目的是优化用户所进行的工作（或游戏）。对于这种情况，操作系统的设计目的是为了用户使用方便，性能是次要的，而且不在乎资源使用率——如何共享硬件和软件资源。性能对用户来说非常重要，而不是资源使用率，这种系统主要为了优化单用户的情况。 在某些情况下，有些用户坐在与大型机或小型机相连的终端前，其他用户通过其他的终端访问同一计算机。这些用户共享资源并可交换信息。操作系统设计为资源使用做了优化:确保所有的CPU时间、内存和I/O都能得到充分使用，并且确保没有用户使用超出其权限以外的资源。 在另一些情况下，其他用户坐在工作站前，工作站与其他工作站和服务器相连。这些用户不但可以使用专用的资源，而且可以使用共享资源，如网络和服务器及文件、计算和打印服务器。因此，这类操作系统的设计目的是个人使用性能和资源利用率的折中。 近来，各种手持计算机开始成为时尚。绝大多数这些设备为单个用户所独立使用。有的也通过有线或（更为常见）无线与网络相连。由于受电源、速度和接口所限，它们只能执行相对较少的远程操作。绝大多数这类操作系统的设计目的是为了方便个人使用，当然如何在有限的电池容量中发挥最大的效用也很重要。 有的计算机几乎没有或根本没有用户观点。例如，在家电和汽车中所使用的嵌入式计算机可能只有键盘，只能打开和关闭指示灯来显示状态，而且这些设备及其操作系统通常设计成无需用户干预就能自行运行。 系统视角 从计算机的角度来看，操作系统是与硬件最为密切的程序，可以将操作系统看作资源分配器。计算机系统可能有许多资源，用来解决CPU时间、内存空间、文件存储空间、I/O设备等问题。操作系统管理这些资源。面对许多甚至冲突的资源请求，操作系统必须决定如何为各个程序和用户分配资源以便计算机系统能有效而公平地运行。众所周知，资源分配对多用户访问主机或微型计算机特别重要。 操作系统的一个稍稍不同的观点是强调控制各种设备和用户程序的需要。操作系统是控制程序。控制程序管理用户程序的执行以防止计算机资源的错误使用或使用不当。它特别关注I/O设备的操作和控制。 计算机语言与程序设计 编程语言（英语：Programming Language），是用来定义计算机程序的形式语言。它是一种被标准化的交流技巧，用来向计算机发出指令。一种计算机语言让程序员能够准确地定义计算机所需要使用的数据，并精确地定义在不同情况下所应当采取的行动。 最早的编程语言是在计算机发明之前产生的，当时是用来控制提花织布机及自动演奏钢琴的动作。在计算机领域已发明了上千不同的编程语言，而且每年仍有新的编程语言诞生。很多编程语言需要用指令方式说明计算的程序，而有些编程语言则属于宣告式编程，说明需要的结果，而不说明如何计算。 编程语言的描述一般可以分为语法及语义。语法是说明编程语言中，哪些符号或文字的组合方式是正确的，语义则是对于编程的解释。有些语言是用规格文件定义，例如C语言的规格文件也是ISO标准中一部分，而其他语言（像Perl）有一份主要的编程语言实现文件，视为是参考实现。 历史 早期发展 非常早期的计算机，例如巨人计算机（Colossus），在没有存储程序的帮助下，通过修改其电路或设置物理控制组来编程。 稍后，程序可以用机器语言编写，程序员以硬件可以直接执行的数字形式写入每条指令。例如，在两个存储器位置添加值的指令可能包含3个数字：一个选择 “添加” 操作的 “操作码” 和两个存储器位置。这些程序以十进制或二进制形式从穿孔卡，纸带，磁带读取或在计算机前面板上的开关上切换。机器语言后来被称为第一代编程语言。 下一步是开发第二代编程语言或汇编语言，它们仍然与特定计算机的指令集架构密切相关。这些使得程序更具人性化，并使程序员免于繁琐且容易出错的地址计算。 第一代高级编程语言或第三代编程语言是在20世纪50年代编写的。为计算机设计的早期高级编程语言是Plankalkül，由康拉德・楚泽（Konrad Zuse）在1943年至1945年间为德国Z3计算机开发。然而，它直到 1998 年和 2000 年才编写完成。 约翰・莫奇利（John Mauchly）在1949年提出短代码编程语言（Short Code），是有史以来为电子计算机开发的第一批高级语言之一。与机器代码不同，短代码语句以可理解的形式表示数学表达式。但是，程序每次运行时都必须转换为机器代码，这使得该过程比运行等效的机器代码慢得多。 在曼彻斯特大学，艾里克・格伦尼（Alick Glennie）在20世纪50年代初开发了Autocode。它使用编译器自动将语言转换为机器代码。第一个代码和编译器是在 1952 年为曼彻斯特大学的Mark 1计算机开发的，被认为是第一个编译的高级编程语言。 第二个Autocode是由托尼・布鲁克（RA Brooker）于1954 年为Mark 1开发的，被称为Mark 1 Autocode。布鲁克还在20世纪50年代与曼彻斯特大学合作开发了Ferranti Mercury（一种计算机）的自动编码。这种语言的EDSAC计算机版本在1961年被剑桥大学数学实验室的哈特利（David Hartley）设计，被称为EDSAC 2 Autocade。它是从Mercury Autocode的基础上根据新机器的需求修改而来，可以指出其目标代码的优化和源语言当时推进的诊断。 1954 年，FORTRAN语言由布鲁克（John Backus）在IBM发明。它是第一个广泛使用的高级通用编程语言，具有功能实现，而不仅仅是纸上设计。它仍然是高性能计算的流行语言，用于对世界上最快的超级计算机进行基准测试和排名的程序。 另一种早期编程语言是由格蕾丝・赫柏（Grace Hopper）在美国设计的，名为FLOW-MATIC。它是最初是在1955年至1959年期间由雷明顿兰德公司（Remington Rand）为UNIVAC I计算机开发的。赫柏发现商业数据处理客户对数学符号感到不舒服，并且在 1955 年初，她和她的团队编写了英语编程语言规范并实施原型。FLOW-MATIC编译器于1958年初公开上市，并于1959年基本完成。 细化 越来越多的高级语言的使用引入了对低级编程语言或系统编程语言的要求。这些语言在不同程度上提供汇编语言和高级语言之间的便利，它们可用于执行需要直接访问硬件设施但仍提供更高级别控制结构和错误检查的任务。 从20世纪60年代到70年代末期，现在使用的主要语言范式得到了发展： APL，引入了阵列编程并影响了函数式编程。 ALGOL，完善了结构化程序编程和语言规范学科；《ALGOL 60算法语言修订报告（Revised Report on the Algorithmic Language ALGOL 60）》成为后来编写语言规范的模型。 Lisp，于 1958 年实现，是第一个动态类型的函数式编程语言。 在 20 世纪 60 年代，Simula是第一种支持面向对象编程的语言 ; 在 20 世纪 70 年代中期，Smalltalk采用了第一种 “纯粹的” 面向对象语言。 C是在 1969 年和 1973 年之间开发的，作为Unix操作系统的系统编程语言，并且仍然很受欢迎。 Prolog，设计于 1972 年，是第一个逻辑编程语言。 1978 年，ML语言在Lisp之上构建了一个多态类型系统，开创了静态类型的 函数式编程语言。 这些语言中的每一种都产生了后代，大多数现代编程语言至少在其祖先中至少有一种。 20世纪60年代和70年代也对结构化编程的优点进行了大量辩论，以及编程语言是否应该被设计为支持它。艾兹赫尔・戴克斯特拉（Edsger Dijkstra）在1968年出版的《ACM通讯》中发表的着名论文中指出，应该从所有更高级别的编程语言中删除GOTO语句。 整合和增长 20世纪80年代是相对稳定的年代。C++结合了面向对象和系统编程。美国政府对Ada语言进行了标准化，Ada是一种源自Pascal的系统编程语言，旨在供国防承包商使用。日本和其他地方花费了大量资金来研究所谓的“第五代” 语言，这些语言包含了逻辑编程结构。所有这些研究与运动都没有发明新范式，而是阐述了前几十年发明的思想。 在20世纪80年代，用于编程大规模系统的语言设计的一个重要趋势是更多地关注模块或大规模组织代码单元的使用。Modula-2、Ada和ML都是在20世纪80年代开发的著名模块系统，它们通常与通用编程结构相结合。 20世纪90年代中期互联网的快速发展为新语言创造了机会。Perl语言最初是1987年首次发布的Unix脚本工具，在动态网站中很常见。Java开始用于服务器端编程，字节码虚拟机在商业环境中再次流行，承诺一次编写，随处运行（UCSD Pascal在 20 世纪 80 年代早期流行一段时间）。这些发展并不是根本新颖的，而是对许多现有语言和范例的改进（尽管它们的语法通常基于C系列编程语言）。 在工业和研究领域，编程语言的演变仍在继续。当前的方向包括安全性和可靠性验证，新型模块化和数据库集成，如Microsoft的LINQ。 第四代编程语言是计算机编程语言，旨在提供比第三代更高级别的内部计算机硬件细节抽象。第五代编程语言是基于使用给予程序的约束来解决问题的编程语言，而不是使用程序员编写的算法。 语言分类 机器语言 用机器语言编写程序，编程人员要首先熟记所用计算机的全部指令代码和代码的涵义。手编程序时，程序员得自己处理每条指令和每一数据的存储分配和输入输出，还得记住编程过程中每步所使用的工作单元处在何种状态。这是一件十分繁琐的工作，编写程序花费的时间往往是实际运行时间的几十倍或几百倍。而且，编出的程序全是些 0 和 1 的指令代码。直观性差，还容易出错。除了计算机生产厂家的专业人员外，绝大多数程序员已经不再去学习机器语言了。 汇编语言 为了克服机器语言难读、难编、难记和易出错的缺点，人们就用与代码指令实际含义相近的英文缩写词、字母和数字等符号来取代指令代码（如用 ADD 表示运算符号 “+” 的机器代码），于是就产生了汇编语言。所以说，汇编语言是一种用助记符表示的仍然面向机器的计算机语言。汇编语言亦称符号语言。汇编语言由于是采用了助记符号来编写程序，比用机器语言的二进制代码编程要方便些，在一定程度上简化了编程过程。汇编语言的特点是用符号代替了机器指令代码。而且助记符与指令代码一一对应，基本保留了机器语言的灵活性。使用汇编语言能面向机器并较好地发挥机器的特性，得到质量较高的程序。 汇编语言中由于使用了助记符号，用汇编语言编制的程序送入计算机，计算机不能象用机器语言编写的程序一样直接识别和执行，必须通过预先放入计算机的 “汇编程序 “的加工和翻译，才能变成能够被计算机识别和处理的二进制代码程序。用汇编语言等非机器语言书写好的符号程序称源程序，运行时汇编程序要将源程序翻译成目标程序。目标程序是机器语言程序，它一经被安置在内存的预定位置上，就能被计算机的 CPU 处理和执行。 汇编语言像机器指令一样，是硬件操作的控制信息，因而仍然是面向机器的语言，使用起来还是比较繁琐费时，通用性也差。汇编语言是低级语言。但是，汇编语言用来编制系统软件和过程控制软件，其目标程序占用内存空间少，运行速度快，有着高级语言不可替代的用途。 高级语言 不论是机器语言还是汇编语言都是面向硬件的具体操作的，语言对机器的过分依赖，要求使用者必须对硬件结构及其工作原理都十分熟悉，这对非计算机专业人员是难以做到的，对于计算机的推广应用是不利的。计算机事业的发展，促使人们去寻求一些与人类自然语言相接近且能为计算机所接受的语意确定、规则明确、自然直观和通用易学的计算机语言。这种与自然语言相近并为计算机所接受和执行的计算机语言称高级语言。高级语言是面向用户的语言。无论何种机型的计算机，只要配备上相应的高级语言的编译或解释程序，则用该高级语言编写的程序就可以通用。 如今被广泛使用的高级语言有Java、Python、C、JavaScript等。这些语言都是属于系统软件。 计算机并不能直接地接受和执行用高级语言编写的源程序，源程序在输入计算机时，通过 “翻译程序” 翻译成机器语言形式的目标程序，计算机才能识别和执行。这种 “翻译” 通常有两种方式，即编译方式和解释方式。编译方式是：事先编好一个称为编译程序的机器语言程序，作为系统软件存放在计算机内，当用户由高级语言编写的源程序输入计算机后，编译程序便把源程序整个地翻译成用机器语言表示的与之等价的目标程序，然后计算机再执行该目标程序，以完成源程序要处理的运算并取得结果。解释方式是：源程序进入计算机时，解释程序边扫描边解释作逐句输入逐句翻译，计算机一句句执行，并不产生目标程序。PASCAL、 FORTRAN、COBOL 等高级语言执行编译方式； BASIC 语言则以执行解释方式为主；而 PASCAL、C 语言是能书写编译程序的高级程序设计语言。每一种高级（程序设计）语言，都有自己人为规定的专用符号、英文单词、语法规则和语句结构（书写格式）。高级语言与自然语言（英语）更接近，而与硬件功能相分离（彻底脱离了具体的指令系统），便于广大用户掌握和使用。高级语言的通用性强，兼容性好，便于移植。 人工智能概述 人工智能是计算机科学的一个分支，她企图了解智能的实质，并产生一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统。 人工智能的发展 谈到人工智能，就不能不提到鼻祖式人物：图灵。1936年，英国数学家、逻辑学家阿兰・麦席森・图灵（1912~1954）提出了一种抽象的计算模型——图灵机(Turing Machine），用纸带式机器来模拟人们进行数学运算的过程，图灵本人被视为计算机科学之父。 1959年，图灵发表了一篇划时代的论文《计算机器与智能》，文中提出了人工智能领域著名的图灵测试——如果电脑能在5分钟内回答由人类测试者提出的一系列问题，且其超过30%的回答让测试者误认为是人类所答，则电脑就通过测试并可下结论为机器具有智能。 图灵测试的概念极大影响人工智能对于功能的定义，在这个途径上，卡内基・梅隆大学两位科学家纽厄尔（A.Newell）和西蒙（H.Simon）的“逻辑理论家”程序非常精妙地证明了罗素《数学原理》52道中的38道。西蒙宣称在10年之内，机器就可以达到和人类智能一样的高度。 第一批人工智能探索者找到共同的语言后，于整整60年前的1956年，在美国达特茅斯大学开了一次会，希望确立人工智能作为一门科学的任务和完整路径。与会者们也宣称，人工智能的特征都可以被精准描述，精准描述后就可以用机器来模拟和实现。后来普遍认为，达特茅斯会议标志着人工智能的正式诞生。 达特茅斯会议推动了全球第一次人工智能浪潮的出现，即为1956年到1974年。当时乐观的气氛弥漫着整个学界，在算法方面出现了很多世界级的发明，其中包括一种叫做增强学习的雏形（即贝尔曼公式）现在常听到的深度学习模型，其雏形叫做感知器，也是在那几年间发明的。除了算法和方法论有了新的进展，在第一次浪潮中，科学家们还造出了聪明的机器。 人工智能第一次浪潮和寒冬 在80年代出现了人工智能数学模型方面的重大发明，其中包括著名的多层神经网络（1986）和BP反向传播算法（1986）等，也出现了能与人类下象棋的高度智能机器（1989）。 但在1974至1980年人工智能进入冬天，因为人们发现逻辑证明器、感知器、增强学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。这里面存在两方面局限：一方面，人工智能所基于的数学模型和数学手段被发现有一定的缺陷；另一方面，有很多计算复杂度以指数程度增加，所以成为了不可能完成的计算任务。 现代PC“促成”第二次人工智能寒冬 然而，1987年到1993年现代PC的出现，让人工智能的寒冬再次降临。相比于现代PC，专家系统被认为古老陈旧而非常难以维护。于是，政府经费开始下降，寒冬又一次来临。 现代AI 的发展 现代AI的曙光发生在这个阶段，出现了新的数学工具、新的理论和摩尔定律。人工智能也在确定自己的方向，其中一个选择就是要做实用性、功能性的人工智能，这导致了一个新的人工智能路径。由于对于人工智能任务的明确和简化，带来了新的繁荣。 在新的数学工具方面，原来已经存在于数学或者其他学科的文献中的数学模型，被重新发掘或者发明出来。当时比较显著几个成果包括最近获得图灵奖的图模型以及图优化、深度学习网络等，都是大约在15年前重新被提出来，重新开始研究。 在新的理论方面，由于数学模型对自然世界的简化，有着非常明确的数理逻辑，使得理论分析和证明成为可能，可以分析出到底需要多少数据量和计算量来以得期望的结果，这对开发相应的计算系统非常有帮助。 在更重要的一方面，摩尔定律让计算越来越强大，而强大计算机很少被用在人工智能早期研究中，因为早期的人工智能研究更多被定义为数学和算法研究。当更强大的计算能力被转移到人工智能研究后，显著提高了人工智能的研究效果。 由于这一系列的突破，人工智能又产生了一个新的繁荣期。 人工智能商业化浪潮 2016年IBM在全球范围内倾全力推出的认知商业，才是真正意义上的人工智能商业化第一波浪潮。在深蓝成功后，IBM研究院进而挑战人工智能的深度问答，这是人工智能的一个重要分支，具有极为广阔的应用空间。 人工智能的关键技术 人机交互 关于人机交互，它最重要的方面研究人和计算机之间的信息交换，主要包括人到计算机和计算机到人的两部分信息交换，是人工智能领域的重要的外围技术。人机交互是与认知心理学、人机工程学、多媒体技术、虚拟现实技术等密切相关的综合学科。传统的人与计算机之间的信息交换主要依靠交互设备进行，主要包括键盘、鼠标、操纵杆、数据服装、眼动跟踪器、位置跟踪器、数据手套、压力笔等输入设备，以及打印机、绘图仪、显示器、头盔式显示器、音箱等输出设备。人机交互技术除了传统的基本交互和图形交互外，还包括语音交互、情感交互、体感交互及脑机交互等技术。 云计算与大数据 关于大数据和云计算的关系人们通常会有误解。而且也会把他们混起来说，分别做一句话解释就是：云计算就是硬件资源的虚拟化；大数据就是海量数据的高效处理。另外，如果做一个更形象的解释，云计算相当于我们的计算机和操作系统，将大量的硬件资源虚拟化之后再进行分配使用。 就目前而言，要想发展好大数据，就离不开云计算，我们在进行大数据的时候同样也是离不开云计算的，于是很多人觉得大数据与云计算都有一定的关系，那么大家知道不知道大数据的云计算有什么关系呢？我们在这篇文章中给大家带来这个问题的答案。 首先我们说一下大数据的定义吧，大数据就是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。同样也是一种规模大到在获取、存储、管理、分析方面大大超出了传统数据库软件工具能力范围的数据集合，具有海量的数据规模、快速的数据流转、多样的数据类型和价值密度低四大特征。 那么大数据的技术有什么意义呢？大数据的意义并不是在于掌握庞大的数据信息，而在于对这些含有意义的数据进行专业化处理。换而言之，如果把大数据比作一种产业，那么这种产业实现盈利的关键，在于提高对数据的优化能力，通过优化实现数据的增值。 而大数据与云计算的关系在技术上的联系也是密不可分。大数据必然无法用单台的计算机进行处理，必须采用分布式架构。它的特色在于对海量数据进行分布式数据挖掘。但它必须依托云计算的分布式处理、分布式数据库和云存储、虚拟化技术。随着云时代的来临，大数据也吸引了越来越多的关注。分析师团队认为，大数据通常用来形容一个公司创造的大量非结构化数据和半结构化数据，这些数据在下载到关系型数据库用于分析时会花费很多的财力和物力。大数据分析常和云计算联系到一起，因为实时的大型数据集分析需要框架来向数十、数百或甚至数千的电脑分配工作。并且，大数据需要特殊的技术，以有效地处理大量的容忍经过时间内的数据。适用于大数据的技术，包括大规模并行处理数据库、数据挖掘、分布式文件系统、分布式数据库、云计算平台、互联网和可扩展的存储系统。 知识图谱 知识图谱属于AI领域的是一个分支，很多人觉得它和CV（Computer Vision，计算机视觉），ASR（Automatic Speech Recognition，语音识别），以及NLP（Natural Language Processing，自然语言处理）一样都是特指的某一项技术，其实这么理解并不准确，它应该算是多种技术融合后的一种综合型技术。 知识图谱的历史最早要追溯到2012年，由Google公司提出主要用于提升搜索引擎的检索效率，但随着其发展其背后更深刻意义，远不仅是提高检索效率这么简单，而是整个搜索引擎结构的整体转型：将传统基于关键字的搜索模型转向基于语义的搜索升级。 如今针对知识图谱的技术方案已被国内外多家搜索引擎公司所采用，如：美国的微软必应，中国的百度、搜狗等，都在在短短的一年内纷纷宣布了各自的知识图谱产品，足以看出这革新对整个搜索引擎界的整体影响。 但现在这项技术的应用并不仅拘泥于搜索引擎领域范围，很多的数据分析软件，CRM系统（Customer Relationship Management System，客户关系管理系统）也开始采用基于知识图谱的模式去处理数据，从而去深入发现数据更大的价值。 知识图谱从字面上看，可以拆分为知识+图谱，这样我们就可以理解：将需要的知识数据（结构化或非结构化数据）以图谱的形式进行展示，这种简单的过程也是知识图谱的构建过程。 知识图谱为互联网上海量、异构、动态的大数据表达、组织、管理以及利用提供了一种更为有效的方式，使得网络的智能化水平更高，更加接近于人类的认知思维。 目前，知识图谱已在智能搜索、深度问答、社交网络以及一些垂直行业中有所应用，成为支撑这些应用发展的动力源泉。 机器学习 机器学习（Machine Learning）是一门专门研究计算机怎样才能模拟或实现人类的学习行为，以获取新的知识或技能，使之不断改善自身的性能的学科。机器学习虽然发展了几十年，但还是存在很多没有良好解决的问题，例如图像识别、语音识别、自然语言理解、天气预测、内容推荐等等。机器主要通过大量的训练数据进行训练，程序不断地进行自我学习和修正来训练出一个模型，而模型的本质就是一堆参数用成千上万的参数来描述业务特点，从而接近人类的智力。 机器学习是一门多领域交叉学科，涉及统计学、系统辨识、逼近理论、神经网络、优化理论、计算机科学、脑科学等诸多领域。通过研究计算机怎样模拟或实现人类的学习行为， 以获取新的知识或技能。通过知识结构的不断完善与更新来提升机器自身的性能，这属于人工智能的核心领域。基于数据的机器学习是现代智能技术中的重要方法之一，研究从观测数据（样本）出发寻找规律，利用这些规律对未来数据或无法观测的数据进行预测。 AlphaGo就这项技术一个很成功的体现。 根据学习模式将机器学习分类为监督学习、无监督学习和强化学习等。根据学习方法可以将机器学习分为传统机器学习和深度学习。 深度学习是机器学习的一个子集。深度学习的前身是人工神经网络（Artificial Neural Network, ANN），它的基本特点就是模仿人脑神经元传递和处理信息的模式。 有监督学习：输入的训练数据有特征、有标记，在学习中就是找到特征与标记之间的映射关系，通过标记不断纠正学习中的偏差，使预测率不断提高。这种训练数据有标记的学习称为有监督学习。 无监督学习：让计算机自己去学习怎样做一些事情，所有训练数据没有标记，只有特征。无监督学习有两种思路：第一种，训练时不为其指定明确分类但数据会呈现聚群的结构，彼此相似的类型会聚集在一起。计算机把这些没有标记的数据分成一个个组合，就是聚类；第二种，在成功时采用某种激励制度，即强化学习. 半监督学习：训练数据中有一部分有标记有一部分无标记，没有标记的数量远远大于有标记的数量（这也符合现实）。它的基本规律是：数据的分布必然不完全随机，通过结合有标记的局部特征，以及大量没标记的数据的整体分布，可以得到比较好的分类结果。 自然语言处理 自然语言处理（Natural Language Processing, NLP）就是用计算机来处理、理解以及运用人类语言(如中文、英文等)，它属于人工智能的一个分支，是计算机科学与语言学的交叉学科，又常被称为计算语言学。由于自然语言是人类区别于其他动物的根本标志。没有语言，人类的思维也就无从谈起，所以自然语言处理体现了人工智能的最高任务与境界，也就是说，只有当计算机具备了处理自然语言的能力时，机器才算实现了真正的智能。 从研究内容来看，自然语言处理包括语法分析、语义分析、篇章理解等。从应用角度来看，自然语言处理具有广泛的应用前景。特别是在信息时代，自然语言处理的应用包罗万象，例如：机器翻译、手写体和印刷体字符识别、语音识别及文语转换、信息检索、信息抽取与过滤、文本分类与聚类、舆情分析和观点挖掘等，它涉及与语言处理相关的数据挖掘、机器学习、知识获取、知识工程、人工智能研究和与语言计算相关的语言学研究等。 值得一提的是，自然语言处理的兴起与机器翻译这一具体任务有着密切联系。机器翻译指的是利用计算机自动地将一种自然语言翻译为另外一种自然语言。由于人工进行翻译需要训练有素的双语专家，翻译工作非常耗时耗力。更不用说需要翻译一些专业领域文献时，还需要翻译者了解该领域的基本知识。世界上有超过几千种语言，而仅联合国的工作语言就有六种之多。如果能够通过机器翻译准确地进行语言间的翻译，将大大提高人类沟通和了解的效率。 自然语言处理的困难可以罗列出来很多，不过关键在于消除歧义问题，如词法分析、句法分析、语义分析等过程中存在的歧义问题，简称为消歧。而正确的消歧需要大量的知识，包括语言学知识（如词法、句法、语义、上下文等）和世界知识（与语言无关）。这带来自然语言处理的两个主要困难。首先，语言中充满了大量的歧义，这主要体现在词法、句法及语义三个层次上。歧义的产生是由于自然语言所描述的对象――人类活动非常复杂，而语言的词汇和句法规则又是有限的，这就造成同一种语言形式可能具有多种含义。另外一个方面，消除歧义所需要的知识在获取、表达以及运用上存在困难。由于语言处理的复杂性，合适的语言处理方法和模型难以设计。 目前，人们主要通过两种思路来进行自然语言处理，一种是基于规则的理性主义，另外一种是基于统计的经验主义。理性主义方法认为，人类语言主要是由语言规则来产生和描述的，因此只要能够用适当的形式将人类语言规则表示出来，就能够理解人类语言，并实现语言之间的翻译等各种自然语言处理任务。而经验主义方法则认为，从语言数据中获取语言统计知识，有效建立语言的统计模型。因此只要能够有足够多的用于统计的语言数据，就能够理解人类语言。然而，当面对现实世界充满模糊与不确定性时，这两种方法都面临着各自无法解决的问题。例如，人类语言虽然有一定的规则，但是在真实使用中往往伴随大量的噪音和不规范性。理性主义方法的一大弱点就是鲁棒性差，只要与规则稍有偏离便无法处理。而对于经验主义方法而言，又不能无限地获取语言数据进行统计学习，因此也不能够完美地理解人类语言。二十世纪八十年代以来的趋势就是，基于语言规则的理性主义方法不断受到质疑，大规模语言数据处理成为目前和未来一段时期内自然语言处理的主要研究目标。统计学习方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。迈进二十一世纪，我们已经进入了以互联网为主要标志的海量信息时代，这些海量信息大部分是以自然语言表示的。一方面，海量信息也为计算机学习人类语言提供了更多的“素材”，另一方面，这也为自然语言处理提供了更加宽广的应用舞台。例如，作为自然语言处理的重要应用，搜索引擎逐渐成为人们获取信息的重要工具，涌现出以百度、谷歌等为代表的搜索引擎巨头；机器翻译也从实验室走入寻常百姓家，谷歌、百度等公司都提供了基于海量网络数据的机器翻译和辅助翻译工具；基于自然语言处理的中文（输入法如搜狗、微软、谷歌等输入法）成为计算机用户的必备工具；带有语音识别的计算机和手机也正大行其道，协助用户更有效地工作学习。总之，随着互联网的普及和海量信息的涌现，自然语言处理正在人们的日常生活中扮演着越来越重要的作用。 计算机视觉 计算机视觉，英文Computer Vision，简称CV。计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等。 计算机视觉的主要任务就是通过对采集的图片或视频进行处理以获得相应场景的信息。计算机视觉任务的主要类型有以下几种： 物体检测 物体检测是视觉感知的第一步，也是计算机视觉的一个重要分支。物体检测的目标，就是用框去标出物体的位置，并给出物体的类别。 物体检测和图像分类不一样，检测侧重于物体的搜索，而且物体检测的目标必须要有固定的形状和轮廓。图像分类可以是任意的目标，这个目标可能是物体，也可能是一些属性或者场景。 物体识别（狭义） 计算机视觉的经典问题便是判定一组图像数据中是否包含某个特定的物体，图像特征或运动状态。这一问题通常可以通过机器自动解决，但是到目前为止，还没有某个单一的方法能够广泛的对各种情况进行判定：在任意环境中识别任意物体。 现有技术能够也只能够很好地解决特定目标的识别，比如简单几何图形识别、人脸识别、印刷或手写文件识别，或者车辆识别。而且这些识别需要在特定的环境中，具有指定的光照，背景和目标姿态要求。 图像分类 一张图像中是否包含某种物体，对图像进行特征描述是物体分类的主要研究内容。一般说来，物体分类算法通过手工特征或者特征学习方法对整个图像进行全局描述，然后使用分类器判断是否存在某类物体。 图像分类问题就是给输入图像分配标签的任务，这是计算机视觉的核心问题之一。这个过程往往与机器学习和深度学习不可分割。 物体定位 如果说图像识别解决的是what，那么，物体定位解决的则是where的问题。利用计算视觉技术找到图像中某一目标物体在图像中的位置，即定位。 目标物体的定位对于计算机视觉在安防、自动驾驶等领域的应用有着至关重要的意义。 图像分割 在图像处理过程中，有时会需要对图像进行分割来提取有价值的用于后继处理的部分，例如筛选特征点，或者分割一或多幅图片中含有特定目标的部分等。 图像分割指的是将数字图像细分为多个图像子区域（像素的集合，也被称作超像素）的过程。图像分割的目的是简化或改变图像的表示形式，使得图像更容易理解和分析。更精确地说，图像分割是对图像中的每个像素加标签的一个过程，这一过程使得具有相同标签的像素具有某种共同视觉特性。 图像语意分割是一个像素级别的物体识别，即每个像素点都要判断它的类别。它和检测的区别是，物体检测是一个物体级别的，他只需要一个框，去框住物体的位置，而通常分割是比检测要更难的问题。 计算机视觉是通过创建人工模型来模拟本由人类执行的视觉任务。其本质是模拟人类的感知与观察的一个过程。这个过程不止识别，而是包含了一系列的过程，并且最终是可以在人工系统中被理解和实现的。 智能机器人 智能机器人之所以叫智能机器人，这是因为它有相当发达的“大脑”。在脑中起作用的是中央处理器，这种计算机跟操作它的人有直接的联系。最主要的是，这样的计算机可以进行按目的安排的动作。正因为这样，我们才说这种机器人才是真正的机器人，尽管它们的外表可能有所不同。 类脑智能 类脑智能又称为类脑计算，上世纪80年代末，美国科学家卡沃・米德（Carver Mead）首次提出类脑计算的概念。类脑计算这一想法摆脱了传统的计算模式，模仿人类神经系统的工作原理，渴求开发出快速、可靠、低耗的运算技术。类脑智能是人工智能的终极目标，但研究类脑智能不可能复制人的大脑。类脑智能希望通过研究人类大脑的工作机理并模拟出一个和人类一样具有思考、学习能力的机器人。类脑智能技术充分学习人脑的思维模式，从仿生角度努力寻求人工智能的突破。这一热门学科前景诱人，应用范围广阔。科学家们曾预言一个国家类脑智能的发展水平将极大程度影响该国在军事、工业等众多行业的发展，因此类脑智能技术的发展显得尤为重要与急迫。 人工智能的应用 人工智能应用（Applications of Artificial Intelligence）的泛围很广，包括：医药，诊断，金融贸易，机器人控制，法律，科学发现和玩具。许多千种人工智能应用深入于每种工业的基础。90年代和21世纪初，人工智能技术变成大系统的元素；但很少人认为这属于人工智能领域的成就。 人工智能在金融领域的应用 银行用人工智能系统组织运作，金融投资和管理财产。2001年8月在模拟金融贸易竞赛中机器人战胜了人。 金融机构已长久用人工神经网络系统去发觉变化或规范外的要求，银行使用协助顾客服务系统；帮助核对帐目，发行信用卡和恢复密码等 人工智能在医疗领域的应用 医学临床可用人工智能系统组织病床计划；并提供医学信息。 人工神经网络用来做临床诊断决策支持系统。用人工智能在医学方面还有下列潜在可能：计算机帮助解析医学图像。这样系统帮助扫描数据图像，从计算X光断层图发现疾病，典型应用是发现肿块。 心脏声音分析。 人工智能在家居领域的应用 人工智能在智能家居场景中，一方面将进一步推动家居生活产品的智能化，包括照明系统、影音系统、能源管理系统、安防系统等，实现家居产品从感知到认知到决策的发展，另一方面在于智能家居系统的建立，搭载人工智能的多款产品都有望成为智能家居的核心，包括机器人、智能音箱、智能电视等产品，智能家居系统将逐步实现家居自我学习与控制，从而提供针对不同用户的个性化服务。 人工智能在汽车领域的应用 基于AI的自动驾驶，自动驾驶车辆所需的处理能力是巨大的，而传统的计算机根本无法胜任这项任务。因为自动驾驶不是遵循一套规则或简单的算法，它涉及到深度学习等，换句话说，就涉及人工智能。越来越多的汽车制造商和初创企业都在开发人工智能应用程序，目前在自动驾驶领域有两家公司处于领先地位：谷歌和特斯拉。 基于AI的云服务，人工智能和云服务也是形影不离，相互作用的。无论如何，汽车都需要通过大量的数据来分析完成相应的任务。人工智能云服务的应用确保了数据的有效性，更充分体现了大数据的潜在价值。 基于AI的汽车保险，保险公司利用人工智能实时进行风险评估。 基于AI的汽车制造，人工智能不仅改变了汽车的功能，也改变了汽车的制造方式。新出现的是与人类并肩作战的智能机器人。例如2018年初，起亚汽车开始与现代合作，为其装配线开发可穿戴工业机器人。背心外骨骼(H-VEX)和无椅外骨骼(H-CEX)可穿戴机器人帮助保护工作人员的膝盖、背部和颈部，同时赋予他们更大的灵活性与更强的力量 基于AI的驾驶员监控，以色列初创企业eyeSight借助先进的TOF摄像机和红外传感器，检测驾驶员的行为， 人工智能在零售领域的应用 人工智能在商业界中已经掀起了一阵风潮，其系统的庞大市场规模越来越受到重视。具体体现为店面优化，供应链优化，营销策略的变化，手势识别等方面 人工智能在教育领域的应用 个性化学习，因材施教：分析内容，构建知识图谱，构建和优化内容模型，建立知识图谱，让用户可以更容易地、更准确地发现适合自己的内容。国外这方面的典型应用是分级阅读平台，推荐给用户适宜的阅读材料，并将阅读与教学联系在一起，文后带有小测验，并生成相关阅读数据报告，老师得以随时掌握学生阅读情况。 自动化辅导与答疑：AI除了应用于个性化学习方案的制定外，还落地在自动化辅导和答疑子领域，这也成为了教师面授外的补充。 智能测评：随着信息化建设、人工智能的发展，大数据、文字识别、语音识别、语义识别，使得规模化的自动批改和个性化反馈走向现实。如何利用人工智能减轻批改压力，实现规模化又个性化的作业反馈，是未来教育的重要攻克点 模拟和游戏化教学平台：寓教于乐也是现代教育理念之一。 教育决策：AI 能做的远远不止大学专业选择的分析决策，AI 帮助决策将越来越多地影响我们生活的方方面面 幼儿早教机器人：早教的未来在移动和智能。儿童机器人的门槛不在技术这块，而在于内容、交互方式。 物联网概述 物联网的发展 物联网的概念英文术语为Internet of Things。物联网是指按照约定的协议，将具有感知、通信、计算功能的智能物体、系统、信息资源互联起来，实现对物理世界泛在感知、可靠传输、智慧处理的智能服务系统。20世纪90年代有关物联网的研究开始萌芽，此后其概念不断地演进和发展。1999年美国麻省理工学院的Kevin Ashton和他的同事首次提出Internet of Things的概念。同年，中科院启动了传感网的研究，并取得了一些科研成果，建立了一些适用的传感网。2005年，国际电信联盟（ITU）在《The Internet of Things》报告中对物联网概念进行扩展。无所不在的物联网通信时代即将来临。 进入2009年，物联网得到了真正的起步。 2019年1月，奥巴马就任美国总统后，与工商界代表举行了一次圆桌会议。IBM公司代表提出了智慧地球的研究计划，建议新政府投资新一代的智慧型基础设施。当年，美国将新能源和物联网列为振兴经济的两大核心武器； 2019年8月，温家宝总理在视察无锡时提出建设“感知中国”中心，物联网被正式列为国家五大新兴战略性产业之一，写入“政府工作报告”，物联网在中国受到了全社会极大的关注； 2019年9月，欧盟第七框架下RFID和物联网研究项目簇（European Research Cluster on the Internet of Things）发布了《物联网战略研究路线图》研究报告，定义为基于标准的和可互操作的通信协议且具有自配置能力的动态的全球网络基础架构。 至此，物联网真正的建立了起来，随后的几年物联网开始迈上了新的台阶。我们要学习物联网，必然要从技术层面入手，当下从技术的角度来理解，物联网的发展共分为4个阶段，具体如下图所示： 物联网当今在中国的受关注程度是在美国、欧盟及其他各国不可比拟的，中国在物联网理念和应用方面可以说是已经走在了世界的前面。近年来，电子信息技术和人工智能应用的发展促使物联网的内涵和外延有了很大的拓展，物联网已经表现为信息技术和通信技术的发展融合，是信息社会发展的趋势。 物联网的关键技术 物联网的关键技术主要包括三个方面：各类终端实现“全面感知”；电信网、互联网等融合实现“可靠创术”；云计算等技术对海量数据的“智能处理”。通过这三个方面的有机结合实现各类资源的“虚拟”和“共享”。 全面感知 全面感知是指利用射频识别（RFID）、传感器、定位器和二维码等手段随时随地对物体进行信息采集和获取。 可靠传输 可靠传输是指通过各种电信网络与互联网的融合，对接收到的感知信息进行实时远程传送，实现信息的交互和共享，并进行各种有效的处理。在这一过程中，通常需要用到现有的电信运行网络，包括无线和有线网络。由于传感器网络是一个局部的无线网，因此无线移动通信网、4G、5G网络是作为承载物联网的一个有力的支撑。 智能处理 物联网是一个智能的网络，面对采集的海量数据，必须通过智能分析和处理才能实现智能化。智能处理是指利用云计算、数据挖掘、模糊识别等各种智能计算技术，对随时接收到的跨地域、跨行业、跨部门的海量数据和信息进行分析处理，提升对物理世界、济社会各种活动和变化的洞察力，实现智能化的决策和控制。 边缘计算 边缘计算起源于传媒领域，是指在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务。其应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求。边缘计算处于物理实体和工业连接之间，或处于物理实体的顶端。而云端计算，仍然可以访问边缘计算的历史数据。对物联网而言，边缘计算技术取得突破，意味着许多控制将通过本地设备实现而无需交由云端，处理过程将在本地边缘计算层完成。这无疑将大大提升处理效率，减轻云端的负荷。由于更加靠近用户，还可为用户提供更快的响应，将需求在边缘端解决。 边缘计算五大优势应对物联网大数据挑战 实时计算，减少反应延迟 边缘计算分布式以及靠近设备端的特性注定它实时处理的优势，所以它能够更好的支撑本地业务实时处理与执行。 可靠性高，离线正常运作 家里的事情就不麻烦远在天边的云计算了，碰到没有网的情况下也一样能运行正常，边缘计算直接对终端设备的数据进行过滤和分析，节能省时效率还高，不受网络限制。 安全合规，满足隐私要求 制造、能源、公共事业等行业要实现智能化，需要整合机械、电子、ICT等跨行业技术，边缘计算首先要实现OT(Operation Technology)和IT领域的深度协作，并将行业专有技术与知识与ICT(Information and Communication Technology) 数字化技术相结合，满足多种用户需求，无论是什么样子的安全协议，他都将支持。 高性价比，节省存储运输成本 按照IDC（国际数据公司）的统计数据，到2020年将有超过500亿的终端与设备联网，未来超过50%的数据需要在网络边缘侧分析、处理与储存。边缘计算所面对的市场规模非常巨大，可以存储可运输，不用大型的服务器机房，照样能够运行。 灵活部署，新旧设备互通 不用担心新设备的诞生造成老设备相关接口的不兼容问题，无论你是智慧城市、智慧家居、智慧医院、在线直播，到智能泊车、自动驾驶、无人机、智能制造还是其他，我们都可以灵活部署到每一个应用领域，且保证新旧设备互通互联。 如果说云计算就像是天上的云，看得见摸不着，像章鱼的大脑，边缘计算就类似于八爪鱼的那些小爪子，一个爪子就是一个小型的机房，靠近具体的实物。把云计算看作是大脑，那么边缘计算就像是大脑输出的神经触角，这些触角连接到各个终端运行各种动作。 阿里云边缘计算产品Link Edge已经问世。据说通过这款产品，开发者能够轻松将阿里云的边缘计算能力部署在各种智能设备和计算节点上，比如车载中控、工业流水线控制台、路由器等。另外基于生物识别技术的智能云锁利用本地家庭网关的计算能力，可实现无延时体验，断网了还能开锁，避免“被关在自己家门外”的尴尬。云与边缘的协同计算，还能实现场景化联动，一推开门，客厅的灯就自动打开迎接你回家。 传感器 在物联网中，传感器主要负责接收物品讲话的内容。传感器技术是从自然信源获取信息并对获取的信息进行处理、变换、识别的一门多学科交叉的现代科学与工程技术，它涉及传感器、信息处理和识别的规划设计、开发、制造、测试、应用及评价改进活动等内容。计算机类似于人的大脑，但仅有大脑而没有感知外界信息的“五官”显然是不够的，计算机也需要它们的五官——传感器。 传感器也就是我们物联网系统中主要用于采集物理世界中发生的物理事件和数据，包括各类物理量、标识、音频和视频数据等。物联网数据采集涉及的技术有多种，主要包括传感器、RFID、多媒体信息采集、实时定位等。传感器网络组网和协同信息处理技术实现传感器、RFID等数据采集技术所获取数据的短距离传输、自组织组网及多个传感器对数据的协同信息处理过程。物联网传感器解决的就是人类世界和物理世界的数据获取问题，包括以下几点： 传感器是一种检测装置，能感受到被检测的信息，并能将检测感受到的信息，按一定规律变换成为电信号或其他所需形式的信息输出，以满足信息的传输、处理、存储、显示、记录和控制等要求，如下图所示，它是实现自动检测和自动控制的首要环节，我们常用的包括以下几种： 物联网的应用 物联网作为一种新兴的信息技术正在迅速向各个行业蔓延，从家庭、医疗保健、物流、汽车、零售到工业制造，物联网产品技术将无处不在。例如，时下流行的共享单车，只要拿出手机扫一扫便可打开智能锁骑行，这些智能锁使用的就是物联网技术。 物联网是一个极其庞大的网络，它包罗万象，涉及各行各业，其实质就是让万事万物通过网络连接起来，实现众多超级智能化的应用。业内预测，未来20年内物联网设备接入数量将越过1万亿台，这意味着物联网产业蕴含着巨大的市场机遇。 目前物联网的应用主要包括：智能工业、智能农业、智能电网、智能家居、智慧校园、智慧医疗、智能交通、智能物流、环境监测等方面。从市场应用来看，智能工业占据物联网市场主要份额最大。物联网技术的应用提高了生产线过程检测、实时参数采集、生产设备监控、材料消耗监测的能力和水平。生产过程的智能监控、智能控制、智能诊断、智能决策、智能维护水平不断提高。钢铁企业应用各种传感器和通信网络，在生产过程中实现对加工产品的宽度、厚度、温度的实时监控，从而提高了产品质量，优化了生产流程。 物联网在家居领域的应用 智能家居是一个居住环境，是以住宅为平台安装有智能家居系统的居住环境，实施智能家居系统的过程称为智能家居集成。 智能家居通过物联网技术将家中的各种设备连接到一起，提供家电控制、照明控制、窗帘控制、电话远程控制、室内外遥控、防盗报警、环境监测、暖通控制、红外转发以及可编程定时控制等多种功能和手段，让用户有更方便的手段来管理家庭设备。 通过触摸屏、无线遥控器、电话、互联网或者语音识别控制家用设备，更可以执行场景操作，使多个设备形成联动；另一方面，智能家居内的各种设备相互间可以通信，不需要用户指挥也能根据不同的状态互动运行，从而给用户带来最大程度的高效、便利、舒适与安全。与普通家居相比，智能家居不仅提供舒适宜人且高品位的家庭生活空间，还将传统家居环境中那些各自单独存在的设备联为一个整体，形成集系统、结构、服务、管理为一体的高效、安全、便利、环保的居住环境，提供全方位的信息交互功能，帮助家庭与外部保持信息交流畅通，优化人们的生活方式，帮助人们有效安排时间，增强家居生活的安全性，甚至为各种能源费用节约资金。 物联网在教育领域的应用 物联网再教育中的应用，目前来说分为具体的五个方面，分别是教学质量监控、学生健康状况监测、信息化教学应用、智慧管理、智慧校园等。 教学质量监控 通常是将物联网与现有教学平台集成，开发阅读器接口中间件，对于需要督导的自律性较差的学生，定时佩戴传感器手表、眼镜等记录学生的多重数据，如脑电图、血压、体温等生理信息及眼动、手部轻微移动等运动信息，引入心理学相关测试技术，得出学生的紧张程度、注意力状况、动脑情况等。将传感器获取的实时数据导入现有教学平台，老师根据这些反馈信息对学生进行有效的督促辅导。 学生健康状况监测 通过门式晨检机感知学生的健康信息,自动采集体温指标,当学生体温异常时,可通过短信等通知家长与老师,当学校出现一定数量体温异常案例时,即可通过应急联动机制,将信息传至医疗机构跟踪处理,防止出现集体疫情；而通过为学生配置运动传感器,可以系统感知其运动指标,避免学校只培养“书呆子”。 信息化教学应用 利用物联网建立泛在学习环境。可以利用智能标签识别需要学习的对象，并且根据学生的学习行为记录，调整学习内容。这是对传统课堂和虚拟实验的拓展，在空间上和交互环节上，通过实地考察和实践，增强学生的体验。例如生物课的实践性教学中需要学生识别校园内的各种植物，可以为每类植物粘贴带有二维码的标签，学生在室外寻找到这些植物后，除了可以知道植物的名字，还可以用手机识别二维码从教学平台上获得相关植物的扩展内容。 智慧管理 物联网在教育管理中可以用于人员考勤、图书管理、设备管理等方面。例如带有RFID标签的学生证可以监控学生进出各个教学设施的情况，以及行动路线。又如将RFID用于图书管理，可通过RFID标签可方便地找到图书，并且可以在借阅图书的时候方便地获取图书信息而不用把书一本一本拿出来扫描。将物联网技术用于实验设备管理可以方便地跟踪设备的位置和使用状态，方便管理。 智慧校园 智能化教学环境，控制物联网在校园内还可用于校内交通管理、车辆管理、校园安全、智能建筑、学生生活服务等领域。例如，在教室里安装光线传感器和控制器，根据光线强度和学生的位置，调整教室内的光照度。控制器也可以和投影仪和窗帘导轨等设备整合，根据投影工作状态决定是否关上窗帘，降低灯光亮度。 开源硬件概述 开源硬件指与自由及开放原始码软件相同方式设计的计算机和电子硬件。开源硬件开始考虑对软件以外的领域开源，是开源文化的一部分。 开源硬件的发展 开源硬件（Open Source Hardware），是指与自由及开放源代码相同方式设计的计算机和电子硬件，是开源文化的一部分。开源文化源于20世纪70年代的黑客亚文化。到了90年代，随着Linux受到大众认可、 Netscape浏览器开放源代码等一系列科技事件，开源运动逐渐进入人们的视野。开源运动最早只有开源软件，并基于互联网进行传播。目前，我们日常生活中使用的手机操作系统安卓（Android）、电脑浏览器 Chrome都是属于开源软件。可以说，在我们的日常生活中，开源软件几乎无处不在。 开源软件推崇任何人都可以自由使用、复制、硏究和改动的思想，深刻影响着开源文化的发展。开源硬件也在这种思想下应运而生。1997年，开放源代码促进会（OSI）推出开源硬件认证计划。1998年，大卫·弗里曼（David Freeman）提出开源硬件规范项目。1999年，非营利组织开放设计基金会（ODF）成立，一场开源硬件的运动悄然发生。 开源运动的一个核心是用户可以自行制造产品，无须支付任何费用。它的长足发展成为创客运动兴起的一个重要的技术因素，被誉为创客之父的克里斯安德森(Chris Anderson）在其著作《创客：新工业革命》中，将在开源社区中分享设计成果、开展合作的文化规范与使用数字桌面工具设计新产品和通过设计传给商业制造服务商或自行制造称为创客运动的3个变革性共同点。 流行的开源硬件 Jetson Nano Jetson Nano是英伟达（NVIDIA）公司提供的一款面向AI的高性能低功率的开发板。具有HDMI、DP、以太网口、USB3.0、GPIO等多个接口。它开启了嵌入式物联网应用程序的新领域。Jetson Nano支持高分辨率传感器，可以并行处理多个传感器，并且可以在每个传感器流上运行多个现代神经网络。它内置了英伟达的硬件加速系统和OpenCV，还支持许多流行的人工智能框架，使开发人员可以很容易地将他们喜欢的模型和框架集成到产品中。Jetson Nano使所有人都能更容易地访问人工智能，并由相同的基础架构和软件提供支持。 树莓派（Raspberry Pi） 树莓派是一款针对电脑业余爱好者、教师、学生以及小型企业等用户的迷你电脑。树莓派基于Linux系统，并采用ARM架构处理器作为主芯片，也提供了USB与以太网接口。树莓派没有板载存储芯片，仅留有SD卡座，因而运行树莓派需要提供SD卡.树莓派尤其适合于需要支持用户界面的场合，因为它拥有HDMI输出。HDMI接口意味着我们可以将树莓派直接接入到电视或其他显示屏上，从而以低成本构建web浏览设备来支持与用户的交互。换句话说，树莓派可以看成一台功能相对完备的电脑，尽管性能不高。 Arduino Arduino是一款便捷灵活、方便上手的开源电子原型台，包含硬件（各种型号的Arduino板）和软件（Arduino IDE）两部分，由一个欧洲开发团队于2005年冬季开发。Arduino使用Atmel公司的一款微处理器作为主芯片，具有体积小、价格实惠等特性。不仅如此，Arduino在设计之初就考虑到了与不同的外设进行交互，在与现有的电子元件例如传感器或者其他控制器件、LED、步进马达等连接时，几乎不需要增加支持电路。当然，Arduino也可以独立运行，并与软件进行交互。同时，Arduino IDE基于processing IDE开发，灵活且简单。开发语言Arduino语言基于wiring语言开发，是对avr-gcc库的二次封装，不要求开发者有太多的编程基础，可以说Arduino对初学者非常友好。 ESPRESSIF ESP8266EX是一个价格低廉的开发板，包含WiFi模块和GPIO，可以连接传感器、舵机、马达等各种设备。使用Arduino IDE进行开发编程。可通过网络、串口和蓝牙等多种方式进行通信。该芯片可工作于三种种模式下，分别是：AP模式，station模式以及混合模式，通过常用的AT指令进行控制。其具有以下四个主要特性： 性能稳定 ESP8266EX的工作温度范围大，且能够保持稳定的性能，能适应各种操作环境。 高度集成 ESP8266EX集成了32位Tensilica处理器、标准数字外设接口、天线开关、射频、功率放大器、低噪放大器、过滤器和电源管理模块等，仅需很少的外围电路，可将所占PCB空间降低。 低功耗 ESP8266EX专为移动设备、可穿戴电子产品和物联网应用而设计，通过多项专有技术实现了超低功耗。ESP8266EX具有的省电模式适用于各种低功耗应用场景。 32位Tensilica处理器 ESP8266EX内置超低功耗Tensilica L106 32位RISC处理器，CPU时钟速度最高可达160MHz，支持实时操作系统 （RTOS）和WiFi协议栈，可将高达80%的处理能力留给应用编程和开发。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-13 "},"content/chapter0/环境准备.html":{"url":"content/chapter0/环境准备.html","title":"环境准备","keywords":"","body":"环境准备 相关软件及资源，请点击这里来下载也可以选择在下方提供的官方网址下载推荐按顺序依次安装以下软件，以避免因依赖问题报错 Arduino建议使用我们提供的预先配置好的版本 在Windows和macOS上的操作 Anaconda Anaconda是一个Python环境管理软件。在Windows，Mac、Linux上均可以方便安装下载链接：https://www.anaconda.com/distribution 选择适合自己的操作系统，并选择Python 3.7版本 基本命令概览 创建环境 conda create -n 环境名字 //例如： conda create -n py27 python=2.7 //表示创建一个名字为py27，运行python2.7的虚拟环境 //后面的python=2.7是可选输入 //不输入时默认环境是python3 进入环境 conda activate 环境名字 //例如： conda activate py27 安装指定包 conda install 包名 //例如：安装OpenCV conda install opencv 其他命令 //退出环境 conda deactivate //列出环境 conda-env list //删除环境 conda-env remove -n 环境名字 setup 1.下载安装Anaconda2.macOS用户打开终端, Windows用户在开始菜单打开Anaconda Prompt3.创建并进入环境 (python版本为默认的3.x)4.在新环境中安装TensorFlow和OpenCV（若电脑有独立显卡应安装GPU版本的TensorFlow） //创建一个名字为learn-ai的虚拟环境 conda create -n learn-ai //激活learn-ai虚拟环境 conda activate learn-ai //无独立显卡的电脑使用这条命令 conda install tensorflow //有独立显卡的电脑使用这条命令 conda install tensorflow-gpu //安装opencv conda install opencv //安装git命令 conda install git VSCode VSCode是微软出品的免费代码编辑软件。在Windows、Mac、Linux上均可以方便安装下载链接：https://code.visualstudio.com setup 1.下载安装VSCode2.安装插件Settings Sync 3.输入Shift+Alt+D,输入GitHub Token和Gist Token(点击获取)，即可从服务端同步设置。免去自己配置的麻烦 CP2102驱动 这个驱动用于使用USB串口连接esp8266注意选择对应的操作系统和版本进行下载和安装下载链接: https://www.silabs.com/products/development-tools/software/usb-to-uart-bridge-vcp-drivers Arduino IDE Arduino IDE （Integrated Development Environment,集成开发环境）是针对Arduino控制板的编程和下载平台。在Windows，Mac、Linux上均可以方便安装，Arduino项目文件的后缀是*.ino项目文件应在与项目名相同的文件夹中下载链接：https://www.arduino.cc/en/Main/Software?setlang=cn setup 1.下载安装Arduino IDE2.在文件--首选项--附加开发板管理器网址一栏中输入https://arduino.esp8266.com/stable/package_esp8266com_index.json,https://dl.espressif.com/dl/package_esp32_index.json 重启IDE 3.在工具--开发板--开发板管理器中分别搜索esp8266和esp32,点击对应项进行安装 4.在工具--管理库中搜索DHT,选择DHT sensor library by Adafruit 5.在工具--管理库中搜索选择选择Adafruit Unifled Sensor by Adafruit 6.打开链接https://github.com/esp8266/arduino-esp8266fs-plugin/releases/tag/0.5.0,选择.zip文件下载，将解压后的文件夹复制到Arduino安装目录/tools文件夹，然后重启IDE 默认的路径应该是这样：C:\\Program Files (x86)\\Arduino\\tools\\ESP8266FS\\tool\\esp8266fs.jar 如果安装成功，会在工具菜单下看到下图选项: 7.设置开发板和端口 教学路由器配置 教学的路由器设置SSID名字为AI，密码为raspberry路由器管理地址设置为http://192.168.123.1，登录账号：admin，登录密码：admin 在树莓派上的操作 我们已经为树莓派配置好了全部环境和学习用的文件，并制作了恢复镜像提供下载。也可以直接使用我们烧录好的SD卡。 镜像恢复操作 在这里找到最新的恢复镜像和备份恢复软件。 将32G或以上的TF卡插入到读卡器，连接到电脑。 使用Etcher或Win32DiskImager进行镜像恢复。 Etcher 选择镜像文件，和读卡器的盘符，点击Flash Win32DiskImager 选择待恢复镜像和待写入磁盘盘符，然后点按写入 进入系统 树莓派默认连接的WiFi名称是AI，密码是raspberry。如果你的路由器名称和密码不是这个的话，你可以： 1.直接插网线 从路由器的lan口引出网线，连接到树莓派。打开你的路由器管理页面，查看树莓派分配到的IP地址。 2.修改你的WiFi名称和密码为AI和raspberry 打开你的路由器管理页面，修改WiFi名称和密码。 3.修改树莓派的配置文件，使其连接到你现有的WiFi 恢复完成后，在电脑上会出现一个boot分区。 在boot分区创建文件wpa_supplicant.conf，写入以下内容。 country=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\"WiFi名字-不要删掉引号\" psk=\"WiFi密码-不要删掉引号\" key_mgmt=WPA-PSK priority=1 } 树莓派环境说明【~TBD~】 1.Docker sudo curl -sL get.docker.com | sed 's/9)/10)/' | sh 2.Nginx web服务 sudo apt install nginx systemctl enable nginx systemctl start nginx systemctl status nginx 3.HomeAssistant Home Assistant是一个开源的物联网平台，兼容各种物联网协议。可以方便的接入和控制各种设备 # Install hassio dependencies sudo apt-get install apparmor-utils apt-transport-https avahi-daemon ca-certificates curl dbus jq network-manager socat software-properties-common # Install hassio cd ~ curl -sL \"https://raw.githubusercontent.com/home-assistant/hassio-installer/master/hassio_install.sh\" >> hassio_install.sh sudo nano hassio_install.sh --- \"armv7l\") HOMEASSISTANT_DOCKER=\"$DOCKER_REPO/raspberrypi3-homeassistant\" HASSIO_DOCKER=\"$DOCKER_REPO/armhf-hassio-supervisor\" ;; --- sudo bash hassio_install.sh 4.麦克风扩展板驱动 cd ~ git clone https://github.com/waveshare/WM8960-Audio-HAT cd WM8960-Audio-HAT sudo ./install.sh sudo reboot 5.Snowboy # https://github.com/Kitt-AI/snowboy sudo docker pull wupanhao/snowboy:1.0 # 启动镜像 sudo docker run -idt --name=\"rapiro\" --privileged -v /home/pi/rapiro:/rapiro wupanhao/snowboy:1.0 /bin/bash # 进入镜像 sudo docker exec -it rapiro env LANG=C.UTF-8 /bin/bash 6.课程项目文件 7.其他 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-25 "},"content/chapter1/第1章简介.html":{"url":"content/chapter1/第1章简介.html","title":"第1章 基础知识","keywords":"","body":"第1章 基础知识 本章主题：掌握基础 学习者通过学习本章内容，将熟悉掌握一些必备的相关技能。如Python基础，Linux常见命令操作，开源硬件的基础操作等。为后续的项目学习打好基础。 后面的三、四、五、六章是四个综合项目，其对应的基础知识如图。 本章重点 了解Python基本语法规则、熟悉Linux基本操作，知道Web相关概念，会做简单的Web服务器，了解开源硬件的基本操作。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-13 "},"content/chapter1/第1节 Python语言基础.html":{"url":"content/chapter1/第1节 Python语言基础.html","title":"第1节 Python语言基础","keywords":"","body":"第1节 Python语言基础 Python简介 Python是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。 Python的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。 Python是一种解释型语言： 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。 Python是交互式语言： 这意味着，您可以在一个Python提示符 >>> 后直接执行代码。 Python是面向对象语言: 这意味着Python支持面向对象的风格或代码封装在对象的编程技术。 Python是初学者的语言：Python对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到浏览器再到游戏。 1.Python发展历史 Python是由Guido van Rossum在八十年代末和九十年代初，在荷兰国家数学和计算机科学研究所设计出来的。 Python本身也是由诸多其他语言发展而来的,这包括ABC、Modula-3、C、C++、Algol-68、SmallTalk、Unix shell和其他的脚本语言等等。 像Perl语言一样，Python源代码同样遵循GPL(GNU General Public License)协议。 现在Python是由一个核心开发团队在维护，Guido van Rossum仍然占据着至关重要的作用，指导其进展。 Python 2.7被确定为最后一个Python 2.x版本，它除了支持 Python 2.x语法外，还支持部分Python 3.1语法。 2.Python特点 1).易于学习：Python有相对较少的关键字，结构简单，和一个明确定义的语法，学习起来更加简单。 2).易于阅读：Python代码定义的更清晰。 3).易于维护：Python的成功在于它的源代码是相当容易维护的。 4).一个广泛的标准库：Python的最大的优势之一是丰富的库，跨平台的，在UNIX，Windows和macOS兼容很好。 5).互动模式：互动模式的支持，您可以从终端输入执行代码并获得结果的语言，互动的测试和调试代码片断。 6).可移植：基于其开放源代码的特性，Python已经被移植（也就是使其工作）到许多平台。 7).可扩展：如果你需要一段运行很快的关键代码，或者是想要编写一些不愿开放的算法，你可以使用C或C++完成那部分程序，然后从你的Python程序中调用。 8).数据库：Python提供所有主要的商业数据库的接口。 9).GUI编程：Python支持GUI可以创建和移植到许多系统调用。 10).可嵌入: 你可以将Python嵌入到C/C++程序，让你的程序的用户获得\"脚本化\"的能力。 3.Python版本说明(以树莓派已安装版本为例) 版本 说明 备注 Python Python2.7 属于Python早期版本，官方逐渐放弃维护该版本 Python3 Pyhton3.7 Python3是较新的版本，Python2.7语法与Python3不兼容，其程序代码无法使用Python3的解释器运行 树莓派上运行python2环境，如下图： 树莓派上运行python3环境，如下图： 4.Python文件的执行 我们一般在终端里，通过python test.py的方式来运行Python文件。 5.Python包管理工具—pip pip是一个现代的，通用的Python包管理工具,提供了对Python包的查找，下载，安装，卸载的功能。PIP的使用方法:【注】：由于Python2与Python3的语法不兼容，故pip为Python2的包管理工具，Python3的包管理工具为pip3。 |pip命令|功能|备注 :-:|:-:|:-: |install|安装软件包|pip install [package name]| |download|下载软件包|| |uninstall|卸载软件包|pip uninstall [package name]| |list|列表列出已安装的软件包|pip list| |show|显示已安装软件包的信息|pip show [package name]| |check|检查已安装的软件包是否具有兼容的依赖项|| |search|搜索PyPI查找软件包|| |help|显示帮助命令|| Python基本语法 1.Python语言源程序模块的初识 一个Python程序可能由一个或多个模块组成。模块是程序的功能单元。Python模块的典型结构由:模块文档、模块导入、变量定义、类定义语句、函数定义语句、主程序等组成。 模块文档：模块文档使用三引号注释的形式，简要的介绍模块的功能以及重要全局变量的含义。 模块导入：导入需要调用的其他模块。模块只能被导入一次，被导入模块中的函数代码并不会被自动执行，只能被当前模块主动（显式）调用。 2.基本词法单位、标识符/常量/运算符等构成规则与关键字 基本词法单位：常量、变量、关键字、运算符、表达式、函数、语句、类等。 常量：是指初始化（第一次赋予值）后保持固定不变的值。例如：1，3.14，'Hello!',False,这是4个不同类型的常量。在Python中没有命名常量，通常用一个不改变值的变量代替。比如：PI=3.14 通常用于定义圆周率常量PI。 标识符：用于不同的的词法单位，通俗的讲就是名字。标识符可以作为变量、函数、类的名字。合法的标识符必须遵守以下规则： 由一串字符组成，字符可以是任意字母、数字、下划线、汉字，但这些字符中的开头不能是数字。 不能与关键字同名。关键字也成为保留字，是被语言保护起来具有特殊含义的词，不能用于起名字。查看Python的语言的所有关键字（用Python自带的IDLE执行下面两句代码） import keyword keyword.kwlist 标识符中唯一能够使用的标点符号是下划线，不能含有其他标点符号（包含：空格、括号、引号、逗号、斜线、反斜线、冒号、句号、问号等）。 正确的标识符：X、varl、FirstName、stu_score、平均分2等 错误的标识符：stu-score、First Name、2平均分 变量：是指在运行的过程中值可以被修改的量。变量的名称除了必须符合标识符的构成规则外，要尽量遵循一些约定俗成的规范。以下划线开头的变量在Python中有特殊的含义，所以自定义名称时，一般不用下划线作为开头字符。此外，Python是严格区分大小写字母的。也就是说，Score和score会被认为是两个不同的名字。 运算符：指常量/变量之间进行何种运算。 表达式：由常量、变量加运算符构成。一个表达式可能包含多次多种运算，与数学表达式在形式上很接近。例如：1+2、2(x+y)、0函数：是相对独立的功能单位，可执行一定的任务。 语句：是由函数、表达式调用组成的。另外，各种控制结构也属于语句，例如： if语句、for语句。 *类：是同一类事物的抽象。我们处理的数据都可以看做数据对象。Python是面向对象的程序设计语言，它是一个事物的静态特征（属性）和动态行为（方法）封装在一个结构里，称之为对象。 3.程序的书写格式与基本规则 缩进：使用缩进来区分代码块的级别。Python语言中没有采用花括号或begin...end等来分隔代码块，而是使用冒号和代码缩进来区分代码之间的层次。代码缩进是一种语法规则，错误的缩进可能导致代码的含义完全不同。如下2个代码块 建议使用在缩进代码前输入4个空格来表示代码缩进，不推荐其他数量的空格或使用制表符的方式来完成缩进。 分号：Python允许在行尾加分号，但不建议加分号，也不要用分号将两条命令放在同一行中。建议每一条命令单独一行。 长语句行：除非遇到长的导入模块语句或者注释里的URL，建议不宜超过80个字符。对于超长语句，允许但不提倡使用反斜杠连接行，建议在需要的地方使用圆括号来连接行。例如： 不推荐写法 year1 = 2016 if year1 % 4 == 0 and year1 % 100 != 0 or \\ year1 % 400 == 0: print(year1,\"是闰年！\") else: print(year1,\"不是闰年！\") 推荐写法 year2 = 2018 if (year2 % 4 == 0 and year2 % 100 != 0 or year2 % 400 == 0): print(year2,\"是闰年！\") else: print(year2,\"不是闰年！\") 括号：不建议使用不必要的括号，除非用于实现行连，否则不要在返回语句或者条件语句中使用括号，例如： if (x): # x两侧的括号多余 foo() if not (x): # x两侧的括号多余 foo() return (x) # x两侧的括号多余 空行：变量定义、类定义以及函数定义之间可以空两行。类内部的方法定义之间，类定义与第一个方法之间，建议一行。函数或方法中，如果有必要，可以空一行。 空格：对于赋值(=)、比较（==,,!=,<>,=,in,not in,is,is not）、布尔（and,or,not）等运算符，在运算符两边各加一个空格，可以使代码更清晰。而对于算数运算符，可以按照自己的习惯决定，但建议运算符两侧保持一致。例如： 不推荐写法 x==1 推荐写法 x == 1 注释：注释通常以#开始直到行尾结束。行内注释：和语句在同一行中的注释。行内注释应该以#和单个空格开始，应该至少用两个空格和前面的语句分开。注释块后面通常跟着代码，且注释块应该与相关代码的缩进一致。注释块中的每行以#和一个空格开始，注释块内段落以仅含单个#的行分割。注释块上下方最好各空一行。例如： 建议的写法 # 这个函数用于计算班级所有学生的平均分 # # 例子： Avg(score,100) def Avg(Score,Num): pass 文档字符串：是Python 语言独特的注释方式。文档字符串是包、模块、类或函数中的第一条语句。文档字符串可以通过对象doc成员被自动提取。我们书写文档字符串的时候，在其前、后使用三重双引号 \"\"\" 或三重单引号 '''。一个规范的文档字符串应该首先是一行概述，接着是一个空行，然后是文档字符串剩下的部分，并且应该与文档字符串的第一行的第一个引号对齐。例如： def Avg(Score, Num=100): \"\"\" 计算班级的平均分 从Score中读取所有学生的成绩，逐一加求总分，然后把总分除以人数Num,结果就是平均分，返回该结果 参数 Score: 记录所有学生的成绩列表 Num:班级总人数，默认值是100 返回值 float类型的平均分 \"\"\" pass 文档字符串可以通过doc成员进行查看，也可以在help()函数的结果里 >>> print(Avg.__doc__) 文档字符串通常用于提供在线帮助信息。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-04-02 "},"content/chapter1/第2节 Linux基本操作.html":{"url":"content/chapter1/第2节 Linux基本操作.html","title":"第2节 Linux基本操作","keywords":"","body":"第2节 Linux基本操作 由于树莓派运行的Raspbian操作系统属于Linux家族，所以我们需要了解Linux的基本命令 内容提要 了解Linux终端操作 体验Linux终端下的基本操作 学会Linux终端下的文件复制，移动，粘贴 学会Linux终端下Nano和Vim文件编辑器的使用 背景知识 Linux 终端 终端（Terminal）也称终端设备，是计算机网络中处于网络最外围的设备，主要用于用户信息的输入以及处理结果的输出。在此处为Linux操作系统用于用户输入信息和输出信息的窗口，也是人机交流的窗口。(如下图所示：) 如何打开树莓派的终端(Terminal) 1.任意时刻按下键盘上的 Ctrl + Alt + t 2.点击快速启动栏上的终端图标 Shell Shell 是一个程序，同时它又是一种程序设计语言。作为命令语言，它交互式解释和执行用户输入的命令或者自动地解释和执行预先设定好的一连串的命令；作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。 在后边的学习中我们只会用到Shell命令，并且通过这些命令与树莓派(Linux)内核沟通，让树莓派执行我们想要的动作。 Linux目录结构 (如图所示：) 在Linux系统中，目录被组织成一个:单根倒置树结构，文件系统从根目录开始，用/来表示。文件名称区分大小写（ 大小写敏感还需要看具体的文件系统格式 ）,以.开头的为隐藏文件,路径用/来进行分割（windows中使用\\来分割）,文件有两个种类:元数据与数据本身.在操作linux系统时，通常会遵循以下的分层结构规则： 目录名称 功能 / 根目录，位于Linux文件系统目录结构的顶层，一般根目录下只存放目录，不要存放文件 /bin 提供用户使用的基本命令， 存放二进制命令，不允许关联到独立分区 /boot 用于存放引导文件,内核文件,引导加载器 /sbin 管理类的基本命令，不能关联到独立分区，OS启动时会用到的程序 /lib 存放系统在启动时依赖的基本共享库文件以及内核模块文件 /lib64 存放64位系统上的辅助共享库文件 /etc 系统配置文件存放的目录，该目录存放系统的大部分配置文件和子目录，不建议在此目录下存放可执行文件 /home 普通用户主目录，当新建账户时，都会分配在此，建议单独分区，并分配额外空间用于存储数据 /root 系统管理员root的宿主目录 /media 便携式移动设备挂载点目录 /mnt 临时文件系统挂载点 /dev 设备（device）文件目录，存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，存放连接到计算机上的设备 /opt 第三方应用程序的安装位置 /srv 服务启动之后需要访问的数据目录，存放系统上运行的服务用到的数据 /tmp 存储临时文件， 任何人都可以访问,重要数据一定不要放在此目录下 /usr 应用程序存放目录，/usr/bin 存放保证系统拥有完整功能而提供的应用程序， /usr/share 存放共享数据，/usr/lib 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件，/usr/local 存放软件升级包，第三方应用程序的安装位置，/usr/share/doc 系统说明文件存放目录 /var 放置系统中经常要发生变化的文件，如日志文件 /proc 用于输出内核与进程信息相关的虚拟文件系统，目录中的数据都在内存中 /sys 用于输出当前系统上硬件设备相关的虚拟文件系统 /selinux 存放selinux相关的信息安全策略等信息 常用的Shell命令 磁盘操作命令 注：命令在输入不完整时可食用Tab键补齐命令或路径上存在的文件名 ls 功能：用于显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录) 　　格式：ls [-参数] [名称] 　　参数：-a 显示所有文件及目录 　　　　　-l 显示文件或文件夹的详细信息 　　实例：ls -al 列出当前目录下所有文件(包括隐藏文件)的详细信息 　　　　　ll 显示文件或文件夹的详细信息(系统内置的快捷指令，相当于ls -l)   cd 功能：用于切换当前工作目录至指定目录 　　格式：cd [指定目录] 　　参数：无 　　实例：cd ~ (~指/home/user/目录)进入home目录(进入home目录也可以直接cd + Enter) 　　　　　cd / 进入根目录 　　　　　cd 123 进入当前目录下的123文件夹 　　　　　cd ../123 进入上级目录下的123文件夹   3.cp 功能：用于复制文件或目录 　　格式：cp [参数] 源文件 目标目录 　　参数：-a 此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容 　　　　　-r 若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件 　　实例：cp 123.c 123.c.back 将当前目录下的123.c文件复制并重命名为123.c.back到当前文件夹 　　　　　cp ../123.c ./ 复制上级目录下的123.c文件到当前目录下 　　　　　cp -r ../dir1/ ./ 复制上级目录下的dir1文件夹及其所有文件到当前目录下   4.touch 功能：用于修改文件或者目录的时间属性，若文件不存在，系统会建立一个新的文件 　　格式：touch [文件名] 　　参数：无 　　实例：touch 123.txt 在当前目录下创建123.txt文件   5.mkdir 功能：用于创建文件夹 　　格式：mkdir 文件夹名称 　　参数：-p 建立多级文件夹 　　实例：mkdir dir1 在当前目录下创建名称为dir1的文件夹 　　　　　mkdir -p dir1/dir2/dir3/ 在当前目录下连续创建dir1,dir2,dir3的子目录   6.mv 功能：用来为文件或目录改名、或将文件或目录移入其它位置 　　格式：mv [参数] 源文件 目标文件 　　参数：-i 若指定目录已有同名文件，则先询问是否覆盖旧文件 　　　　　-f 在 mv 操作要覆盖某已有的目标文件时不给任何指示; 　　实例：mv 123.c 456.c 将当前目录下的123.c文件重命名为456.c 　　　　　mv 123.c ./dir1/ 将当前目录下的123.c文件移动到当前目录的子目录dir1下   7.rm 功能：用于删除一个文件或者目录 　　格式：rm [参数] 名称 　　参数：-r 将目录以及目录中的文件全部删除 　　　　　-f 即使文件属性为只读，也会直接删除，无需逐一确认 　　实例：rm 123.c 将当前目录下的123.c文件删除(无确认提示，无法恢复) 　　　　　rm -rf ./dir1/ 删除当前目录下的dir1子目录及其内所有文件，且无需确认，直接删除，不可恢复   8.cat 功能：用于查看文件的内容(将文件内容打印到终端上用以查看) 　　格式：cat 目录+文件 　　参数：无 　　实例：cat 123.c 查看123.c文件的内容   9.pwd 功能：用于显示当前工作目录的绝对路径 　　使用方法：在终端键入：pwd，按Enter键，即显示当前工作目录的绝对路径 系统操作命令 1.Linux 操作系统命令 命令名称 | 执行动作 | 备注 :-: | :-: | :-: sudo apt-get update| 更新软件源|由于改变系统环境，故加sudo sudo apt-get upgrade |更新已安装的软件版本|由于改变系统环境，故加sudo sudo apt-get dist-upgrade|更新系统|由于改变系统环境，故加sudo sudo apt-get install [软件名]|安装软件|由于改变系统环境，故加sudo sudo apt-get remove [软件名]|卸载软件|由于改变系统环境，故加sudo sudo apt-get autoremove|自动卸载不需要的软件包|由于改变系统环境，故加sudo apt-cache search [软件名]|搜索指定名称的软件包|由于未对系统做出改变，不需加sudo apt-cache show [软件名]|获取包的相关信息，如说明、大小、版本|由于未对系统做出改变，不需加sudo apt-get source [软件名]|下载软件包的源代码|由于未对系统做出改变，不需加sudo sudo apt-get clean|清理无用软件包|与下一条命令配合使用 sudo apt-get autoclean|清理无用软件包|与上一条命令配合使用 whereis [软件名]|搜索软件并得到其详细信息| which [命令]|在系统中搜索命令以确定该命令是否存在|   2.sudo 功能：以超级用户身份运行软件或修改系统文件(类似windows10上的以管理员身份运行) 　　实例：sudo apt-get install nano :安装nano文本编辑软件时，由于是更改系统环境，所以需要加sudo   3.sudo shutdown -r now 重启系统 　sudo shutdown -h now 关机   4.chmod 功能：Linux的文件调用权限分为三级: 文件所有者、所属组、其他。chmod可修改文件的使用权限，即是否允许文件被其所有者，所属组，其他进行 读(r)，写(w)，执行(x)，三类权限分别对应八进制数：r -> 4,w -> 2,x -> 1 　说明：(1) User（所有者），Group(所属组)，Other(其他)分别都拥有对该文件的rwx权限，即： 文件所属 | User | Group | Other :-:|:-:|:-:|:-: 权限|rwx|rwx|rwx 各权限值|421|421|421 八进制值|7|7|7 实例：sudo chmod 666 123.sh 去除当前目录下123.sh文件的所有所属的可执行权限x(八进制数为1) 　　　sudo shmod 775 123.sh 为当前目录下123.sh文件的所有所属添加可执行权限x   5.chown 功能：指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID 　实例：sudo chown root:root 123.py 将123.py的用户以及用户组改为root(管理员用户) 　实例：sudo chown pi:pi 123.py 将123.py的用户以及用户组改为pi(普通用户)   6.netstat 功能：用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。（如下图所示） 　解析：(1) netstat会显示当前活动的网络连接(Active Internet connections) 和 活动的本地进程间通信的状态； 　　　　(2) 通过查看这些信息我们能知道当前有哪些通信端口被占用以及当前程序工作的状态。   7.pkill 功能：控制(关闭)同名程序的所有进程 　语法：pkill 选项 pattern（模式） 　参数：-G:仅匹配真实组ID在给定列表中的进程。 　　　　-t termlist:仅匹配与给定列表中终端关联的进程。 　　　　-signal:指定发往每一个匹配进程的信号 　　　　-U uidlist:仅匹配真实的用户ID在给定列表中的进程。 　实例：pkill -9 -U UserName 强制退出UserName用户   终端下常用应用软件的使用方法 1.tar 功能：将单个或多个文件(文件夹)打包或打包并压缩或解压 　参数：-c：新建打包文件，同 -v 一起使用 查看过程中打包文件名 　　　　-x：解压文件 　　　　-C：解压到对应的文件目录 　　　　-f：后边接要处理的文件 　　　　-j：通过bzip2方式压缩或解压，最后以.tar.br2 为后缀。压缩后大小小于.tar.gz 　　　　-z：通过gzip方式压缩或解压，最后以.tar.gz 为后缀 　　　　-v：显示解压或压缩的过程 　　　　-t：查看打包文件中内容，重点文件名 　　　　-u：更新压缩文件中的内容 　　　　-p：保留绝对路径，即允许备份数据中含有根目录 　　　　-P：保留数据原来权限及属性 　　　　--exclude = FILE ：压缩过程中不包含FILE文件 　实例：(1) tar czvf all-txt.tar.gz ./*.txt 将当前目录下的所有文件名以.txt结尾的文件，使用gzip方式压缩打包all-txt.tar.gz文件 　　　　(2) tar xvf JieYaWenJian.tar.gz 将JieYaWenJian.tar.gz 文件解压到当前文件夹下   2.zip 功能：zip压缩文件 　参数：-d：从压缩文件内删除指定的文件 　　　　-D：压缩文件内不建立目录名称 　　　　-F：尝试修复已损坏的压缩文件 　　　　-g：将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件 　　　　-i： 只压缩符合条件的文件 　　　　-m：将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中 　　　　-n： 不压缩具有特定字尾字符串的文件 　　　　-o：以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同 　　　　-r：递归处理，将指定目录下的所有文件和子目录一并处理 　　　　-q：不显示指令执行过程 　　　　-V：保存VMS操作系统的文件属性 　实例：(1) zip -q -r html.zip /home/html 将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip 　　　　(2) zip -dv cp.zip a.c 从压缩文件 cp.zip 中删除文件 a.c   3.unzip解压*.zip文件(*为通配符，代指任意字符) 　用法: unzip JieYaSuo.zip 将JieYaSuo.zip文件解压到当前文件夹   4.wget 功能：下载URL所连接的文件到本地 　用法：wget [参数] [URL] (URL即文件的下载链接，可通过浏览器点击鼠标右键并选择复制链接地址来获取目标的URL) 　参数：-v：显示Wget的版本信息并退出 　　　　-b：wget启动后转入后台 　　　　-q：安静模式(无信息输出) 　　　　-v：详尽的输出(此为默认值) 　　　　-nc：不要重复下载已存在的文件 　　　　-c：继续下载部分下载的文件 　　　　-O：下载文件到对应目录，并且修改文件名称 　　　　-spider：模拟下载，不会下载，只是会检查是否网站是否正常可用 　实例：(1) wget http://mirrors.aliyun.com/ubuntu-16.04.6.iso 将ubuntu-16.04.6.iso文件下载到当前目录 　　　　(2) wget --spider www.baidu.com 模拟下载，不会下载，只是会检查是否网站是正常可用   5.curl 功能：curl是一个非常实用的、用来与服务器之间传输数据的工具 　用法：(1) curl http://localhost:8080/simple-service-webapp/test/hello 获取页面内容 　　　　(2) curl -I http://localhost:8080/simple-service-webapp/test/hello显示 HTTP 头，而不显示文件内容，使用 -I 选项 　　　　(3) curl -o save.txt http://localhost:8080/simple-service-webapp/test/hello 将返回的结果保存到文件   6.git clone 功能：将URL指定的github代码仓库克隆到本地当前目录 　用法：git clone [git仓库的URL] 　实例：git clone https://github.com/esp8266/Arduino.git 将此链接对应的仓库克隆到本地当前目录 使用文本编辑器nano编辑文件 1.使用nano文本编辑器打开文件123.txt: 　nano 123.txt 2.打开文件的同时显示文件行数 　nano -c 123.txt 3.若编辑文件时提示“权限不够”，则在命令前加sudo 即： 　sudo nano 123.txt 4.保存使用nano编辑好的文件：键入Ctrl + o,然后 按下Enter键 　退出nano编辑器：键入Ctrl + x 其他常见Linux命令 命令名称 执行动作 备注 Alt + Tab键 切换活动窗口 Tab键 自动补齐 man [命令] 查看命令使用手册 ifconfig 查看当前网路连接状态以及IP地址 ping [IP地址]/[URL] 检测与某个IP地址是否连通 sudo raspi-config 打开树莓派配置界面 只针对树莓派系统 date 查看当前系统时间 date 011318172020.00 设置时间，格式为月日时分年.秒 ps -ax 显示当前运行的进程 kill -9 [进程号] 关闭某个进程 top 实时显示各个进程对资源的占用情况 passwd 设置用户密码 groups 显示当前用户所属组 clear 清空终端屏幕 uname -m 显示机器的处理器架构 which [命令] 在系统中搜索命令以确定该命令是否存在   © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-02-26 "},"content/chapter1/第3节 Web服务基础.html":{"url":"content/chapter1/第3节 Web服务基础.html","title":"第3节 Web服务基础","keywords":"","body":"第3节 Web服务基础 OSI七层网络模型 我们在后面的章节中会接触到很多和网络相关的内容，比如第三章的小车控制，是开发板作为服务器，使用手机等访问服务器，对小车进行运动控制，接收服务器传来的小车摄像头画面等。第六章通过物联网平台，控制机器人的姿态、语音交互、各种传感器数据的读取和处理等。 OSI（Open System Interconnect），即开放式系统互联。 一般都叫OSI参考模型，是ISO（国际标准化组织）组织在1985年研究的网络互连模型。是互联网最基本也是重要的知识。 ISO为了更好的使网络应用更为普及，推出了OSI参考模型。其含义就是推荐所有公司使用这个规范来控制网络。这样所有公司都有相同的规范，就能互联了。 OSI七层模型的划分 OSI定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），即ISO开放互连系统参考模型。如下图。 每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI的服务定义详细说明了各层所提供的服务。某一层的服务就是该层及其下各层的一种能力，它通过接口提供给更高一层。各层所提供的服务与这些服务是怎么实现的无关。 传输层协议：TCP、UDP 顾名思义，传输层主要的功能是传递信息。传输层建立了主机端到端的链接，我们通常说的，TCP UDP就是在这一层。端口号即是这里的“端”。端是由应用层来决定的。 我们在后面章节接触到的机器人或小车，我们也是通过TCP协议，通过访问IP地址和端口号，来与它们交换信息的。 应用层协议：HTTP、FTP、SMB 网络中的计算机是通过IP地址来代表其身份的，IP地址（公网IP）能表示某台特定的计算机，但是一台计算机上可以同时提供很多个服务，如数据库服务、FTP服务、Web服务等，我们就通过端口号来区别相同计算机所提供的这些不同的服务，如常见的端口号21表示的是FTP服务，端口号23表示的是Telnet服务端口。端口号80和443是http常用的端口。同学们可以在浏览器的地址栏尝试输入、，观察有无区别。一般来说，网址或IP地址后面如果不输入特定端口，默认是80端口。 Web服务器Apache与Nginx Apache是Apache软件基金会下的一个项目—Apache HTTP Server Project，Nginx同样也是一款开源的HTTP服务器软件。HTTP服务器软件本质上也是一种应用程序——它通常运行在服务器之上，绑定服务器的IP地址并监听某一个端口来接收并处理HTTP请求，这样客户端（一般来说是 IE, Firefox，Chrome这样的浏览器）就能够通过HTTP协议来获取服务器上的网页、文档、音频、视频等等资源。 安装与配置Nginx 我们后面使用的树莓派，运行的是Linux的一个重要的发行版Debian。在Debian操作系统，通过终端可以很方便地安装和部署Nginx服务器。 安装Nginx 打开终端 运行命令sudo apt install nginx 安装完毕后，运行sudo systemctl enable nginx，sudo systemctl start nginx 打开浏览器，输入树莓派的IP地址，看看是不是打开了一个Nginx的说明呢，这就表示我们安装成功了。其他同学可以通过访问你的树莓派IP地址，来看到你发布的内容了。网站的搭建是不是非常简单呢？ 使用WordPress或Typecho，发布个人网站 同学们如果对搭建个人网站感兴趣，可以了解一下以下三个网站系统，WordPress是基于PHP和MySQL的一个个人博客网站系统，Typecho是一个较为轻量级的个人博客网站系统。 Scratch与Blockly 这只可爱的小猫就是Scratch的吉祥物。Blockly和Scratch都是开源的网络程序。Scratch比Blockly更早诞生，到了Scratch 3.0，Scratch开始使用Blockly进行构建。我们可以比像部署WordPress或Typecho更容易来在服务器上部署Blockly和Scratch。 上图是Blockly的一个Demo。通过它，我们可以用积木的方式来控制小车和机器人、灯、甚至是电视机和空调。在后面的学习中，我们将深入地了解它们。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-24 "},"content/chapter1/第5节 认识硬件—树莓派.html":{"url":"content/chapter1/第5节 认识硬件—树莓派.html","title":"第5节 认识硬件—树莓派","keywords":"","body":"第5节 认识硬件—树莓派（Raspberry Pi） Raspberry Pi 4（树莓派4代） Raspberry Pi（树莓派）是早在2012年，由树莓派基金会发售的一台只有信用卡大小的电脑，他们发售树莓派的目的是给贫困地区的儿童一台廉价的用于学习编程的电脑，经过几年的迭代，树莓派已经到了第四代。(如上如所示)树莓派的详细硬件配置见于下表： 项目|参数 :-: | :-: |名称|Raspberry Pi4 (树莓派4)| |工作电压|3.3V 和 5v| |输入电压|5V| |GPIO数量|40 Pin | |支持的接口|I2C, SPI, UART| |主频|4核-1.4GHZ| |运行内存|4GB| |数据存储|64GB-TF卡| |外部接口|USBx4，网口，mini-HDMIx2，3.5mm音视频接口| |外部供电接口|Type-C 电压：5V| |供电方式|10000毫安移动电源| |操作系统|Raspbian (基于Debian定制的Linux操作系统)| |操作方式|接入显示器和键盘鼠标；局域网内使用VNC和远程桌面访问| 树莓派GPIO接口 GPIO（General-purpose input/output），即通用输入输出接口。树莓派的GPIO名称与功能如下表所示： GPIO 功能 3.3V 3.3V供电 (可为3.3V工作电压的设备提供电源，即电源正极) 5V 5V供电 (可为5V工作电压的设备提供电源，即电源正极) Ground(GND) 电源负极，且所有Ground相通，接在任意Ground皆可 注意 3.3V，5V与Ground引脚不可短接，否则会烧毁树莓派主板 GPIO2~GPIO27 可用于编程控制的GPIO口 输入电压 5V GPIO数量 40 Pin 支持的接口 I2C, SPI, UART 主频 4核-1.4GHZ 运行内存 4GB 数据存储 64GB-TF卡 外部接口 USBx4，网口，mini-HDMIx2，3.5mm音视频接口 外部供电接口 Type-C 电压：5V 供电方式 10000毫安移动电源 操作系统 Raspbian (基于Debian定制的Linux操作系统) 操作方式 接入显示器和键盘鼠标；局域网内使用VNC和远程桌面访问 注：树莓派系统的基本操作详见于本章“第二节 Linux基本操作” © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter1/第6节 认识硬件—Arduino.html":{"url":"content/chapter1/第6节 认识硬件—Arduino.html","title":"第6节 认识硬件—Arduino","keywords":"","body":"第6节 认识硬件—Arduino 1. Arduino UNO Arduino UNO 上搭载一块Atmel公司生产的AVR单片机，名称为ATmega328P。详细信息如下表所示 项目 参数 名称 Arduino UNO (ATmega328P) 工作电压 5V 输入电压 7V~12V 数字I/O引脚数量 14 Pin PWM通道 6 Pin 模拟I/O引脚数量 6 Pin 所有I/O口电流输出大小 20 mA Flash大小 32 KB SRAM 2 KB EEPROM 1 KB 时钟速度 16 MHz 板载LED灯控制引脚 13号数字I/O口 程序下载接口 USB 标准B型口 外部供电接口 5.2mm DC接口 程序编码与编译环境 Arduino IDE (IDE:集成开发环境) Arduino UNO 的各个接口和功能介绍，如下图所示： 程序烧录过程 在桌面上打开“Arduino IDE” (此集成开发环境已提前配置完整，直接使用即可)，如下图所示： 将Arduino UNO 通过USB线连接到电脑的USB口上，如下图： 通过Arduino IDE打开程序代码，如使13号接口连接的LED灯闪烁的程序：Blink 选择目标开发板：Arduino UNO,如下图： 选择开发板所在的物理端口，如下图： 点击下载按钮，Arduino IDE 开始编译源程序并把编译结果下载到开发板上；完成后，开发板上13号I/O口连接的LED会每隔一秒亮灭一次，如下图： 2. Arduino Nano Arduino Nano 与Arduino UNO 同样搭载一块Atmel公司生产的AVR单片机，名称为ATmega328P。只是与Arduino UNO 相比，Arduino Nano在同样搭载了USB程序下载接口，更多一些的I/O口的前提下，体积要小的多，这就为需要小体积控制板的项目提供了更多选择。详细信息如下表所示 项目 参数 名称 Arduino UNO (ATmega328P) 工作电压 5V 输入电压 7V~12V 特殊接口 原生支持USB接口 数字I/O引脚数量 22 Pin PWM通道 6 Pin 模拟I/O引脚数量 6 Pin 所有I/O口电流输出大小 40 mA Flash大小 32 KB SRAM 2 KB EEPROM 1 KB 时钟速度 16 MHz 板载LED灯控制引脚 13号数字I/O口 程序下载接口 Micro-USB接口 外部供电接口 5.2mm DC接口 程序编码与编译环境 Arduino IDE (IDE:集成开发环境) 注：Arduino Nano的程序烧写方法与Arduino UNO 相同。 3. Arduino Leonardo Arduino Leonardo 是一个搭载ATmega32u4的8位AVR单片机的开发板，其上同样有与Arduino UNO 相同的I/O口，唯一不同的是，ATmega32u4单片机支持原生的USB接口，并且可以通过程序控制，来讲此USB接口模拟成各类电脑USB外设，如鼠标，键盘，游戏手柄等等。详细信息如下图表格所示： |项目|参数| :-:|:-: |名称|Arduino Leonardo (ATmega32u4)| |工作电压|5V| |输入电压|7V~12V| |数字I/O引脚数量|14 Pin | |PWM通道|6 Pin| |模拟I/O引脚数量|8 Pin| |所有I/O口电流输出大小|40 mA| |Flash大小|32 KB| |SRAM|2 KB| |EEPROM|1 KB| |时钟速度|16 MHz| |板载LED灯控制引脚|13号数字I/O口| |程序下载接口|Mini-USB接口| |外部供电接口|5.2mm DC接口| |程序编码与编译环境|Arduino IDE (IDE:集成开发环境)| 注：Arduino Leonardo的程序烧写方法与Arduino UNO 相同 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter1/第7节 认识硬件—ESP8266.html":{"url":"content/chapter1/第7节 认识硬件—ESP8266.html","title":"第7节 认识硬件—ESP8266","keywords":"","body":"第7节 认识硬件—ESP8266 1. NodeMCU-Esp8266开发板 NodeMcu开发板上搭载了一颗国产32位WiFi SOC(片上系统)：ESP8266；也附带了TTL串口转USB芯片，可以直接通过Micro-USB线(安卓数据线)连接电脑，通过PC端的软件为其编译下载程序。由于ESP8266原生支持wifi,所以其在全球物联网领域大放异彩。详细参数如下表所示： 项目 参数 名称 NodeMcu(ESP8266) 工作电压 3.3V 输入电压 5V 数字I/O引脚数量 11 Pin 模拟I/O引脚数量 1 Pin 支持的接口 I2C, SPI, UART Flash大小 4MB 时钟速度 120 MHz 程序下载接口 Micro-USB接口 外部供电接口 VIN插针 电压为5V 程序编码与编译环境 Arduino IDE (IDE:集成开发环境) NodeMcu的Arduino引脚编号与芯片引脚编号的对应关系如下图所示： 给NodeMcu烧写程序 在本课程中我们使用Arduino IDE为NodeMcu烧写程序。 1.在桌面上打开“Arduino IDE” (此集成开发环境已提前配置完整，直接使用即可)，如下图所示： 2.将NodeMcu 通过Micro-USB线连接到电脑的USB口上，用Arduino IDE打开任意扩展名为“*.ino”程序。 选择目标开发板：\"NodeMcu 1.0(ESP-12e Module)\",如下图： 选择开发板所在的物理端口\"/dev/ttyUSB0\"，如下图： 点击下载按钮，Arduino IDE 开始编译源程序并把编译结果下载到开发板上. 2. Wemos D1-Esp8266开发板 Wemos D1与NodeMcu开发板具有相同的主控核心：Esp8266wifi模块，所以NodeMcu能实现的功能,Wemos D1也同样能实现，不同的是Wemos D1与Arduino UNO有相同的板型和接口，所以Arduino UNO上能用的扩展板或模块，Wemos D1也同样适用。Wemos D1的详细参数如下表所示： 项目 参数 主控核心 ESP8266 数字I/O数量 13 Pin 模拟I/O数量 1 Pin 复位按键(reset) 位于板左上角的微动开关(按一次主控重启，程序从头运行) 程序下载和低电流供电接口 Micro-USB 接口 外部供电接口 5.1mm DC接口 特殊功能 板载WiFi模块 Wemos D1烧写程序 Wwemos D1的程序烧写过程与NodeMcu大致相同，除要选择的板卡不同外，其他都相同。板卡选择如下图所示： © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter1/第8节 嵌入式系统软件开发流程.html":{"url":"content/chapter1/第8节 嵌入式系统软件开发流程.html","title":"第8节 嵌入式系统软件开发流程","keywords":"","body":"第8节 嵌入式系统软件开发流程 嵌入式系统定义：嵌入式系统（Embedded Systems）由硬件和软件组成．是能够独立进行运作的器件。其软件内容只包括软件运行环境及其操作系统。硬件内容包括信号处理器、存储器、通信模块等在内的多方面的内容。嵌入式系统软件开发流程框图： 嵌入式硬件平台 按照微处理器指令集类型来划分，分为复杂指令集（CISC，即Complex Instruction Set Computing）和精简指令集（RISC即Reduced Instruction Set Computing）。复杂指令集的处理器架构以x86和AMD64架构为主，主要应用在个人电脑，网站服务器等场景，复杂指令集的处理器的每条指令按顺序串行执行，控制相对简单，但速度相对较慢。精简指令集的处理器架构有ARM，AVR，MIPS等，这些架构各有特点；而在本次课程中用到的树莓派4开发板的处理器就属于ARM架构。本节主要以ARM架构为例讲解嵌入式系统软件开发流程。 嵌入式软件 嵌入式软件：嵌入式软件就是在嵌入式硬件中运行的操作系统和在嵌入式操作系统中的应用程序、驱动程序和应用程序等。 嵌入式操作系统 到目前嵌入式领域中的嵌入式操作系统有：Linux，Unix，Windows Embeded，VXWorks，RTOS等。而占据主要地位的是开源阵营的以Linux为核心的操作系统，如Android，Openwrt，Ubuntu，Debian，RedHat，CentOS等等。本次课程中用到的树莓派所用的操作系统就是以Debian为主深度优化的嵌入式操作系统：Raspbian，其系统核心仍然是Linux。 操作系统是如何被制作出来的 嵌入式ARM-Linux操作系统的结构 ARM-Linux操作系统由一下几部分构成： |名称|说明| :-:|:-: |Bootloader|引导加载器：这是一段裸机程序，能够在硬件上电后完成对硬件的检测，初始化各个硬件模块，主要功能是完成加载并引导操作系统启动的工作；常见的Botloader有U-boot，Bread，Grub，BIOS等| |Kernel|linux操作系统的内核：包含操作系统的各项功能，硬件的驱动等| |Rootfs|根问文件系统：根文件系统提供对文件的管理、对文件系统的支持，以及提供Linux系统下的标准目录结构(详见本章第二节：Linux基本操作)| 下图为嵌入式linux操作系统在存储设备上的分区结构图： 注：Boot Env分区为U-boot环境变量存储分区，引导操作系统启动所需的相关配置信息就存储在此分区内。 从源代码开始 由于Linux是开源操作系统，其源代码可以按照开源协议任意修改，也可以用于我们的嵌入式操作系统。操作系统的源码大多以C语言这种高级语言编写，所以从操作系统源代码开始，对源代码进行一定的“配置”，再通过编译器的“预处理”，“编译”，“汇编”，“链接”四步的深度加工，最后再经过固件打包工具的处理才能制作出能用的嵌入式操作系统。 由于嵌入式处理器大多为精简指令集(RISC)处理器，其处理能力相对PC端处理器较弱，不适合用来编译操作系统固件，所以我们要在X86平台上编译ARM架构处理器能执行的操作系统软件，这种编译方式称为“交叉编译”。 交叉编译的工具—交叉编译工具链 要把源代码制作成嵌入式操作系统的可烧写镜像(.img文件)，中间就需要交叉编译工具链(Toolchains)的操作，常用免费的的交叉编译工具链有： |编译器|作用| :-|:- |arm-none-linux-gnueabi-gcc|1. Codesourcery 公司基于GCC推出的的ARM交叉编译工具。2.用于交叉编译ARM(32位)系统中所有环节的代码，包括裸机程序、u-boot、Linux kernel、filesystem和App应用程序| |arm-linux-gnueabihf-gcc|1.Linaro公司基于GCC推出的的ARM交叉编译工具。2.用于交叉编译ARM(32位)系统中所有环节的代码，包括裸机程序、u-boot、Linux kernel、filesystem和App应用程序| |aarch64-linux-gnu-gcc|1.Linaro公司基于GCC推出的的ARM交叉编译工具。2.用于交叉编译ARMv8 64位目标中的裸机程序、u-boot、Linux kernel、filesystem和App应用程序| |arm-none-elf-gcc|1.Codesourcery公司基于GCC推出的的ARM交叉编译工具。2.用于交叉编译ARM MCU(32位)芯片，如ARM7、ARM9、Cortex-M/R芯片程序| |arm-none-eabi-gcc|1.GNU推出的的ARM交叉编译工具。2.用于交叉编译ARM MCU(32位)芯片，如ARM7、ARM9、Cortex-M/R芯片程序| 由于经交叉编译器处理U-boot、内核和根文件系统源码后只生成的其二进制文件，因此还需要将U-boot、内核(Kernel)和根文件系统(Rootfs)三者打包整合，最终生成可用的嵌入式操作系统固件(.img文件)。 嵌入式操作系统调试 TFTP和NFS远程挂载根文件系统 由于嵌入式开发板的存储设备容量较小，若交叉编译生成的系统镜像较大，每次将系统镜像烧写到板载存储设备中比较耗时，调试起来效率较低；因此，为避免这些问题，常使用TFTP和NFS远程挂载根文件系统的方式进行开发调试。步骤详见下表： |名称|配置步骤| :-:|:- |Linux PC端|1.配置并开启TFTP和NFS服务；2.设置有线网卡IP地址，使其与开发板网卡IP在同一网段；3.将编译好的内核镜像(Kernel.img)放入TFTP服务指定的目录下；4.将开发板可用的根文件系统放置于PC端的某个目录下| |开发板|1.开发板启动到支持网络的U-boot下；2.配置U-boot Env，使其IP地址与PC网卡IP在同一网段；2.配置U-boot Env,从tftp服务器获取并启动内核和从NFS服务器获取并挂载根文件系统；3.在U-boot的的命令行中键入启动命令，启动内核和挂载根文件系统。| 上图为通过NFS方式远程挂载根文件系统(Rootfs)并启动内核。 嵌入式Linux操作系统基本操作 通过SSH方式登录Linux系统 SSH：为安全外壳协议(Secure Shell);由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。下图为使用Putty通过SSH方式访问树莓派： xrdp:是Linux平台上的远程桌面的一种，通过在系统中开启此软件(服务)，就可以通过Windows操作系统中的“远程桌面”应用程序访问目标计算机的桌面，如下图所示： 如上图所示，在局域网中，只需在 “计算机” 文本框中填入目标计算机的IP地址，即可访问到远程计算机的桌面。若远程桌面访问起来比较卡顿，可通过修改“显示选项”来改善： 修改显示分辨率 修改网络传输类型 3.VNC：是第三方公司开发的远程桌面访问软件，树莓派官方系统直接对VNC服务端做了系统整合；只需在局域网的PC端安装“VNC Viewer”，即可通过此PC访问目标计算机在局域网中的IP地址来开启远程桌面。如下图所示： hyinn@live.com © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-24 "},"content/chapter2/第2章简介.html":{"url":"content/chapter2/第2章简介.html","title":"第2章 人工智能初体验","keywords":"","body":"第2章 人工智能初体验 本章主题：体验 学习者通过学习本章内容，将进一步了解人工智能和机器学习的发展历程、相关概念以及主要应用。此外，以样例体验的形式进行学习，学习者将对人工智能在图形图像和语言处理、电子游戏及其他领域的应用产生更加深刻的认识与理解。 本章重点 1 了解人工智能的基本概念和原理 2 了解卷积神经网络（CNN）以及深度神经网络（RNN）等的应用 涉及软硬件 PC 树莓派（Raspberry Pi） NVIDIA Jetson Nano © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-02-26 "},"content/chapter2/第1节 人工智能、机器学习的相关概念.html":{"url":"content/chapter2/第1节 人工智能、机器学习的相关概念.html","title":"第1节 人工智能、机器学习的相关概念","keywords":"","body":"第1节 人工智能、机器学习的相关概念 机器学习是人工智能研究发展到一定阶段的必然产物。 二十世纪五十年代到七十年代初，人工智能研究处于推理期，那时人们认为只要能赋予机器逻辑推理能力，机器就具有智能。 随着研究发展，在七十年代中期开始，人工智能研究进入了知识期，要使机器具有智能，就必须设法使机器拥有知识。此期间大量的专家系统面世。 在八十年代，从样例中学习（监督和无监督学习等）的一大主流是符号主义学习。其代表包括决策树(decision tree)和基于逻辑的学习。 九十年代中期之前，从样例中学习的另一主流技术是基于神经网络的连接主义学习。与符主义学习能产生明确的概念表示不同，连接主义学习产生的是黑箱模型。连接主义最大的局限是试错性：学习过程涉及大量参数，而参数的设置缺乏理论指导，主要靠手工调试。 九十年代中期，统计学习(statistical learning)登场。代表技术是支持向量机(support vector machine)。 二十一世纪初，连接主义通过深度学习卷土重来。所谓深度学习，即很多层的神经网络。在涉及语音、图像等复杂对象的应用中，深度学习取得了优越性能。深度学习虽然缺乏严格的理论基础，但是它显著降低了机器学习的门槛，为机器学习的实践带来了便利。 当前时代，互联网和硬件高度发达，人们进入了大数据时代，深度学习取得了大发展。随着物联网、边缘计算、5G网络、IPV6等的发展和普及，相信人工智能会在人类社会发挥更大的作用。 算法 机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中，经验通常以数据形式存在。因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生模型(model) 的算法。有了算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时，模型会给我们提供对应的判断。 数据集 要进行机器学习，先要有数据。假定我们收集了一批关于西瓜的数据，例如 {色泽=青绿；根蒂=蜷缩；敲声=浊响} {色泽=乌黑；根蒂=稍蜷；敲声=沉闷} {色泽=浅白；根蒂=硬挺；敲声=清脆} 这样的一组数据称为一个数据集(data set)，其中每条记录是关于一个事件或对象的描述，称为一个示例(instance)或样本(sample)。如果把每个样本中的色泽、根蒂和敲声作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可以在这个空间中找到自己的位置。当然，一般来说，维数越多，描述就会越精确。空间中每个点对应一个坐标向量，因此我们也把一个样本称为特征向量(feature vector) 训练 从数据中学得模型的过程称为学习(learning) 或训练(training)，这个过程通过执行某个算法来完成。训练过程中使用的数据称为训练数据(training data)，其中每个样本称为一个训练样本(training set)。学得的模型会对应关于数据的某种规律。 例如，如果希望学得一个能帮助我们判断一个西瓜是不是好瓜的模型，仅仅有前面的数据集是不够的。要建立关于预测(prediction)的模型，我们需要过得训练样本的结果信息: 例如{{色泽=青绿；根蒂=蜷缩；敲声=浊响}，好瓜} 这个关于结果的信息（好瓜）称为标记(label)。 分类、回归、聚类、监督与无监督学习 若我们预测的是离散值，例如好瓜、坏瓜，此类学习任务称为分类(classification) 若预测的是连续值，如西瓜成熟度0.95，0.37，此类学习任务称为回归(regression) 我们可以对西瓜做聚类(cluistering)。即将训练集中的西瓜分为若干做，每组称为一个簇(cluster) 例如，算法自动将数据集分成了3簇，用三种颜色代表。每一簇内较大的点代表核心对象，较小的点代表边界点。黑色的点代表离群点或者叫噪声点。 根据训练数据是否拥有标记信息（好瓜），学习任务可划分为两大类：监督学习(supervised learning)和无监督学习(unsuperviserd learning) 分类和回归是监督学习的代表。聚类是无监督学习的代表。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-02-26 "},"content/chapter2/第2节 知识图谱.html":{"url":"content/chapter2/第2节 知识图谱.html","title":"第2节 知识图谱","keywords":"","body":"第2节 知识图谱 知识图谱是由 Google 公司在 2012 年提出来的一个新的概念。从学术的角度，我们可以对知识图谱给一个这样的定义：知识图谱本质上是语义网络（Semantic Network）的知识库。 知识图谱在线体验 基于医药知识图谱的智能问答系统 这是一个集自然语言处理，统计机器学习和知识图谱，有关医药领域的初级自动问答系统。 该问答系统可以解析输入的自然语言问句生成相应的后台查询指令，进一步请求后台基于TDB知识库相关服务，进而得到问题的结果。 从实际应用的角度出发其实可以简单地把知识图谱理解成多关系图（Multi-relational Graph）。那什么叫多关系图呢？ 学图是由节点（Vertex）和边（Edge）来构成，但这些图通常只包含一种类型的节点和边。但相反，多关系图一般包含多种类型的节点和多种类型的边。比如左下图表示一个经典的图结构，右边的图则表示多关系图，因为图里包含了多种类型的节点和边。这些类型由不同的颜色来标记。 在知识图谱里，我们通常用 “实体（Entity）” 来表达图里的节点、用 “关系（Relation）” 来表达图里的 “边”。实体指的是现实世界中的事物比如人、地名、概念、药物、公司等，关系则用来表达不同实体之间的某种联系，比如人 -“居住在”- 北京、张三和李四是 “朋友”、逻辑回归是深度学习的 “先导知识” 等等。 现实世界中的很多场景非常适合用知识图谱来表达。 比如一个社交网络图谱里，我们既可以有 “人” 的实体，也可以包含 “公司” 实体。人和人之间的关系可以是 “朋友”，也可以是 “同事” 关系。人和公司之间的关系可以是 “现任职” 或者 “曾任职” 的关系。 类似的，一个风控知识图谱可以包含 “电话”、“公司” 的实体，电话和电话之间的关系可以是 “通话” 关系，而且每个公司它也会有固定的电话。 我们为什么需要知识图谱 当你看到下面这行文本时会想到什么？ Ronaldo Luís Nazário de Lima 估计绝大多数中国人不明白上面的文本代表什么意思。没关系，我们看看它对应的中文： 罗纳尔多・路易斯・纳萨里奥・德・利马 现在大多数人应该能够明白这是一个外国人的名字。熟悉足球的人可能会知道这是一个巴西足球运动员。 之所以举这样一个例子，是因为，计算机一直面临着这样的困境 —— 无法获取网络文本的语义信息。尽管近些年人工智能得到了长足的发展，在某些任务上取得超越人类的成绩，但离一台机器拥有一个两三岁小孩的智力这样一个目标还有一段距离。这距离的背后很大一部分原因是机器缺少知识。如同上面的例子，机器看到文本的反应和我们看到罗纳尔多葡萄牙语原名的反应别无二致。为了让机器能够理解文本背后的含义，我们需要对可描述的事物 (实体) 进行建模，填充它的属性，拓展它和其他事物的联系，即，构建机器的先验知识。就以罗纳尔多这个例子说明，当我们围绕这个实体进行相应的扩展，我们就可以得到下面这张知识图。 机器拥有了这样的先验知识，当它再次看到 Ronaldo Luís Nazário de Lima，它就会 “想”：“这是一个名字叫 Ronaldo Luís Nazário de Lima 的巴西足球运动员。” 这和我们人类在看到熟悉的事物，会做一些联想和推理是很类似的。 需要说明的是，上面的知识图这是一张草图，并不代表知识图谱的实际组织形式，相反，它还会让读者对知识图谱产生一定的误解。 Google 为了提升搜索引擎返回的答案质量，推出了知识图谱概念。有知识图谱的辅助，搜索引擎能够根据用户查询背后的语义信息，返回更准确、更结构化的信息。Google 知识图谱的宣传语 “things not strings” 道出了知识图谱的精髓：不要无意义的字符串，需要文本背后的对象或事物。 我们可以把知识图谱认为是一个知识库。比如在 Google 搜索引擎里输入 “Who is the wife of Bill Gates?”，我们直接可以得到答案 -“Melinda Gates”。这是因为我们在系统层面上已经创建好了一个包含 “Bill Gates” 和 “Melinda Gates” 的实体以及他俩之间关系的知识库。所以，当我们执行搜索的时候，就可以通过关键词提取（\"Bill Gates\", \"Melinda Gates\", \"wife\"）以及知识库上的匹配可以直接获得最终的答案。这种搜索方式跟传统的搜索引擎是不一样的，一个传统的搜索引擎它返回的是网页、而不是最终的答案。我们只能得到包含这个关键词的网页，然后不得不点击进入相关网页查找需要的信息，所以就多了一层用户自己筛选并过滤信息的过程。 知识图谱的前世今生 通过上面这个例子，大家应该对知识图谱有了一个初步的印象，其本质是为了表示知识。 其实知识图谱的概念并不新，它背后的思想可以追溯到上个世纪五六十年代所提出的一种知识表示形式 —— 语义网络 (Semantic Network)。语义网络由相互连接的节点和边组成，节点表示概念或者对象，边表示他们之间的关系 (is-a 关系，比如：猫是一种哺乳动物；part-of 关系，比如：脊椎是哺乳动物的一部分)，如下图。在表现形式上，语义网络和知识图谱相似，但语义网络更侧重于描述概念与概念之间的关系，（有点像生物的层次分类体系 —— 界门纲目科属种），而知识图谱则更偏重于描述实体之间的关联。 知识抽取 知识图谱的构建是后续应用的基础，而且构建的前提是需要把数据从不同的数据源中抽取出来。对于垂直领域的知识图谱来说，它们的数据源主要来自两种渠道：一种是业务本身的数据，这部分数据通常包含在公司内的数据库表并以结构化的方式存储；另一种是网络上公开、抓取的数据，这些数据通常是以网页的形式存在所以是非结构化的数据。 前者一般只需要简单预处理即可以作为后续 AI 系统的输入，但后者一般需要借助于自然语言处理等技术来提取出结构化信息。比如在上面的搜索例子里，Bill Gates 和 Malinda Gate 的关系就可以从非结构化数据中提炼出来，比如维基百科等数据源。 知识图谱的存储 知识图谱主要有两种存储方式：一种是基于 RDF 的存储；另一种是基于图数据库的存储。它们之间的区别如下图所示。 在知识图谱中我们用 RDF 形式化的表示这种三元关系。RDF，Resource Description Framework，资源描述框架，是 W3C 制定的一种用于描述实体 / 资源的标准数据模型。RDF 中有三种类型：IRI、blank node 和 literals，常用的是 IRI 和 literals。 IRI，International Resource Identifier，可以看做是 URI 或 URL 的泛化，用于在整个知识图谱中唯一的表示一个实体 / 资源。 literals，字面量，可以看做是带有数据类型的纯文本，比如罗纳尔多的全名是 Ronaldo Luís Nazário de Lima 这个字面量可以表示为： Ronaldo Luís Nazário de Lima\"^^xsd:string 那么，“罗纳尔多的中文名是罗纳尔多・路易斯・纳扎里奥・达・利马” 这个 SPO 三元组用 RDF 形式表示就是： http://www.kg.com/person/1 kg:fullName \"Ronaldo Luís Nazário de Lima\"^^xsd:string 将上面的知识图用更正式的形式画出来： © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-13 "},"content/chapter2/第4节 卷积神经网络—CNN.html":{"url":"content/chapter2/第4节 卷积神经网络—CNN.html","title":"第4节 卷积神经网络—CNN","keywords":"","body":"第4节 卷积神经网络—CNN 卷积神经网络（Convolutional Neural Networks, CNN）是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习（deep learning）的代表算法之一。卷积神经网络具有表征学习（representation learning）能力，能够按其阶层结构对输入信息进行平移不变分类（shift-invariant classification），因此也被称为“平移不变人工神经网络（Shift-Invariant Artificial Neural Networks, SIANN） 在线体验 点击CNN可视化或全连接CNN可视化来进行可视化CNN体验 Tensorflow训练自定义图片分类器 使用Tensorflow深度学习框架按类别训练图像。我们将使用狗狗的图片进行模型训练，测试图片分类器对狗的品种的识别。 环境准备 1.在资源管理器中打开learn-ai\\codes\\chapter1\\part4_CNN\\DogsBreedClassification。下载数据库和模型文件，解压到项目文件夹中。 2.Windows用户打开Anaconda Prompt，macOS用户打开终端 3.输入下面的命令来进入learn-ai环境 conda activate learn-ai 4.安装额外的软件包 conda install bleach conda install html5lib conda install pandas conda install python-dateutil 5.切换工作路径到项目文件夹 //Windows cd C:\\learn-ai\\codes\\chapter1\\part4_CNN\\DogsBreedClassification //macOS cd ~/Desktop/learn-ai/codes/chapter1/part4_CNN/DogsBreedClassification 程序及操作 1.整理训练数据文件夹 运行数据处理程序data_processing.py来通过狗品种名称重新排列文件夹 python data_processing.py 2.使用处理好数据训练模型 运行以下命令以使用 CNN 架构训练模型。 默认情况下，脚本下方将下载 Google 的初始架构 -'inception-2015-12-05.tgz' python retrain.py — image_dir=dataset/ — bottleneck_dir=bottleneck/ — how_many_training_steps=500 — output_graph=trained_model/retrained_graph.pb — output_labels=trained_model/retrained_labels.txt — summaries_dir=summaries 以下是程序的输出 上述训练模型的 Tensorboard 精度图 要运行 TensorBoard，请运行此命令 User:/dogs_breed_classification$ tensorboard — logdir summaries/ — host=0.0.0.0 — port=8888 TensorBoard 1.7.0 at http://0.0.0.0:8888 (Press CTRL+C to quit)# 3.测试模型 运行下面的 python 脚本，根据我们预先训练的模型对测试图像进行分类。 python classify.py 你可以跳过上面教程中的第2步，直接使用提供的预训练模型（trained_model /retrained_graph.pb）来测试模型。 图像风格迁移 在神经网络之前，图像风格迁移的程序有一个共同的思路：分析某一种风格的图像，给那一种风格建立一个数学或者统计模型，再改变要做迁移的图像让它能更好的符合建立的模型。这样做出来效果还是不错的，但一个很大的缺点：一个程序基本只能做某一种风格或者某一个场景。因此基于传统风格迁移研究的实际应用非常有限。 而 Neural Style 程序通过输入一张代表内容的图片和一张代表风格的图片，使用深度学习网络输出一张融合了这个风格和内容的新作品。 环境准备 1.VGG网络 训练好的 VGG 19 网络，下载到项目文件夹“Neural Style 图像风格迁移”的中，或在运行时使用参数 --network 指定其位置。 2.Pillow conda activate learn-ai conda install pillow 程序及操作 python neural_style.py --content --styles --output -- --iterations 我们使用 examples 文件夹中的 1-content.jpg 和 2-style1.jpg 来举例，把上面命令中： 替换为 examples/1-content.jpg 替换为 examples/2-style1.jpg 替换为 examples/output.jpg，当然也可以不叫output，使用你自己喜欢的名字； 替换为 100 替换后的命令为： python neural_style.py --content examples/1-content.jpg --styles examples/2-style1.jpg --output examples/output.jpg -- --iterations 100 不建议使用过大的图片，这会明显的增加机器的负担，特别是对于性能差或者没有独立显卡的机器，可能需要数个小时来生成新的图片。 在课程中使用的是 100 次迭代，可以初步看出机器风格迁移的效果。一般来说 1000 次迭代可以获得不错的图像质量，但会花费更多的时间。 当窗口中的迭代次数变为 “100/100” 时就完成了整个图片的处理过程，打开examples文件夹中的图片就可以开到结果。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter2/第5节 循环神经网络—RNN.html":{"url":"content/chapter2/第5节 循环神经网络—RNN.html","title":"第5节 循环神经网络—RNN","keywords":"","body":"第5节 循环神经网络—RNN RNN（Recurrent Neural Network）是一类用于处理序列数据的神经网络。首先我们要明确什么是序列数据，摘取百度百科词条：时间序列数据是指在不同时间点上收集到的数据，这类数据反映了某一事物、现象等随时间的变化状态或程度。这是时间序列数据的定义，当然这里也可以不是时间，比如文字序列，但总归序列数据有一个特点——后面的数据跟前面的数据有关系。 语音助手 当你用小米手机呼叫小爱同学，让她帮你设定闹钟的时候，实际发生的事情如下 步骤： 将用户的语音转化为文字 分析文字内容，进行填槽（Slot Filling） 根据填槽结果，执行命令 反馈结果到界面 这里的Slot Filling，中文称为填槽，将句子的内容的文字填写到正确的槽中，这个过程就是循环神经网络实现的。 文字情感分析、关键词提取 利用循环神经网络生成古诗词 1.打开项目文件夹learn-ai/codes/chapter1/part5_RNN/PoetAI 其中， poetry.txt内包含了大量的古诗词 poet_rnn.py用来训练模型 poet_rnn_output用来生成古诗词 2.打开Anaconda Prompt，执行： conda activate learn-ai //Windows cd C:\\learn-ai\\codes\\chapter1\\part5_RNN\\PoetAI //macOS cd ~/Desktop/learn-ai/codes/chapter1/part5_RNN/PoetAI python poet_rnn.py 执行后将会开始进行模型训练。 3.待模型训练完毕后，会在当前目录下生成模型文件poetry.module-49 使用VS Code编辑器打开poet_rnn_output.py，在最后一行： print(gen_poetry_with_head_and_type(\"深度学习\", 7)) 将会生成以深度学习四个字开头的七言藏头诗。尝试将文字替换为其他，7可以替换为5，即生成五言诗。保存后执行： python poet_rnn_output.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter2/第6节 人工智能与游戏—DQN.html":{"url":"content/chapter2/第6节 人工智能与游戏—DQN.html","title":"第6节 人工智能与游戏—DQN","keywords":"","body":"第6节 人工智能与游戏—DQN DeepMind《Playing Atari with Deep Reinforcement Learning》提出了强化学习算法（DQN），DQN使用卷积神经网络作为价值函数来拟合Q-learning中的动作价值，这是第一个直接从原始像素中成功学习到控制策略的深度强化学习算法。DQN 模型的核心就是卷积神经网络，使用Q-learning 来训练，其输入为原始像素，输出为价值函数。在不改变模型的架构和参数的情况下，DQN在七个Atari2600游戏上，击败了之前所有的算法，并在其中三个游戏上，击败了人类最佳水平。 Flappy Bird 1.打开项目文件夹learn-ai/codes/chapter1/part6_DQN/DeepLearningFlappyBird 2.打开Anaconda Prompt，进行训练： conda activate myenv //Windows cd C:\\\\learn-ai\\\\codes\\\\chapter1\\\\part6_DQN\\\\DeepLearningFlappyBird //macOS cd ~/Desktop/learn-ai/codes/chapter1/part6_DQN/DeepLearningFlappyBird python deep_q_network.py 3.预先训练好的模型： python deep_q_network_trained.py 进化算法超级马里奥 这种学习方式称之为神经网络进化拓扑结构（NeuroEvolution of Augmenting Topologies，简称NEAT） 实际进化过程中，超级马里奥并不会进行预测以改变其行动。通过进行不同的尝试，而不是做其“应该”做的事情，这样每次都会产生新的点子。当一个点子成功后，就会被记住，反之则被作废。就这样，超级马里奥在经历了34尝试后，完全通关了！当然，如果重新运行的话，这套AI机会肯定可以找到一条不同但不会更加成功的线路。 1.打开项目文件夹learn-ai/codes/chapter1/part6_DQN/SuperMario 2.双击打开EmuHawk.exe 3.载入游戏文件 点击左上角的File——Open ROM，然后选择项目目录下的Super Mario World(USA).sfc 4.载入游戏存档文件 点击左上角的File——Load State——Load Named State，然后选择Lua目录下的DP1.State 5.载入算法文件 点击左上角的Tool——Tool Box，选择Lua Console。在新窗口中点击Script——Open Script，选择项目目录下的neatevolve.lua 6.观察游戏的自我进化过程 思考游戏进化的过程和生物进化的异同 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter3/第3章简介.html":{"url":"content/chapter3/第3章简介.html","title":"第3章 硬件基础—智能小白","keywords":"","body":"第3章 硬件基础—智能小白 本章主题：了解硬件操作 主要使用ESP8266提供Web服务，来控制电机、舵机、传感器等，实现远程遥控、控制机械臂抓取、远程视频监控等功能。可以通过积木编程的方式来对小车的功能进行编程。 本章重点 1 了解开源硬件和电路、网络的基础知识 2 掌握一定的通过开源硬件解决实际问题的能力 涉及软硬件 ESP8266，ESP32-CAM 小车套件（可3D打印） 舵机，灰度传感器、超声波传感器等 自行开发的物联网控制平台 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter3/第1节 小白的心脏—esp8266开发板.html":{"url":"content/chapter3/第1节 小白的心脏—esp8266开发板.html","title":"第1节 小白的心脏—esp8266开发板","keywords":"","body":"第1节 小白的心脏—esp8266开发板 熟悉操作esp8266的步骤。是第一章的基础 包括功能提出和实现，硬件连接，上传的参数调节和html文件在本地服务器中的打开，传感器数据的实时呈现等，并使用Chart.js来绘制实时变化曲线 这部分主要包括两种传感器的读取，为温湿度传感器和超声波传感器 活动目标 了解物联网的基本概念 了解使用开发板读取传感器的基本原理 熟悉使用Arduino IDE烧录固件的操作流程 背景知识：物联网 原理图 传感器-->小白: WiFi/GPIO 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.提交执行动作请求，如“前进” 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 esp8266是WiFi串口模块，功能简单来讲就是：从WiFi接收到数据，串口输出；从串口接收数据，WiFi输出数据。 通过自带的GPIO口连接传感器，传感器将环境数据转化为电信号发送给esp8266读取、处理并输出。 硬件准备 硬件清单 ESP8266主板 温湿度传感器（型号为DHT11或DHT22） 超声波传感器（型号为HC-SR04） 杜邦线、数据线 实验1：简单温湿度数据读取 1.硬件连接 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part1_Sensor/esp8266_dht11_http2).将esp8266通过数据线连接到电脑3).使用Arduino IDE打开文件esp8266_dht11_http.ino4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 3.读取温湿度传感器数据 1).打开路由器管理地址，esp8266此时应该已经加入到了局域网中，查看esp8266获取到的路由器地址2).在浏览器中打开esp8266获取到的局域网地址，查看温湿度传感器的读数3).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 实验2：温湿度实时变化曲线绘制 1.硬件连接 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part1_Sensor/esp8266_dht11_http_chartjs2).将esp8266通过数据线连接到电脑3).使用Arduino IDE打开文件 esp8266_dht11_http_chartjs.ino4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 3.读取温湿度传感器实时曲线 1).打开路由器管理地址，esp8266此时应该已经加入到了局域网中，查看esp8266获取到的路由器地址2).在浏览器中打开esp8266获取到的局域网地址，查看温湿度传感器的读数3).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 实验3：超声波距离测量 1.硬件连接 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part1_Sensor/esp8266_ultrasonic_http2).将esp8266通过数据线连接到电脑3).使用Arduino IDE打开文件 esp8266_ultrasonic_http.ino4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 3.超声波传感器数据读取 1).打开路由器管理地址，esp8266此时应该已经加入到了局域网中，查看esp8266获取到的路由器地址2).在浏览器中打开esp8266获取到的局域网地址，查看距离传感器的读数3).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter3/第2节 无线控制—遥控小车.html":{"url":"content/chapter3/第2节 无线控制—遥控小车.html","title":"第2节 无线控制—遥控小车","keywords":"","body":"第2节 无线控制—遥控小车 使用esp8266开发板，组装并遥控一辆小车，通过网页端发送命令来遥控它 活动目标 了解HTTP通信概念 体验使用开发板控制电机 学会使用ip地址访问服务器 背景知识：电机 电机一般用作小车的动力系统。当电机接上正向电压时，电机会正转，当电机接上反向电压时，电机会反转。当电机接上的电压不同时，电机转动的速度也会有所不同。由于开发板能提供给小车的电压有限，所以我们通常不会直接将电机接在开发板上，而是会找一块电机驱动扩展板。 原理图 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.提交执行动作请求，如“前进” 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 硬件清单 小车套件(底盘和夹层，电机，车轮，万向轮，铜柱等) esp8266开发板 电机扩展板 杜邦线，数据线 移动电源 实验：WiFi小车 1.硬件连接 将两个车轮分别与电机相连 使用理线带，将电机和万向轮固定在底盘上 使用铜柱，增加一层夹层 将esp8266开发板和电机扩展板如图相连，将电机连接到图示位置。 使用数据线连接esp8266开发板和移动电源，将移动电源置于小车夹层并加以固定 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part2_WiFiCar/esp8266_wificar_http 2).将esp8266通过数据线连接到电脑3).使用Arduino IDE打开文件esp8266_wificar_http.ino4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 5).点击工具菜单，选择esp8266 Sketch Data Upload,会自动将项目目录下的data文件夹上传到esp8266开发板上 3.开始无线控制 1).打开路由器管理地址，esp8266此时应该已经加入到了局域网中，查看esp8266获取到的路由器地址2).将esp8266与电脑连接断开，连接到移动电源上3).在浏览器中打开esp8266获取到的局域网地址，通过点击上下左右按钮或键盘的光标键来控制小车4).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter3/第3节 汽车人小白—机械臂.html":{"url":"content/chapter3/第3节 汽车人小白—机械臂.html","title":"第3节 汽车人小白—机械臂","keywords":"","body":"第3节 汽车人小白—机械臂 使用esp8266，通过网页端发送命令，控制多个舵机 活动目标 了解舵机的基本概念 了解使用开发板控制动力设备的基本原理 熟悉使用Arduino IDE烧录固件的操作流程 背景知识：舵机 伺服电机通常被称为舵机，它是一种带有输出轴的小装置。当我们向伺服器发送一个控制信号时，输出轴就可以转到特定的位置。只要控制信号持续不变，伺服机构就会保持轴的角度位置不改变。如果控制信号发生变化，输出轴的位置也会相应发生变化。日常生活中，舵机常被用于遥控飞机、遥控汽车、机器人等。 舵机内部的控制电路、电位计（可变电阻器）和电机均被连接到电路板上。控制电路通过电位计可监控舵机的当前角度。 其工作流程为：控制信号 → 控制电路板 → 电机转动 → 齿轮组减速 → 舵盘转动 → 位置反馈电位计 → 控制电路板反馈。 1.脉冲宽度调制（PWM） 脉冲宽度调制，英文名Pulse Width Modulation，缩写为PWM，它是通过对一系列脉冲的宽度进行调制，等效出所需要的波形，对模拟信号电平进行数字编码。 2.占空比 占空比是指在一个周期内，信号处于高电平的时间占据整个信号周期的百分比。 上图信号一个周期的时间为4ms，其中高电平时间为1ms。占空比为： 原理图 舵机机械臂->小白: GPIO 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.提交执行舵机角度请求 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 硬件清单 esp8266主板 电机扩展板 esp12E Motor Shield 舵机 杜邦线、数据线 机械臂和零件 实验：机械臂 1.硬件连接 此处表示舵机连接到了D0口，最多可以连9个舵机（D0-D9） 黄色-信号D（DATA） 红色-正极V（VCC） 棕色-负极G（GND） 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part3_ServoArm/esp8266_servoarm_http 2).将esp8266通过数据线连接到电脑 3).使用Arduino IDE打开文件esp8266_servoarm_http.ino 4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 5).点击工具菜单，选择esp8266 Sketch Data Upload,会自动将项目目录下的data文件夹上传到esp8266开发板上 3.开始机械臂控制 1).打开路由器管理地址，esp8266此时应该已经加入到了局域网中，查看esp8266获取到的路由器地址2).将esp8266与电脑连接断开，连接到移动电源上 3).在浏览器中打开esp8266获取到的局域网地址，通过拖动滑块来控制机械臂 4).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter3/第4节 视物而行—远程视频救援.html":{"url":"content/chapter3/第4节 视物而行—远程视频救援.html","title":"第4节 视物而行—远程视频救援","keywords":"","body":"第4节 视物而行—远程视频救援 也许，你会希望在小车上装一个摄像头，这样就可以身临其境的遥控它了。 esp32是esp8266的升级版本。拥有更强的处理能力，能够很好的处理实时视频和音频等数据。通过本部分来为小车增加实时视频的功能 活动目标 确定活动方向并提出需要解决的问题 了解esp32的功能及引脚并熟练了解实验步骤 按照操作步骤实际操作并完成小车实时摄像等相关功能 对实验进行总结，并分析遇到的问题 背景知识：ESP32 esp32是一系列低成本，低功耗的片上 微控制器系统，集成了Wi-Fi和双模蓝牙。esp32包括双核和单核变体，包括内置天线开关，功率放大器，低噪声接收放大器，滤波器和电源管理模块。 原理图 舵机机械臂->小白: GPIO 摄像头->小白: WiFi 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.查看实时画面，提交控制请求 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 硬件清单 esp32主板 ov2640摄像头 USB转TTL编程器 杜邦线 双自由度舵机云台 实验：远程救援车 1.硬件连接 注意：IO0口需要和它边上的GND口用一根杜邦线连接到一起，这样才可以正常上传代码 2.烧录程序到开发板esp32 1).打开项目文件夹learn-ai/codes/chapter3/part4_FirstAid/esp32_camerawebserver 2).将上图连接好后，将USB转TTL编程器插入电脑3).使用Arduino IDE打开文件esp32_camerawebserver.ino4).配置esp32的上传环境如下图所示： 5).上传完毕后，保持USB连接在电脑上。将IO0口需要和它边上的GND口杜邦线拔掉，按一下esp32主板上面的reset键 3.烧录程序到开发板esp8266 1).打开项目文件夹learn-ai/codes/chapter3/part4_FirstAid/esp8266_firstaid_http 2).将esp8266通过数据线连接到电脑 3).使用Arduino IDE打开文件esp8266_firstaid_http.ino 4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 5.点击工具菜单，选择esp8266 Sketch Data Upload,会自动将项目目录下的data文件夹上传到esp8266开发板上 4.远程视频救援控制 1).打开路由器管理地址，esp32此时应该已经加入到了局域网中，查看esp32和esp8266获取到的路由器地址2).在浏览器中打开esp32获取到的局域网地址，在左侧最下方选择Start Stream 3).访问救援控制页面，将esp32的ip地址填入对应位置 4).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter4/第4章简介.html":{"url":"content/chapter4/第4章简介.html","title":"第4章 机器视觉—自动追踪小车大白","keywords":"","body":"第4章 机器视觉—自动追踪小车大白 本章主题：机器视觉 从机器视觉出发，让学生理解机器视觉的相关概念和原理，辨别OpenCV和深度学习的异同点。使用OpenCV来处理视觉信号，并通过蓝牙或串口来将处理过的视觉信号发送给小车，从而实现物体追踪，人脸追踪，智能机械臂抓取等功能。 学生通过使用Python，完成信息采集：爬虫、多文件处理；信息处理：训练采集的数据，形成分类器，从而让计算机视觉系统能够对特定的物体进行分辨。 本章重点 了解计算机视觉的相关概念和原理 了解OpenCV和深度学习的关系和区别 了解Python在图像处理方面的一些基本操作 了解模式识别，会训练分类器，并使用开源硬件来对图像处理结果做简单的反馈 涉及软硬件 树莓派、Arduino 舵机、CSI摄像头、电磁传感器 小车套件 3D打印机 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter4/第1节 借我一双慧眼吧.html":{"url":"content/chapter4/第1节 借我一双慧眼吧.html","title":"第1节 借我一双慧眼吧","keywords":"","body":"第1节 借我一双慧眼吧 OpenCV的全名是Open Source Computer Vision Library。它是一个计算机视觉库，通过使用它，可以对计算机图像进行各种各样的处理。 从茹毛饮血的蛮荒，到钢筋水泥的城市，人类逐步将自身能力投射到计算机上。无论是计算能力，还是记忆能力，计算机的如今表现都堪称卓越。但仅拥有这些还远远不够，我们期待计算机可以做得更多。一部风靡全球《星际穿越》激起了无数人对探索浩瀚宇宙奥秘的渴望，也让许多人记住了Tars这个聪明可爱、幽默风趣的智能机器人。人工智能主题的好莱坞电影一直广受影迷们的喜爱，人类用无尽的想象力和炫目的特技构筑了一个又一个无比精彩的未来世界，令人如痴如醉。不过，回到现实，计算机科学家们的行动力却看似远远赶不上电影艺术家们的想象力，电影终归是电影，要研发出一个像Tars一样能看懂周围世界、听懂人类语言、并和人类进行流畅对话的智能机器人，我们要走的路还有很长。 长时间来，让计算机能看、能听、能说一直是我和计算机界同行们孜孜以求的目标。耕耘在计算机视觉领域十余年，赋予计算机一双慧眼，让它也能看懂这个多彩的世界，一直是激励着我在这条充满挑战的道路上前行的重要力量。虽然计算机暂时还无法像电影中所展现的那般智能，但已经取得了很多令人惊喜的成绩。在这篇文章中，我将就如何让计算机能“看”懂世界这个主题，为大家介绍计算机视觉的基本概念、这个领域面临的挑战、一些带来重要突破的技术并展望未来的演进趋势。 世界如何在我们眼中形成 对人类而言，“认人”似乎是与生俱来的本能，刚出生几天的婴儿就能模仿父母的表情；它赋予我们只凭极少细节就分辨彼此的能力，借着暗淡灯光我们仍能认出走廊那端的朋友。然而，这项对人类而言轻而易举的能力，对计算机而言却举步维艰。过去很长一段时间，计算机视觉技术徘徊不前，在进一步探求前，不如先谈谈我们是如何用眼睛观察世界的。 相信大家都在中学的物理课上尝过小孔成像的原理。不过人的眼睛要比小孔成像复杂得多，当我们观察物体时，每秒大约扫视3次，并有1次驻留。当视网膜的感光体感受到蜡烛的轮廓，一个被称为中央凹的区域其实是以扭曲变形的形式记录下蜡烛的形状。 那么问题来了，为何我们看到的世界既未扭曲也没有变形呢？很简单，因为人类拥有大脑皮层这个万能的“转换器”，它将我们的视觉神经捕捉到的信号转换为真实的形象。这个“转换器”可简化理解为四个区域，生物学家将它们分别称为V1、V2、V4和IT区。V1区的神经元，只针对整个视觉区域中很小的一部分做出反应，例如，某些神经元发现一条直线，就变得异常活跃。这条直线可以是任何事物的一部分，也许是桌边，也许是地板，也许是这篇文章某个字符的笔划。眼睛每扫视一次，这部分神经元的活动就可能发生快速变化。 奥秘出现在大脑皮层顶层的IT区，生物学家发现，物体在视野的任何地方出现（例如一张脸），某些神经元会一直处于固定的活跃状态中。也就是说，人类的视觉辨识是从视网膜到IT区，神经系统从能识别细微特征，到逐渐变为能识别目标。如果计算机视觉也可以拥有一个“转换器”，那么计算机识别的效率将大为提高，人眼视觉神经的运作为计算机视觉技术的突破提供了启迪。 计算机为何总是“雾里看花” 尽管人眼识别的奥秘已经被逐步揭开，但直接应用于计算机上却非易事。我们会发现计算机识别总是在“雾里看花”，一旦光线、角度等发生变化，计算机难以跟上环境的节奏，就会误识。对计算机而言，识别一个在不同环境下的人，还不如识别在同一环境下的两个人来得简单。这是因为最初研究者试图将人脸想象为一个模板，用机器学习的方法掌握模板的规律。然而人脸虽然看起来是固定的，但角度、光线、打扮不同，样子也有差别，都令简单的模板难以匹配所有人脸。 因此，人脸识别的核心问题在于，如何让计算机忽略同一个人的内部差异，又能发现两个人之间的分别，即让同一个人相似，不同的人有别。 对人工神经网络的引进是计算机视觉超越模板识别的关键。然而人类尚且未完全掌握神经的运作机制时，又该如何引导计算机进步呢？人工神经网络在1960年代就已萌芽，初期理论只固定在简单的模型之上，即生物课上的“输入-隐层-输出”模型。在介绍神经的工作原理时，老师们一般都会简单告知是外界刺激接触到输入神经元，输入神经元再链接其他部分形成隐层，最后通过输出神经元表现出来。这些神经元的链接强度并不相同，就像不同乐谱的强弱高低不同，人工神经网络就是依靠这些神经元之间不同的链接强度，学会将输入方式映射到输出上。 不过“乐谱”只是静止不动的，而且只能从“输入走向输出”，不存在反向呈现。也就是说如果人静止不动，计算机也许可以通过这一原理读出，但这在现实生活中不可能实现。1980年代末期，用于人工神经网络的“反向传播算法”发明，它能将输出单元的错误传回输入单元，并记住它。这种方法令人工神经网络能从大量训练样本中学习统计规律，对未知事件做出预测。不过与大脑的复杂及层级结构相比，这种只包含一个隐层的神经网络构造还显得微不足道。 深层神经网络为计算机“拨云见日” 2006年，多伦多大学教授Geoffrey Hinton在深层神经网络的训练上取得了突破。一方面，他证明了多隐层的人工神经网络具备更优异的特征学习能力，另一方面能通过逐层初始化克服此前一直困扰研究者的训练难题——基本原理是先通过大量无监督数据保证网络初始化，再用有监督数据在初始化好的或者是预训练的网络上优化调整。 受到这些因素的启发，如今的人脸或图像识别研究，大多基于CNN（Convolution Neural Networks）原理。CNN可以被视为一种逐层扫描的“机器”。第一层检测边缘、角点、平坦或不平坦的区域，这一层几乎不包含语义信息；第二层基于第一层检测的结果进行组合，并将组合传递给下一层，以此类推。多层扫描之下，累加准确率，计算机就在向前文提及的“让同一个人相似，不同的人有别”这一目标迈进。 CNN的学名为带有卷积结构的深度神经网络，这一网络识别物体还可分为两个步骤：图像分类和物体检测。在第一个阶段，计算机首先识别出物体的种类，例如人、动物或其他物品；第二个阶段，计算机获取物品在图像中的精确位置——这两个阶段分别回答了“是什么”和“在哪里”两个问题。微软的智能聊天机器人“小冰”具有辨识狗的品种的能力即是CNN的典型示例。首先，需要搭建一个好几层深度卷积网络。第一层跟人类视觉系统的定义很像，用来对一些小的边缘或者小的色块做一些检测；第二层会把这些小的结构组成大的结构，如狗腿和狗的眼睛；依次向上进行组织，最后就能鉴别出狗的种类来。其次，需要往这个带有卷积结构的深度神经网络里投入很多的图，训练系统识狗的准确度。 2013年，加州大学伯克利分校的研究者们提出了一种称为叫R-CNN方式（Region-based CNN）的物体检测方法，具有很高的识别准确度，它将每张图像分为多个窗口或个子区，在每个子区域应用神经网络进行分类。但其主要缺陷在于，对于实时检测，算法过慢。为了在一张图片上检测几个物体，整个神经网络可能需要运算上千次。 在微软亚洲研究院，视觉计算组的研究员们实现了一种称为空间金字塔聚合（Spatial Pyramid Pooling，SPP）的新算法，通过在内部特征识别，而不是每个区域从头检测，对整个图片只做一次计算。利用这种新算法，在不损失准确度的前提下，物体检测速度有了上百倍的提升。在2014年ImageNet大规模视觉识别挑战赛中，微软亚洲研究院采用SPP算法的系统取得了分类第三名和检测第二名的成绩。目前，这项技术已经成功转化进入OneDrive中。采用了这项技术后，OneDrive可以自动为上传的图片添加标签。同时，用户输入关键词，就可以搜索与之相对应的图片。 展望未来 计算机视觉和人类共舞 如果单纯识别面部，而不考虑发型和身体的其他部分，人类的正确率约为97.5%，而计算机目前则能达到99%以上。这是否意味着计算机已经胜过了人类？不是，因为我们不只观察面部，身材和体态都有助于我们认出对方。在复杂光照的真实环境下，人能够更智能地选择这些分支帮助自己决策，而计算机在这方面则要逊色许多。不过，如果数据量庞大，或者面对陌生的脸孔，计算机又更强大些。如果能够各扬其长，歌词中所唱的“借我一双慧眼吧”或许将会实现。 人类通过不断发明的新技术来替代旧技术去更高效和经济地完成任务。在计算机视觉领域亦是如此，我们开发更便捷人脸识别用于门禁系统，以替代手动的输入用户名和密码——Xbox One利用红外相机设计的人脸识别系统就颇受用户好评。 除上述人类自身也能做到的识别功能外，计算机视觉还可应用在那些人类能力所限，感觉器官不能及的领域和单调乏味的工作上——在微笑瞬间自动按下快门，帮助汽车驾驶员泊车入位，捕捉身体的姿态与电脑游戏互动，工厂中准确地焊接部件并检查缺陷，忙碌的购物季节帮助仓库分拣商品，离开家时扫地机器人清洁房间，自动将数码照片进行识别分类……或许在不久的将来，超市电子秤就能辨别出蔬菜的种类；门禁系统能分辨出带着礼物的朋友，抑或手持撬棒的即将行窃的歹徒；可穿戴设备和手机帮助我们识别出镜头中的任何物体并搜索出相关信息。更奇妙的是，它还能超越人类双眼的感官，用声波、红外线来感知这个世界，观察云层的汹涌起伏预测天气，监测车辆的运行调度交通，甚至突破我们的想象，帮助理论物理学家分析超过三维的空间中物体运动。 活动1：远程监控和自动避障 原理图 摄像头\\n机械臂\\n超声波传感器->大白\\n树莓派: CSI/USB/GPIO 大白\\n树莓派-->手机客户端: WiFi Note right of 大白\\n树莓派: 处理超声波传感器数据\\n接收客户端控制指令 手机客户端->大白\\n树莓派: 发送请求给服务器，让小绿的动力系统执行 硬件准备 智能车套件 树莓派及扩展板 两自由度舵机云台 CSI摄像头 热熔胶枪 硬件连接 组装小车 将树莓派及电机扩展板固定到小车上 将摄像头固定到舵机云台上，并将云台固定到小车上 将树莓派连接到移动电源，通电 避障小车启动 1.使用远程桌面连接到树莓派 Windows；按开始+R，输入mstsc，回车。在新的窗口中输入树莓派的IP地址。在新的窗口中输入树莓派的用户名pi和密码raspberry macOS:打开VNC viewer，输入树莓派的IP地址。在新的窗口中输入树莓派的用户名pi和密码raspberry 2.打开终端，输入cd ~/Desktop/learn-ai/codes/chapter4/part1_ObstacleAvoid/ObstacleAvoid 3.输入python run.py 4.在浏览器中输入树莓派IP 5.通过前后左右和舵机控制按钮来遥控小车。使用self_driving按钮来进行自动避障 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-25 "},"content/chapter4/第2节 大白智能分拣.html":{"url":"content/chapter4/第2节 大白智能分拣.html","title":"第2节 大白智能分拣","keywords":"","body":"第2节 大白智能分拣 使用OpenCV来识别圆形物体，若识别到则发送串口指令给Arduino。Arduino控制机械臂和电磁铁进行抓取 训练大白认识圆形 利用霍夫变换来进行圆环检测。一个圆环需要3个参数来确定，所以进行圆环检测的累加器必须是三维的，这样效率就会很低，因此OpenCV使用了霍夫梯度法这个巧妙的方法，来使用边界的梯度信息，从而提升计算的效率。 OpenCV中进行霍夫圆环检测的函数： cv2.HoughCircles(image, method, dp, minDist, circles=None, param1=None, param2=None, minRadius=None, maxRadius=None) 本例中使用的具体参数： cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT , 1, 100, param1=100, param2=100, minRadius=50,maxRadius=200) 参数解释： image：8位，单通道图像。如果使用彩色图像，需要先转换为灰度图像。 method：定义检测图像中圆的方法。目前唯一实现的方法是cv2.HOUGH_GRADIENT。 dp：累加器分辨率与图像分辨率的反比。dp获取越大，累加器数组越小。例如，如果dp= 1时，累加器和输入图像具有相同的分辨率。如果dp=2，累加器便有输入图像一半那么大的宽度和高度。 minDist：为霍夫变换检测到的圆的圆心之间的最小距离，即让我们的算法能明显区分的两个不同圆之间的最小距离。这个参数如果太小的话，多个相邻的圆可能被错误地检测成了一个重合的圆。反之，这个参数设置太大的话，某些圆就不能被检测出来了。 param1：有默认值100。它是method设置的检测方法的对应的参数。对当前唯一的方法霍夫梯度法，它表示传递给canny边缘检测算子的高阈值，而低阈值为高阈值的一半。 param2：也有默认值100。它是method设置的检测方法的对应的参数。对当前唯一的方法霍夫梯度法，它表示在检测阶段圆心的累加器阈值。它越小的话，就可以检测到更多根本不存在的圆，而它越大的话，能通过检测的圆就更加接近完美的圆形了。 minRadius：默认值0，表示圆半径的最小值。单位是像素。 maxRadius：也有默认值0，表示圆半径的最大值。单位是像素。 示例： 原始图像： 处理后图像： 会自动抓取硬币的机械臂 视觉图像经由OpenCV处理后，如果识别到圆形，就通过串口将信息发送给Arduino，Arduino接收到信号后，控制云台舵机转动，并通过电磁铁将圆形物品分拣处理 原理图 摄像头\\n机械臂\\n电磁传感器->大白\\n树莓派: CSI/USB/GPIO 大白\\n树莓派-->传送带: 摄像头实时监测 Note right of 大白\\n树莓派: OpenCV处理摄像头数据\\n发送指令给机械臂和电磁传感器 硬件准备 大白 Arduino CSI摄像头 摄像头桌面支架 待检测的圆形金属物体（任选） 硬件连接 将烧录好程序的Arduino通过USB连接到树莓派 电磁传感器连接到pin5，两个舵机连接到3和4 用乐高制作传送带和摄像头支架参考活动，将待检测的物体放置在传送带上，使传送带缓慢转动 USB摄像头垂直固定在传送带顶部，使之能够看到传送带上的物体 启动智能分拣系统 1.使用远程桌面或HDMI视频输出连接到树莓派 2.打开终端，输入cd ~/Desktop/learn-ai/codes/chapter4/part2_AutoSort/AutoSort 3.输入python classifier.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2019-12-15 "},"content/chapter4/第3节 大白自动追踪.html":{"url":"content/chapter4/第3节 大白自动追踪.html","title":"第3节 大白自动追踪","keywords":"","body":"第3节 大白自动追踪 通过拍照、爬虫等方式获取待训练图片，使用python进行简单的文件处理，用OpenCV训练后，可实现对特定物体的识别和追踪 级联分类器简介 目前图像检测方法主要分为两大类，基于知识和基于统计。 以人脸检测来说，基于知识的人脸检测方法主要包括：模板匹配，人脸特征，形状与边缘，纹理特征，颜色特征。 基于统计的人脸检测方法主要包括：主成分分析与特征脸法，神经网络模型，隐马尔可夫模型，支持向量机，Adaboost算法。 基于知识的方法将人脸看成不同特征的特定组合，即通过人脸的眼睛、嘴巴、鼻子、耳朵等特征及其组合关系来检测人脸。 基于统计的方法将人脸看成统一的二维像素矩阵，通过大量的样本构建人脸子空间，通过相似度的大小来判断人脸是否存在。 OpenCV采用的级联分类器，可以理解为将采用Adaboost算法构建的若干分类器串联起来，即级联。只有通过所有分类器后才识别为检测正确。这样可以提高检测的准确度。 OpenCV提供了若干已经提前训练好的级联分类器供使用，包括人体、人脸、猫咪等。 示例：识别猫脸 核心代码： String catFileName = \"~/opencv/build/etc/haarcascades/haarcascade_frontalcatface.xml\" CascadeClassifier catclassifier 结果： 活动1：人脸分类器：追着人跑的大白 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->Arduino: 串口指令 Note right of 大白\\n树莓派: OpenCV处理摄像头数据（级联分类器）\\n发送指令给Arduino 硬件准备 大白车 Arduino CSI摄像头 待识别的人或猫的照片（电子或纸质打印任选） 硬件连接 将烧录好程序的Arduino通过USB连接到树莓派 启动追踪小车 1.使用远程桌面或HDMI视频输出连接到树莓派 2.打开终端，输入cd ~/Desktop/learn-ai/codes/chapter4/part3_AutoTrack/AutoTrack 3.输入python tracker.py 4.将待识别的物体（人脸或猫）在车前移动，观察车的追踪行为 活动2：训练新的分类器 通过收集大量样本图片，可以训练自定义的分类器，可以识别任意的物体。 1.环境准备 在Windows桌面上执行： 新建一个文件夹，重命名为待检测的物体名称（英文），比如检测移动电源，就命名为yidongdianyuan 进入文件夹，再新建两个文件夹，分别命名为p和n，p代表positive（正样本），n代表negative（负样本） 获取分类器图形化训练软件，下载安装。 获取图片批量处理软件,解压即可，主程序为MtPcl.exe 获取示例数据集 2.收集负样本 训练样本包括正样本和负样本。正样本，通俗点说，就是图片中只有你需要的目标。而负样本的图片只要其中不含有目标就可以了。但需要说明的是，负样本也并非随便选取的。 例如，需要检测的目标是汽车，那么正样本就应该是仅仅含有汽车的图片，而负样本显然不能是一些包含天空的，海洋的，风景的图片。因为最终训练分类器的目的是检测汽车，而汽车应该出现在马路上。也就是说，分类器最终检测的图片应该是那些包含马路，交通标志，建筑物，广告牌，汽车，摩托车，三轮车，行人，自行车等在内的图片。很明显，这里的负样本应该是包含摩托车、三轮车、自行车、行人、路面、灌木丛、花草、交通标志、广告牌等。 Adaboost方法是机器学习中的一个经典算法，而机器学习算法的前提条件是，测试样本和训练样本独立同分布。所谓的独立同分布，可以简单理解为：训练样本要和最终的应用场合非常接近或者一致。否则，基于机器学习的算法并不能保证算法的有效性。此外，足够的训练样本（至少得几千张正样本、几千张负样本）也是保证训练算法有效性的一个前提条件。 使用网络浏览器或各种方法，收集各种图片，但是不能包含待检测的物体（移动电源）。保存在n文件夹中。数量为数十个为宜。 3.收集正样本 正样本就是想要识别出来的物体。尽可能排除无关物体的干扰（图片中无其他物体） 使用手机，拍摄待识别的物体，并将其存储在p文件夹。数量在10个以上为宜。 4.图片预处理 这一步骤调整正负样本的图片分辨率。 打开MtPcl.exe，选择添加文件夹，选择p文件夹 选择右侧修改尺寸，高度设置为480，勾选保持原图比例。然后选择下面的覆盖原图。点击保存。 点击清空，并对n文件夹执行相同的操作 5.训练分类器 打开Cascade-Trainer-GUI 点击Browse，选择包含n和p的文件夹 路径中不能包含中文 单击Common选项卡，调整第一项Number of Stages，选择10获得更快的训练速度，如果效果不明显可以逐渐增大，但是训练速度会显著增加。 修改宽度和高度为20，30。使宽高比和待处理的文件相同。 点击Start开始训练 训练成功后，在原文件夹中会增加一个classifier文件夹，里面的cascade.xml就是训练成功的级联分类器。 6.测试 选择Test选项卡，点击右上角Browse，选择上一步的cascade.xml 输入设置，选择Single Image，测试图片可以是包含多个目标物体的图片或截图 选择输出方式为Result Image in a Folder，并指定路径 点击Start，最小检测阈值输入10，10；最大检测阈值输入800，800（可以不断调整以取得最好的效果） 检测效果 活动3：应用新的分类器 将cascade.xml通过U盘拷贝到树莓派的路径下 打开终端，执行： cd ~/Desktop/learn-ai/codes/chapter4/part3_AutoTrack/AutoTrack python tracker_my_object.py 大白将会跟随训练的物体进行移动。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2019-12-15 "},"content/chapter5/第5章简介.html":{"url":"content/chapter5/第5章简介.html","title":"第5章 深度学习—无人驾驶小车老白","keywords":"","body":"第5章 深度学习—无人驾驶小车老白 本章主题：深度学习、无人驾驶 这部分基于树莓派以及一些开源软件构建。树莓派从摄像头模块获取输入，然后通过无线方式发送获得的图像数据到电脑，电脑通过之前训练好的神经网络对输入的图像数据预测小车接下来的动作，然后发送这些预测动作的控制指令到树莓派控制小车的程序中。小车根据这些获得的指令实现自动驾驶。 现有的Caffe、TensorFlow等工具箱已经很好地实现CNN模型，但这些工具箱需要的硬件资源比较多，不利于初学者实践和理解。本章使用NumPy来构建卷积神经网络（Convolutional Neural Network,CNN）模型，通过对驾驶数据的采集和训练，实现无人驾驶。 本章重点 1 掌握无人驾驶数据采集及训练的基本方法 2 会灵活地在无人驾驶系统中训练和应用分类器 涉及软硬件 树莓派、摄像头 小车套件 OpenCV © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter5/第1节 更加专业的视觉系统.html":{"url":"content/chapter5/第1节 更加专业的视觉系统.html","title":"第1节 更加专业的视觉系统","keywords":"","body":"第1节 更加专业的视觉系统 准备硬件，搭建小车。按照操作步骤进行小车的动力和视觉系统的测试。完成测试后，即可正式进入无人驾驶过程。 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->客户端: WiFi Note right of 大白\\n树莓派: HTTP协议传送摄像头数据 硬件准备 硬件清单 树莓派 树莓派电机扩展板 CSI摄像头 超声波传感器 小车套件 硬件连接 将超声波传感器连接到树莓派上 Trig——GPIO 23 Echo——GPIO 24 VCC和GND接到扩展板的Vin和GND插口 执行测试 电机测试 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer #也可以使用autojump工具快速跳转，比如想访问computer路径， #只需输入`j c`并回车即可（需要之前通过cd命令访问过） #如果执行文件报错\"Permission Denied\"，尝试在执行命令的最前面加上sudo sudo python3 drive_api.py -s 150 //-s 150作为可选的参数，来指定行驶速度。可选范围是0-256 2.打开树莓派上的网络浏览器，在地址栏输入路由器管理地址，查看树莓派的IP地址3.在浏览器地址栏输入树莓派IP:81/drive例如（192.168.123.100:81/drive） 4.在打开的界面上按键盘上的上下左右方向键来测试小车5.测试完毕后，在终端输入ctrl + c来结束当前任务 摄像头测试 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd test python3 stream_server_test.py 2.新建一个终端窗口 3.在新的终端窗口中输入以下命令，如果有正常的视频画面输出，则测试通过 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py 4.在终端输入ctrl + c来结束当前任务 超声波传感器测试 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd test python3 ultrasonic_server_test.py 2.新建一个终端窗口 3.在新的终端窗口中输入以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 ultrasonic_server_test.py 4.在终端输入ctrl + c来结束当前任务 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-25 "},"content/chapter5/第2节 无人驾驶数据采集、训练与测试.html":{"url":"content/chapter5/第2节 无人驾驶数据采集、训练与测试.html","title":"第2节 无人驾驶数据采集、训练与测试","keywords":"","body":"第2节 无人驾驶数据采集、训练与测试 搭建起车道，然后运行相应的收集数据的程序，按下键盘方向键控制小车行驶，每按一次方向键，程序就会记录下一帧相应的图像。让小车平均遍历自动驾驶中可能出现的各种情况，按‘q‘退出数据采集，然后再运行相应的模型训练程序训练自动驾驶神经网络。最后使用训练好的神经网络模型在跑道上进行测试。 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->客户端: WiFi Note right of 大白\\n树莓派: HTTP协议传送摄像头数据\\n神经网络收集和训练数据 硬件准备 硬件清单 纸 胶带 硬件搭建-跑道 地面颜色为纯色，与所用纸张的颜色对比度应较大 跑道的宽度稍大于车的宽度 可以把拐弯处的弯度设计得稍大一些 采集驾驶数据 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 collect_training_data.py 2.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py 3.开始采集 顺利执行后会出现两个窗口，上面的是摄像头的画面，下面的是操作区。 将鼠标焦点移到箭头所指的工作区上。 把小车放置在跑道上，点击键盘上下左右光标控制小车。 通过键盘控制，让小车在跑道上正确的绕行数圈（3圈左右即可） 训练结束后，确定焦点仍在工作区上，点击键盘q退出训练，程序会自动保存驾驶数据 训练驾驶数据 1.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 model_training.py 2.得到模型 模型文件在~/Desktop/learn-ai/chapter5/SelfDrivingCar/computer/saved_model/nn_model.xml 开始无人驾驶 根据训练好的神经网络模型，现在我们可以实现自动驾驶 1.打开终端 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 rc_drive_nn_only.py 2.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2019-12-15 "},"content/chapter5/第3节 红灯停绿灯行—识别交通信号.html":{"url":"content/chapter5/第3节 红灯停绿灯行—识别交通信号.html","title":"第3节 红灯停绿灯行—识别交通信号","keywords":"","body":"第3节 红灯停绿灯行—识别交通信号 在上一章我们采用机器学习的方法制作了级联分类器来识别物体。这一部分通过深度学习的方法来训练识别特定物体 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->客户端: WiFi Note right of 大白\\n树莓派: HTTP协议传送摄像头数据\\n神经网络收集和训练数据\\n应用级联分类器处理交通信号 识别交通信号 1.打开终端 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 rc_driver.py 2.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py 本节已经使用训练好的级联分类器，可以识别STOP交通信号牌。 当识别后，小车会自动停止。 识别超声波信号 在现有的基础上，只需要再新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 ultrasonic_client.py 把障碍物放到车前，车是不是自动停止了呢？ 使用自己的分类器 通过修改rc_drive.py文件，我们也可以使用上一章中训练的级联分类器。也可以训练新的分类器，比如其他交通信号。 1.放置分类器 通过文件管理器，将上次训练的级联分类器xml文件复制到如下位置 2.编辑自动驾驶文件，引用自己的分类器 cd ~/Desktop/learn-ai/codes/chapter5/self_driving_car cd computer # cp命令复制一个新的文件，防止对原来文件改动造成错误 sudo cp rc_driver.py rc_driver_my_object.py sudo nano -c rc_driver_my_object.py 在箭头处，仿照上面的语法，尝试添加自己的分类器引用。 完成后，按Ctrl+X，然后按Y确认并回车，来退出文本编辑器。 3.新建终端，重复上一节的操作，开始无人驾驶 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 rc_drive_my_object.py 4.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter6/第6章简介.html":{"url":"content/chapter6/第6章简介.html","title":"第6章 综合进阶—机器人小绿","keywords":"","body":"第6章 综合进阶—机器人小绿 本章主题：机器人 小绿是一个使用3D打印制作外壳，使用舵机作为动力部分，使用树莓派作为控制中枢的智能机器人。作为物联网的一个节点，实现多种物联网功能，包括网页遥控：通过自行开发的物联网平台来对它进行遥控；语音助手：可以通过自己训练的热词来进行唤醒、通过语音来控制机器人执行各种动作；控制其他设备：比如控制前几个章节的小车，读取各种传感器的数据等；人脸解锁：通过实时的人脸识别和红外线发射装置，实现人脸解锁，也可以通过Google Assistant、Siri、Alexa等远程控制；实时姿态模仿：通过单目摄像头拍摄实时画面，采用OpenPose姿态识别软件进行处理，将关节姿态数据通过蓝牙或串口传递给机器人，机器人进行实时的姿态模仿。 本章重点 1 了解物联网的基本概念和原理 2 会通过物联网和开源硬件制作较为复杂的综合机器人系统 涉及软硬件 树莓派、ESP8266、安卓手机 麦克风阵列、舵机、摄像头 3D打印机 OpenPose、OpenCV © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter6/第1节 小绿的一小步，我们的一大步.html":{"url":"content/chapter6/第1节 小绿的一小步，我们的一大步.html","title":"第1节 小绿的一小步，我们的一大步","keywords":"","body":"第1节 小绿的一小步，我们的一大步 小绿通过移动电源即可供电。接通电源后，访问小绿的ip地址，试着让小绿迈出第一步吧 原理图 小绿->手机浏览器: 1.建立局域网服务器 手机浏览器-->小绿: 2.通过WiFi访问控制界面 手机浏览器-->小绿: 3.发送请求给服务器，如“前进” 小绿->手机浏览器: 4.服务器响应请求，让小绿的动力系统执行 组装小绿 小绿的外壳是3D打印而成。将舵机固定在关节处。然后将舵机都接在主控板上就可以了。是不是很简单呢？ 小绿的3D打印源文件在learn-ai/assets/3D Models/green 小绿共需要9个舵机，每个胳膊2个共4个，每条腿2个共4个，还有1个在颈部。 按顺序将舵机用螺丝刀固定在3D打印件上，完成组装。注意将舵机的线都引向中间。 烧录程序到开发板（选做） 程序烧录过程略，程序源文件见learn-ai/codes/chapter6/part2_FirstStep/greenrobot 小绿迈出第一步 1.将小绿连接到移动电源 2.查看ip地址 使用浏览器打开路由器管理地址，查找小绿的ip地址 3.访问测试地址 在浏览器中打开小绿ip地址/test 4.正确连接舵机 逐个将舵机的线连接到基于ESP8266芯片的Wemos D1开发板扩展板上。从0到11共12个槽位都可以。按照下面的对应关系将小绿的舵机连接到正确的槽位上，并进行测试。 小绿的不同部位与槽位的对应关系如下：此面为正面 位置 槽位 位置 槽位 左手 D5 右手 D4 左脚 D9 右肩 D2 左腿 D7 右腿 D6 左肩 D3 右脚 D8 5.访问小绿ip地址 最后，终于可以让小绿迈出第一步了！ 使用blockly积木控制小绿 打开learn-ai/codes/chapter6/part2_FirstStep/robot_diy_blockly/index.html，通过积木拖拽控制小绿 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-25 "},"content/chapter6/第2节 “小绿，跳舞！”制作自己的语音助手.html":{"url":"content/chapter6/第2节 “小绿，跳舞！”制作自己的语音助手.html","title":"第2节 “小绿，跳舞！”制作自己的语音助手","keywords":"","body":"第2节 “小绿，跳舞！”制作自己的语音助手 通过深度学习的方式训练自己的声音模型，制作自己的语音助手，用语音来控制小绿的行动。 原理图 麦克风阵列->树莓派: GPIO 树莓派-->小绿: WiFi Note right of 树莓派: 处理麦克风语音数据\\n如“前进”、“跳舞” 树莓派-->小绿: 发送处理结果 Note right of 小绿: 动作执行 树莓派-->小白: WiFi Note right of 树莓派: 处理麦克风语音数据\\n如“左转”、“停车” 树莓派-->小白: 发送处理结果 Note right of 小白: 动作执行 树莓派-->RGB彩灯: 使用MQTT传递指令\\n“开灯”、“关灯” 硬件准备 1.连接麦克风扩展板 通过对齐GPIO将扩展板固定在树莓派上 2.连接扬声器 将扬声器通过3.5mm耳机线连接到麦克风扩展板 3.设置基于ESP8266的RGB彩灯 使用基于WS2812的RGB彩灯，ESP8266通过MQTT（一种物联网轻量级通讯协议）与HomeAssistant通信 程序烧录过程略，程序源文件见~/Desktop/learn-ai/codes/chapter6/part3_VoiceAssistant/mqttlight 接通电源，使用杜邦线将彩灯的Data接到ESP8266的D3，GND和VCC分别接到对应位置 4.通过HDMI或ssh或远程桌面连接到树莓派 参数配置 rapiro项目文件夹在~目录下 参数配置时，可以使用命令行文本编辑工具nano或vim Nano：用法是nano 文件名。退出时候按ctrl+w，需要保存按y,否则按n，然后按回车。 Vim：用法是vi 文件名。先按insert键，然后进行输入。要退出vi编辑器，按esc键，然后输入:wq，回车 1.调用参数配置~/rapiro/config.yaml # 在http://yuyin.baidu.com/注册语音识别应用，获取ak、sk和id baidu_yuyin: api_key: 'qW5HLj4Ks6DfsCV2K9If5O80' secret_key: '37riCUCmGj1lfrhaGcyu11wWqCjvZbZR' app_id: '9217941' homeassistant: url: 'http://localhost' port: '8123' password: 'welcome' # 在http://www.turingapi.com/注册机器人，获取key tuling: key: 'be4efe7298b24d0d8c9b5542dd56671a' 2.机器人网络配置~/rapiro/opiro.py #!coding:utf-8 import os import time import requests class rapiro: def __init__(self,ip): #把双引号里的地址替换为小绿的ip地址 self.ip = \"http://192.168.123.184\" self.actions = { \"停止\":'/otto-home', \"小绿前进\":'/otto-walk', \"小绿后退\":'/otto-walk-back', \"小绿挥手\":'/wave-hands', \"小绿左转\":'/otto-turn', \"小绿右转\":'/otto-turn-right', \"\"\" 适用于小白的命令 \"小白前进\":'/get?command=forward' \"小白后退\":'/get?command=backward' \"\"\" } def get(self,url): r = requests.get(self.ip+url) print(r.text) def do(self,action): method = self.actions.get(action,None) if(method): self.get(method) print(\"rapiro \" + action) def isValid(self,text): for key in self.actions.keys(): if(key in text): return key return None if __name__ == '__main__': #把双引号里的地址替换为小绿的ip地址 rap = rapiro('http://192.168.123.184') action = rap.isValid('前进') print(action) if action: rap.do(action) #rap.do(\"前进\") time.sleep(4) rap.do(\"挥手\") time.sleep(4) rap.do(\"停止\") 3.核心文件配置~/rapiro/server.py …… # 第84行 把引号里的地址替换为小绿的ip地址 rap = rapiro('http://192.168.123.184') …… 4.关键词触发优化~/rapiro/handle.py #!coding:utf-8 from rapiro import * rap = rapiro() def handle(str): # 仿照下一行的格式，补充更多的关键词，优化小绿的智力 # 如果语句命令中包含关键词，则将会识别为对应的机器人指令 cmds = [\"前进\",\"后退\",\"左转\",\"右转\",\"停止\"] for cmd in cmds: if(cmd in str): rap.do(cmd) break 5.声音设备配置~/.asoundrc # 使用`aplay -l`和`arecord -l`查看wm8960soundcard对应的card和device号码。 # 例如，如果aplay对应的card和device分别是1和0， # 则在playback.pcm处的双引号内填入`hw:1,0`， # arecord则在capture.pcm处填写。 pcm.!default { type asym playback.pcm { type plug slave.pcm \"hw:1,0\" } capture.pcm { type plug slave.pcm \"hw:1,0\" } } 6.语音助手设置~/homeassistant/configuration.yaml …… …… …… conversation: intents: # 意图类型（名称），以及对应的语法匹配规则 OpenLight: - 打开{item}灯 - 把{item}灯打开 CloseLight: - 关上{item}灯 - 关闭{item}灯 intent_script: # 意图类型（名称） OpenLight: # speech返回 speech: text: 已打开{{ item }}灯 # 执行动作 action: service: light.turn_on data_template: entity_id: > {% if item==\"教室\" %} light.classroom_light_rgb {% endif %} CloseLight: speech: text: 已关闭{{ item }}灯 action: service: light.turn_off data_template: entity_id: > {% if item==\"教室\" %} light.classroom_light_rgb {% endif %} mqtt: broker: 127.0.0.1 port: 1883 light: - platform: mqtt name: \"Classroom Light RGB\" state_topic: \"classroom/rgb1/light/status\" command_topic: \"classroom/rgb1/light/switch\" brightness_state_topic: \"classroom/rgb1/brightness/status\" brightness_command_topic: \"classroom/rgb1/brightness/set\" rgb_state_topic: \"classroom/rgb1/rgb/status\" rgb_command_topic: \"classroom/rgb1/rgb/set\" state_value_template: \"{{ value_json.state }}\" brightness_value_template: \"{{ value_json.brightness }}\" rgb_value_template: \"{{ value_json.rgb | join(',') }}\" qos: 0 payload_on: \"ON\" payload_off: \"OFF\" optimistic: false 训练自己的语音模型 语音唤醒模型的训练是基于深度神经网络的训练。采用神经网络作为特征提取器，把声波信息转化为多维特征向量输入到深度神经网络（DNN）中，进行训练，得到模型。 嘿，Siri！ OK，Google！ 小爱同学！ 小度小度！ 这些是主流的语音助手的唤醒词。小绿也有自己的唤醒词。 当我们呼唤他小绿的时候，他就会回应。这是因为已经提前训练好的识别文件green.pmbl 当然，我们可以训练自己独特的唤醒词。你想要叫他什么？叫什么都可以~只需要稍微的训练一下，得到一个识别文件就可以了。 1.登陆网址叫我的机器人什么好呢 你需要有一个GitHub账号，然后在右上角选择Login with GitHub 登陆后的界面： 2.Create Hotword 3.选择右下角的Record my voice 4.录制3个样本后，点击右下角的按钮进行模型训练 在左侧选择你的性别和年龄段，这是为了更加准确的调整模型。 然后在右侧说出唤醒词，通过调整灵敏度，逐渐调节到最优状态。然后点击Save and download 5.将下载好的模型文件放在项目文件夹 可以命名为myrobot.pmbl 启动小绿的语音助手系统 //先启动HomeAssistant sudo docker start home-assistant //启动小绿 cd ~/rapiro python server.py green.pmdl //或者使用自己训练的myrobot.pmbl //python server.py myrobot.pmbl 对着麦克风说小绿，听到提示音后，说出你的问题。 你可以说今天的天气怎么样？、讲个笑话、小绿前进/后退/跳舞、小白前进/左转/停车、把灯打开/关闭等。 试着用你的唤醒词来叫醒机器人吧 与苹果家庭或谷歌家庭融合，使用Siri和Google Assistant来控制设备 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-25 "},"content/chapter6/第3节 使用物联网制作人脸解锁.html":{"url":"content/chapter6/第3节 使用物联网制作人脸解锁.html","title":"第3节 使用物联网制作人脸解锁","keywords":"","body":"第3节 使用物联网制作人脸解锁 原理图 摄像头-->树莓派: WiFi Note right of 树莓派: HomeAssistant处理人脸数据匹配 树莓派-->语音合成: 播放识别结果 树莓派-->红外发射器: 发送处理结果 红外发射器-->大门\\n电灯\\n空调\\n电视\\n……: 红外信号 硬件清单 树莓派 安卓手机 红外发射器 具有红外遥控器的大门/灯/空调/电视/…… 硬件准备 摄像头和扬声器 在安卓手机上下载安装IP摄像头和Kodi两个app 将安卓手机连接到教学WiFi，通过路由器查询记录手机的ip地址 打开IP摄像头app，进行设置后点击最下面的开启服务器，记录下视频服务的地址和端口 Kodi是为了通过安卓手机的扬声器远程播放声音 红外发射器 安卓手机安装智慧家app，对博联RM Pro红外发射器进行初始化设置，连接到教学WiFi，然后通过路由器查询记录ip地址和mac地址 HomeAssistant的启动 1.启动HomeAssistant sudo docker start home-assistant 启动大概需要1分钟 2.访问HomeAssistant 树莓派ip:8123，选择API密码登陆，密码welcome 配置HomeAssistant（configuration.yaml） sudo docker exec -it home-assistant env LANG=C.UTF-8 /bin/bash vi configuration.yaml # 按insert键，然后进行输入 # 退出vi编辑器先按esc键，然后输入:wq，回车 # 退出bash环境输入exit，回车 1.基础配置 group: !include groups.yaml automation: !include automations.yaml script: !include scripts.yaml scene: !include scenes.yaml # 如果希望能够从iOS或macOS中的家庭应用来管理，增加下面这一行。 homekit: …… …… …… 2.Kodi和摄像头配置 …… …… …… # 在host处填入安卓平板的ip地址 media_player: - platform: kodi host: 192.168.123.194 # android_ip_webcam: # - host: 192.168.123.194 # port: 8090 # ffmpeg: # camera: # - platform: ffmpeg # name: Camera # input: -rtsp_transport tcp -i rtsp://192.168.123.29:8554/live # camera: # - platform: rpi_camera # camera: # - platform: local_file # name: camera01 # file_path: /share/motion/lastsnap.jpg camera: - platform: mjpeg mjpeg_url: http://192.168.123.218:8080/?action=stream # mjpeg_url: http://192.168.123.59:8088/?action=snapshot 3.红外发射配置 …… …… …… # 在host和mac处填入红外发射器的ip和mac地址 switch: - platform: broadlink host: 192.168.123.107 mac: '78:0F:77:5A:26:85' timeout: 15 switches: door: friendly_name: \"大门\" command_on: 'eAY0AC8PEAAB2xAuLw8QLi8PEC4vDxEuLw8QLi8QEC4vEBEuLw8vDy8QEC4vDxEuLw8RLi8QEC4AAAAA' command_off: 'eAY0AC8PEAAB2xAuLw8QLi8PEC4vDxEuLw8QLi8QEC4vEBEuLw8vDy8QEC4vDxEuLw8RLi8QEC4AAAAA' 访问http://HomeAssistant的ip地址:8123 点击左下角的第一个服务按钮，然后选择switch.broadlink_learn_command 点击Call Service，这时博联红外发射器的前端会出现小红点。用遥控器要学习的按键对着小红点按下去，小红点消失 点击左下角的第二个状态按钮，找到类似下图的内容，将最后的一长串代码复制到配置文件的对应位置即可 4.人脸识别和tts配置 …… …… …… # 正确填写下面的参数 # 百度人脸识别注册：https://cloud.baidu.com/product/face sensor: - platform: baidu_face api_key: \"tHjWWiNXlQLFNT2SdrNPWwH3\" secret_key: \"LXHQ5kP6GYewzOqFL1umrK4mfljx3W4r\" group_list: \"['normal_group']\" camera_entity_id: \"camera.mjpeg_camera\" token: \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiI0NjBjMjFlM2NiZjY0YTliYTdjZTFjMzVhNDYzY2I2YiIsImlhdCI6MTU3ODU0NjU3OSwiZXhwIjoxODkzOTA2NTc5fQ.rUDysZx983VxFJPj4cq5gynlNa3A7HO5zd8H9FxTHAQ\" # liveness: \"NORMAL\" # name: \"ren lian shi bie\" # port: 8123 # pic_url: \"网络、本地图片地址\" scan_interval: 1 # image_processing: # - platform: baidu_face_indentify # app_id: '11478116' # api_key: 'tHjWWiNXlQLFNT2SdrNPWwH3' # secret_key: 'LXHQ5kP6GYewzOqFL1umrK4mfljx3W4r' # snapshot_filepath: '/home/pi/images/' # resize: 0 # detect_top_num: 3 # ha_url: 'http://192.168.123.201:8123' # # ha_password: 'welcome' # scan_interval: 1 # source: # - entity_id: camera.mjpeg_camera # name: faceRec # 百度TTS注册：https://cloud.baidu.com/product/speech/tts tts: - platform: baidu app_id: 9217941 api_key: qW5HLj4Ks6DfsCV2K9If5O80 secret_key: 37riCUCmGj1lfrhaGcyu11wWqCjvZbZR #person：声音（0：女，1：男，3：特殊声音，4：特殊声音，缺省0） person: 4 #speed：语速0-9（缺省5） speed: 5 #pitch：语调0-9（缺省5） pitch: 5 #volume：音量0-15（缺省5） volume: 15 5.人脸注册 将照片传到HomeAssistant目录下的uploadpics目录下 选择注册人脸服务进行注册 依照此格式填写： {\"user_info\":\"乔碧萝\",\"image\":\"/config/uploadpics/zhangcuihua.jpg\",\"uid\":\"tank\"} user_info为用户标识，识别出人脸时候系统会显示这个名称 uid用于查找删除人脸数据 image为上传照片的路径 注册成功后会弹出提示 可对注册的人脸进行颜值检测 依照此格式填写： {\"image\":\"/config/uploadpics/zhangcuihua.jpg\"} 检测成功会返回结果 6.自动化配置 automations.yaml …… …… …… # 当检测到人脸（人脸识别结果大于0），就执行tts和开关操作。 - id: baiduface alias: face_indentify trigger: - entity_id: sensor.ren_lian_shi_bie platform: state to: 'True' action: - data_template: entity_id: media_player.kodi message: > service: tts.baidu_say service: switch.turn_on data: - entity_id: switch.door 执行人脸解锁 将安卓手机放置在大门边上 可以将另一个大的显示器放在边上，全屏实时显示手机拍摄的实时画面 当人靠近手机摄像头的时候，如果能够正确识别，则会播放语音问候，并执行红外线开关操作 在这个基础上，可以扩展出各种其他的应用，基本过程就是通过正确的人脸识别，触发其他物联网操作。 比如在教室门口识别到教师后，就自动执行打开投影仪、放下投影幕布，拉上窗帘等一系列上课操作。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-25 "},"content/chapter6/第4节 物联网进阶—执行自动化操作.html":{"url":"content/chapter6/第4节 物联网进阶—执行自动化操作.html","title":"第4节 物联网进阶—执行自动化操作","keywords":"","body":"第4节 物联网进阶—执行自动化操作 https://github.com/nijisakai/TeachableMachine_with_MQTT_and_HomeAssistant © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/chapter6/第5节 唱跳rap—小绿实时姿态模仿.html":{"url":"content/chapter6/第5节 唱跳rap—小绿实时姿态模仿.html","title":"第5节 唱跳rap—小绿实时姿态模仿","keywords":"","body":"第5节 唱跳rap—小绿实时姿态模仿 卡内基梅隆大学（Carnegie Mellon University）的研究人员开发了一个身体跟踪系统，并命名为OpenPose。该系统能实时跟踪人的肢体运动，包括手和脸部。它使用计算机视觉和机器学习技术来处理视频帧，甚至可以同时跟踪多个人的运动。 姿态检测的应用 对标准化体育动作进行建模，通过视频方式对运动员实时动作进行比对分析，可实现动作规范指标化。同时，还可以对运动员运动量进行统计分析，科学指导体育训练教学。 小绿通过OpenPose模仿人类动作 原理图 摄像头-->PC/树莓派: WiFi/USB PC/树莓派-->小绿: WiFi Note right of PC/树莓派: OpenPose处理帧画面，计算姿态角度 PC/树莓派-->小绿: 发送处理结果 Note right of 小绿: 动作执行 活动1：模仿视频文件中的人物动作 1.将小绿通电 2.在电脑上打开Anaconda Prompet， conda activate learn-ai //Windows cd C:\\learn-ai\\codes\\chapter6\\part5_OpenPose //macOS cd ~/Desktop/learn-ai/codes/chapter6/part5_OpenPose python OpenPoseVideo.py OpenPoseVideo.py核心代码： …… //这部分指定输入源为文件夹下的`sample_video.mp4` input_source = \"sample_video.mp4\" cap = cv2.VideoCapture(input_source) #cap = cv2.VideoCapture(0) hasFrame, frame = cap.read() …… //这部分将各个关节的姿态通过反三角函数转化为角度数据发送给舵机 POSE_PAIRS2 = [ { \"servo\":2,\"pair\":[2,3] ,\"trim\":0 ,\"factor\":-1 , 'angle':-1,'rangle':-1 } ,{ \"servo\":3,\"pair\": [5,6] , \"trim\": 180 ,\"factor\":-1 , 'angle':-1,'rangle':-1} ] POSE_PAIRS2.extend( [ { \"servo\":4,\"pair\":[3,4] ,\"trim\":0 ,\"factor\":-1 , 'angle':-1,'rangle':-1} ,{ \"servo\":5,\"pair\": [6,7] , \"trim\": 180 ,\"factor\":-1 , 'angle':-1,'rangle':-1} ]) for idx,item in enumerate(POSE_PAIRS2): partA = item['pair'][0] partB = item['pair'][1] # print(points[partB]) if points[partA] and points[partB]: angle = int(atan2( points[partB][0]-points[partA][0] , points[partB][1]-points[partA][1])/pi*180) print((item['servo'],angle)) # angle = limitTo(angle,10,170) print((item['servo'],angle)) item['rangle'] = angle if(item['servo'] %2 == 0 and angle > 90): angle = angle - 360 elif(item['servo'] %2 != 0 and angle 3.运行代码后将会在电脑窗口中看到实时的姿态，同时小绿也会跟随视频中的人物姿态运动。 活动2：实时姿态模仿 1.将小绿通电 2.在电脑上打开Anaconda Prompet， conda activate learn-ai //Windows cd C:\\learn-ai\\codes\\chapter6\\part5_OpenPose //macOS cd ~/Desktop/learn-ai/codes/chapter6/part5_OpenPose python OpenPoseRealtimeVideo.py 3.运行代码后将会在电脑窗口中看到连接电脑的USB摄像头的实时画面。画面中的人物姿态将会实时的传递给小绿。试试挥挥手，看看小绿模仿的怎么样 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "},"content/codes/下载.html":{"url":"content/codes/下载.html","title":"资料下载","keywords":"","body":"资料下载 课程讲义、源代码及相关资源，请点击这里来下载 账号：sli 密码：sli 仅限北京师范大学课程人工智能与STEM教育教学学习使用 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-24 "},"content/chapter1/第4节 开源硬件基本操作.html":{"url":"content/chapter1/第4节 开源硬件基本操作.html","title":"第4节 开源硬件基本操作","keywords":"","body":"第4节 开源硬件基本操作 什么是开源 Open Source Code(开放源代码)：开放源代码（Open source code）也称为源代码公开，指的是一种软件发布模式。一般的软件仅可取得已经过编译的二进制可执行档，通常只有软件的作者或著作权所有者等拥有程序的原始码。有些软件的作者会将原始码公开，被公开的原始程序代码称为开放源代码。开放源代码软件源于自由软件开源运动，简称开源软件。是指那些源代码公开，可以被自由使用、复制、修改和再发布的一系列软件的集合。由此得出开源软件的几个特点，即： 代码自由使用并可再发行 开源软件发行时其源代码要一并发行 允许他人对既有的源码进行修改并再次发布 原始创作者保证源代码的完整性 不歧视程序在任何领域内的使用 基于源程序的新产品也要遵循同样的开源许可协议等 开源许可协议 自由软件/开源软件是自由的，免费的，源代码开放的，可自由下载安装和使用。同时，为了维护作者和贡献者的合法权利，保证这些软件不被一些商业机构或个人窃取，影响软件的发展，开源社区开发出了各种的开源许可协议，如：GPL协议，COPYLEFT协议，LGPL协议，Apache License协议，BSD协议重点介绍GPL协议，其授予程序接受人以下权利(自由)： 以任何目的运行此程序的自由 以学习程序工作机理为目的，对程序进行修改的自由(能得到源代码是前提) 再发行复制件的自由 改进此程序，并公开发布改进的自由(能得到源代码是前提) 例如：全球所有搭载Android操作系统的手机， 其操作系统部分要遵循一定的开源协议，因为Android操作系统的内核是Linux，而Linux正是基于开源许可协议-GPL协议的操作系统，所以，以它为核心的Android也要遵循同样的GPL协议。如下图： 开源硬件的分类 主控板 开源硬件中有一部分根据其功能作用，称之为主控板。而主控板上的核心正是能够运行程序代码的小电脑，它能将我们的想法，也就是程序转换为其上引脚电信号的变化，通过这些变化的电信号来达成我们的想法。 外设和传感器 本次AI课程配有：外设：舵机，舵机云台，TT电机，TT电机小车传感器：超声波测距传感器，温湿度传感器等 开源硬件的基本操作 扩展板 1. Arduino电机扩展板 此扩展板搭载了两颗L293DD电机驱动芯片和独立的稳压电路，可通过DC插头给该扩展板提供外部5V-12V电源，2颗L293DD电机驱动芯片可驱动4个直流电机，为小车平台提供了驱动基础。由于直流电机可通过电流的方向来改变转向，即可通过互换直流电机的两根引线来改变电机的运转方向。 2. Arduino Nano扩展板 此扩展板为引脚和电源扩展板，即把体积较小的Arduino Nano的所有引脚都印出来，并对每个引脚都配有供电引脚(VCC和GND)，同时配有5mmDC接口，可接7-12V电源给arduino nano供电，且每个数字引脚都符合舵机控制线的定义，可以直接接入舵机。此扩展板与Arduino Nano的组合状态如下图： 3. NodeMcu电机扩展板 此电机扩展板集成一颗L293DD直流电机驱动芯片，可以同时驱动两路直流电机，同时将NodeMcu开发板的所有引脚印出来，并对每个引脚配有电源(VCC和GND)插针，可直接入舵机，并可为需要5V或3.3V电源的设备供电，同时也可以通过VIN接线端子输入5V电源，Power开关可控制外部电源的通断。 NodeMcu与此扩展板组合状态如下图所示： NodeMcu电机扩展板的外部接线 4. 树莓派电机扩展板 此电机扩展板通过I2C接口接入树莓派，通过I2C总线芯片外挂两颗直流电机驱动芯片，可同时驱动4个直流电机，同时又引出了单独的一组I2C总线接口，除此之外，此扩展板带有4个标准舵机PWM输出接口，可以控制4路舵机。由于该扩展板为大功率输出板，所以板上带有独立外部供电接口，使用此驱动板控制电机时需要外接5V-12V电源，否则不能正常工作。 此电机扩展板与树莓派组合状态如下图: 外设和传感器 1. 舵机 如上图所示,舵机是一种由直流电动机，减速齿轮组，角度控制器和动力输出轴组成的一种动力提供机械，主要作用是根据控制信号使动力输出轴转动一定角度。通常使用舵机来控制一些车船模型，以及机器人等。 舵机有3条线，其定义见下表：|颜色|作用| :-:|:-: |黄色|控制信号(PWM)输入线| |红色|5V供电线(电源正极)| |GND|电源负极| 注：第一根黄色线为信号线，需要为其输入PWM(脉冲宽度调制)信号才能使舵机正常工作。如下图所示： 即在一个脉冲循环内，高电平持续时间占总循环时间的比率(占空比)越大，舵机转动的角度就越大。 2. 小车直流电机 小车直流电机也叫TT电机，单个电机由一个直流马达和苏联减速齿轮构成，通过控制直流马达的正反转控制方向，控制直流马达的转速来控制速度。在实际使用时可通过调换两条引出线在驱动板的位置来更改旋转方向。 3. 超声波测距传感器 超声波测距传感器(如下图所示)通过发出超声波(频率为20000Hz的声波)，再被阻挡物体表面反射，反射的超声波又被接收装置接收，然后按下方照公式计算出来：距离 = 声速 x 发出超声波到被接收返回的时间 / 2 超声波测距传感器的接口有4根引脚，基本定义为：|名称|作用| :-:|:-:| |VCC|5V供电接口(电源正极)| |Trig|触发控制信号输入| |Echo|回响信号输出| |GND|电源负极| 4. DHT22温湿度传感器 DHT22温湿度传感器也称AM2302，是一款含有已校准数字信号输出的温湿度复合传感器，湿度量程范围0~99.9%RH，精度±2%RH，而温度量程范围是-40℃~80℃，精度±0.5℃。DHT22传感器也是单总线传感器，即其输出的数据通过一个引脚即可输出，其接口定义如下表所示：|名称|作用| :-:|:-:| |VCC(+)|5V供电接口(电源正极)| |out|信号输出引脚| |GND(-)|电源负极| 5. 电磁铁 电磁铁是给绕在铁质内芯的线圈通电而产生磁力，而断电后磁力消失的装置。其控制接口定义如下表所示： |名称|作用| :-:|:-: |S(signal)|开关控制信号：高电平产生磁力；低电平磁力消失| |+(5V)|电源正极| |-(GND)|电源负极| 以Arduino UNO为例，电磁铁的接线方法如下图： 6. ESP32-Cam无线摄像头 ESP32-Cam是以ESP32芯片为计算核心，并搭载原生WiFi控制器的无线摄像头。它能够根据用户烧录的程序代码，使用户在连接它wifi名称的电脑网页端看到摄像头拍摄的实时视频，如下图所示： 由于此模块已提前烧录好程序，且其在小组局域网中的IP地址也已固定下来，所以在使用时只需按照下图连接电源线，稍等片刻，在同局域网电脑的浏览器中输入该摄像头的IP地址，按回车即可： 7. WS2812-RGB灯带 WS2812灯带由12颗级联的LED单元组成，每颗LED灯为5mmx5mm的正方形，每颗灯能单独发出红色(R),绿色(G),蓝色(B)，而且每颗灯都集成了WS2812控制芯片，12颗灯级联后可通过一根数据线连接开发板，通过程序来控制灯带的亮起效果。WS2812灯带的接口定义如下表所示： |线的颜色|定义| :-:|:-: |黄色|数据线| |红色|电源5V| |黑色|电源负极| © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-04-02 "},"content/chapter2/第3节 前馈神经网络—FFNN.html":{"url":"content/chapter2/第3节 前馈神经网络—FFNN.html","title":"第3节 前馈神经网络—FFNN","keywords":"","body":"第3节 前馈神经网络—FFNN 前馈神经网络是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层，信息仅在一个方向上移动。是目前应用最广泛、发展最迅速的人工神经网络之一。研究从20世纪60年代开始，目前理论研究和实际应用达到了很高的水平。 MNIST手写数字识别 一个基于MNIST训练的手写数字识别系统。点击这里来体验。 在学习机器学习的时候，首要的任务的就是准备一份通用的数据集，方便与其他的算法进行比较。 MNIST数据集是一个手写数字数据集，每一张图片都是0到9中的单个数字，比如下面几个： MNIST数据库是一个大型数据库的手写数字是通常用于训练各种图像处理系统。该数据库还广泛用于机器学习领域的培训和测试。它是通过重新混合来自MNIST原始数据集的样本而创建的。 MNIST数据库包含60000个训练图像和10000个测试图像。训练集的一半和测试集的一半来自NIST的训练数据集，而训练集的另一半和测试集的另一半来自MNIST的测试数据集。 前馈神经网络解读 先来看这样一组数据： 序号 输入 x 输出 y 第1条数据 4 36 第2条数据 9 81 ... ... ... 第n-1条数据 1 9 第n条数据 3 27 第n+1条数据 10 90 这只是我们随机编写的一些数字，它很简单，不使用任何模型算法，你也能轻而易举地找到 x-y 之间的规律： 输出y = 9 × 输入x 但是如果，我们一定要用神经网络来计算的话。那么，这个神经网络可以简单地搭建为： 我们以第一条数据输入4，输出36为例： 输入层，让模型读入第 1 条数据 4 输出层，告诉模型其结果为 36 隐藏层，就像连接 输入 和 输出 之间的桥梁 这个模型的核心：就是努力找到 x 与 y 之间的联系。 比如， 图中的 1 和 9，就是模型找到的其中一种连接方法。 更一般的，如果你拥有数据（X,Y），神经网络算法就会去寻找最佳的参数 W： 求解 W，就是这条神经网络会替我们努力完成的工作。 上面的图，写成公式为： 这就是一条最简单的神经网络。 当然，更多的时候，你在教材上看到的是这样的： 如果我们将参数 b 暂时遮挡住： 公式二 与 公式一 之间，仅仅多出一个 f () 函数。 这个 f () 函数，在学术上被称为 激活函数，通常是一个非线性的函数。例如： 像上面这些，均可以作为激活函数来使用。你会问：为什么我们要使用激活函数？这是因为，(w*X) 和 (w*h) 仅仅是线性运算。而我们在现实中遇到的问题，更多都是非线性的。这就好比，家到学校，理论上是两点一线的距离；但现实中，你要曲曲弯弯走很多路，才能抵达终点。因而，在 wX 的外面，包裹上一层激活函数，f(w\\X)。可以将线性问题转化为非线性问题，这样更接近真实的世界，也能使我们模型预测的准确度，得到大幅提升。 现在，如果我们把 n+1 条数据，全部考虑进来： 序号 输入 x 输出 y 第1条数据 4 36 第2条数据 9 81 ... ... ... 第n-1条数据 1 9 第n条数据 3 27 第n+1条数据 10 90 那么此时，神经网络的形态变为： 由图可以看出，它是 n+1 条数据的 堆叠。你会发现，像这样的神经网络，它只有横向箭头，并没有纵向箭头。即 第n条数据，并不受之前数据的影响。你可以视它为一条 一直向前，永不回望 的神经网络，也因此而得名 前馈神经网络。 我们单拎出第 n 条数据： 此时，hn 仅受 Xn 的影响。 在实际工作中，它适用于上一条数据与下一条数据，彼此之间没有任何关联的情形。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-03-28 "}}