{"./":{"url":"./","title":"关于本项目","keywords":"","body":"人工智能课程介绍 北京师范大学智慧学习研究院 智慧学习研究院（Smart Learning Institute）是北京师范大学下设的综合性科学研究、技术开发和教育教学实验平台。主要任务包括：在重点产品开发及项目研究的关键环节上取得实质性突破，形成可大规模推广的智慧学习解决方案；建构智慧学习理论，探索信息技术与教育双向融合的方法与途径，形成一批具有国际影响的学术成果；建立智慧学习实验区和实验校，发展基于大数据的教育教学研究模式；通过双聘机制和企业导师制，探索产学研结合的教育信息化高端人才培养机制。 青少年人工智能创新计划—元卓计划 元卓计划由北京师范大学发起，旨在培养青少年利用原创算法解决真实问题的能力，建立产学研协同机制，推动人工智能企业科技成果向教育教学转化，助力我国成为世界主要人工智能创新中心。 概述 本项目包含一个在线文档以及配套的教学材料（PPT、教案、学习单）。 包含6个有所关联、逐步递进的项目构成的章节。分别涉及物联网、机器人、机器视觉、语音识别和控制等内容。 包含背景知识学习、环境准备和资源下载部分。 本课程通过6个有所关联、逐步递进的章节，探究人工智能的基本原理，了解人工智能、机器学习基本概念，参与计算机视觉、语音技术等人工智能领域相关项目，利用人工智能解决学习和生活中的实际问题。 课程涉及人工智能基本概念、计算机视觉、语音技术、机器人等内容。通过一系列动手实验，制作小车和机器人，完成物体检测、自动追踪、无人驾驶、机器人姿态模仿、语音助手等项目。 课程包含详细的在线操作文档、配套代码、小车及机器人3D打印零件及全部硬件器材，学生无需自行准备任何设备，即可顺利完成全部项目。 完成课程学习后，将会对人工智能的基本概念有一定了解；对图像分类，目标检测，自然语言处理、语音识别等技术有直观体会；掌握开源硬件的基本操作，并通过开源硬件构建人工智能应用。 基于本项目的内容，通过调整章节比例和难度，我们制作了分别面向小学高年级、初中、高中及以上三套课程。每套课程均为16课时。 分章节介绍 第1章 基础知识 介绍： 学习者通过学习本章内容，将熟悉掌握一些必备的相关技能。如Python基础，Linux常见命令操作，开源硬件的基础操作等。为后续的项目学习打好基础。 第2章 人工智能体验 介绍： 通过本章内容，学生对人工智能的数学基础、概率论和博弈论、人工智能在图形图像和语言处理、电子游戏及其他领域的应用有感性认识。 使用在线的积木编程（google blockly/scratch）来控制 涉及软硬件： PC或树莓派（Raspberry Pi）或NVIDIA Jetson Nano 第3章 智能车“小白” 介绍： 主要使用ESP8266提供Web服务，来控制电机、舵机、传感器等，实现远程遥控、远程视频监控、巡线、避障、控制机械臂抓取等功能 可以通过积木编程的方式来对小车的功能进行编程 涉及软硬件： ESP8266，ESP32-CAM，小车套件（可3D打印），舵机，灰度传感器、超声波传感器等 自行开发的物联网控制平台，MIT App Inventor 第4章 自动追踪小车“大白” 介绍： 从机器视觉出发，让学生理解机器视觉的相关概念和原理，辨别OpenCV和深度学习的异同点。 使用OpenCV来处理视觉信号，并通过蓝牙或串口来将处理过的视觉信号发送给小车，从而实现物体追踪，人脸追踪，智能机械臂抓取等功能 学生通过使用Python，完成信息采集：爬虫、多文件处理；信息处理：训练采集的数据，形成分类器，从而让计算机视觉系统能够对特定的物体进行分辨 涉及软硬件： 树莓派、Arduino、舵机、USB摄像头、小车套件、3D打印机、电磁传感器、蓝牙接收器 OpenCV、Python 第5章 无人驾驶小车“老白” 介绍： 采用深度学习的方式，通过采集无人驾驶的数据，并进行训练，来实现无人驾驶的功能 涉及软硬件： 树莓派、摄像头、小车套件 Python 第6章 机器人“小绿” 介绍： 组装一个机器人，作为物联网的一个节点，实现多种物联网功能，包括网页遥控：通过自行开发的物联网平台来对它进行遥控；语音助手：可以通过自己训练的热词来进行唤醒、通过语音来控制机器人执行各种动作；控制其他设备：比如控制前几个章节的小车，读取各种传感器的数据等；人脸解锁：通过实时的人脸识别和红外线发射装置，实现人脸解锁，也可以通过Google Assistant、Siri、Alexa等远程控制；实时姿态模仿：通过单目摄像头拍摄实时画面，采用OpenPose姿态识别软件进行处理，将关节姿态数据通过蓝牙或串口传递给机器人，机器人进行实时的姿态模仿。 涉及软硬件： 树莓派、ESP8266、麦克风阵列、舵机、3D打印机、摄像头等 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-22 "},"content/课程说明.html":{"url":"content/课程说明.html","title":"课程说明","keywords":"","body":"课程说明 本部分是对课程的目标、大纲、时间地点、学分授予等的说明。授课老师可对此节按需进行修改。 课程目标 了解计算机基本知识 了解人工智能、机器学习基本概念 体验人工智能在实际中的应用，会使用开源硬件解决实际问题 课程时间和开课形式 由于新冠肺炎造成的影响，本课程采用远程授课形式开展。开课时间是第x-x周。 北师大珠海校区：周三第7-8节。励教楼C407 北师大珠海分校：周四第5-6节。励教楼C407 远程授课采用Zoom直播形式。Zoom软件下载地址：https://cernet.zoom.com.cn/client/latest/ZoomInstaller.exe下载安装后，点击加入会议 然后输入会议号：123456，以及个人姓名，点击加入会议即可 通过网络浏览器打开直播地址，也会自动跳转到Zoom软件。 课程直播地址：https://cernet.zoom.com.cn/j/2641642171 课程大纲 章节 主题 时间分配 前导 课程综述 2课时 第1章 基础知识 2课时 第2章 人工智能体验 2课时 第3章 硬件基础 2课时 第4章 机器视觉 2课时 第5章 深度学习 2课时 第6章 综合进阶 2课时 尾声 小组汇报 2课时 预备要求 掌握计算机基本操作 对编程语言有简单的了解 少量内容需要一定的英文阅读能力 学分授予 本课程学分1分。 根据学生学习的总评成绩认定学分： 总评成绩超过60分给予课程学分，此外总评成绩在60-84分发放合格证书，总评成绩大于84分发放优秀证书。总评成绩的计算公式如下： 总评成绩 = 平时成绩 x 10% + 出勤 x 20% + 小组综合作业 x 70% 其中： 平时成绩：参照平时表现，按照比例计入总分； 出勤：按照出勤情况给予打分，全勤则为满分，按照比例计入总分； 小组综合作业：形式为综合创意，由完成和汇报情况打分，按照比例计入总分。 主讲教师 黄荣怀教授 北京师范大学教授，长江学者。主要从事智慧学习环境、人工智能与教育、教育技术、知识工程、技术支持的创新教学模式等领域研究。现任北京师范大学智慧学习研究院院长、互联网教育智能技术及应用国家工程实验室主任、联合国教科文组织国际农村教育研究与培训中心主任。目前担任国家教材委员会科学学科专家委员会委员、教育部教育信息化专家组成员、教育部人工智能科技创新专家组工作组专家、普通高中信息技术课标组联席组长、中国教育技术协会副会长、中国教育装备行业协会副会长、北京市教育信息化专家委员会副主任委员、全球华人计算机应用学会（GSECE）主席、国际智慧学习环境协会副主席、国际期刊 Smart Learning Environment（Springer出版）主编、国际期刊 Journal of Computers in Education（Springer出版）主编等。曾获国家精品课程、国家精品资源共享课、国家规划教材、国家教学成果奖、北京市优秀教学团队、北京市教学名师、北京市优秀教师等。承担国家、省部级等横向纵向课题100余项，现已发表学术论文近400篇，出版著作、杂志40余本。 朱立新高级工程师 朱立新博士，籍贯山东省临沂市沂南县, 中国科学院自动化所博士 & 美国密歇根州立大学（MSU, Michigan State University）Research Associate、博士后。曾任法国斯伦贝谢公司嵌入式软件工程师、美国科胜讯（Conexant）公司中国研发中心研发经理、美国英特尔（Intel）公司中国研发中心研发经理、美国微软公司移动部门系统软件首席架构师(Principle Architect)、美国超导加速器实验室（FRIB）控制部门助理研究员、中国和芯星通公司嵌入式软件研发负责人、网龙网络公司高级技术总监、爱奇艺智能硬件研发总监。目前担任北京师范大学互联网教育智能技术及应用国家工程实验室高级工程师，学习环境构建与测评实验室主任，主要负责人工智能与STEM的教育、中国教育机器人研发、AI与教育大数据的结合、智能教室、边缘计算与学习环境的研究和产业化等工作。兼任中国科学院高能物理研究所客座研究员，中国洪泰智造公司技术顾问。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/环境准备.html":{"url":"content/环境准备.html","title":"环境准备","keywords":"","body":"环境准备 本节详细说明了课程实施的全程中需要的软硬件环境配置。相关软件，代码及课程资源，请点击这里来下载也可以选择在下方提供的官方网址下载推荐按顺序依次安装以下软件，以避免因依赖问题报错 Arduino建议使用我们提供的预先配置好的版本 涉及硬件 电脑：x86架构，运行Windows/Linux/macOS 树莓派3B或4B套装（主板，电源，SD卡） 路由器 可选配件：显示器，视频线缆 在你的电脑上的操作 1. 安装Arduino IDE Arduino IDE（Integrated Development Environment，集成开发环境）是针对Arduino控制板的编程和下载平台。在Windows，macOS，Linux上均可以方便安装。Arduino项目文件的后缀是*.ino 。项目文件应在与项目名相同的文件夹中。 使用预先配置的Arduino（推荐） 下载压缩包，解压到磁盘任意位置，比如桌面。 点击文件夹中的Arduino.exe，开始使用。 手动安装 下载安装Arduino IDE 在文件--首选项--附加开发板管理器网址一栏中输入https://arduino.ESP8266.com/stable/package_ESP8266com_index.json,https://dl.espressif.com/dl/package_esp32_index.json 重启Arduino IDE 在工具--开发板--开发板管理器中分别搜索esp8266和esp32，选择最新版本进行安装 在工具--管理库中搜索DHT，选择DHT sensor library by Adafruit 在工具--管理库中搜索adafruit sensor，寻找并选择Adafruit Unifled Sensor by Adafruit 打开链接https://github.com/ESP8266/arduino-ESP8266fs-plugin/releases,选择.zip文件下载，将解压后的文件夹复制到Arduino安装目录/tools文件夹，然后重启IDE 默认的路径应该是这样：/Arduino/tools/ESP8266FS/tool/ESP8266fs.jar 如果安装成功，会在工具菜单下看到下图选项: 设置开发板和端口 2. 安装CP2102驱动 这个驱动用于使用USB串口连接ESP8266。注意选择对应的操作系统和版本进行下载和安装。下载链接: https://www.silabs.com/products/development-tools/software/usb-to-uart-bridge-vcp-drivers 3. 安装Anaconda（可选） 本课程大部分Python运行环境已经迁移到元卓在线编程平台Anaconda是一个Python环境管理软件。在Windows、Mac、Linux上均可以方便安装。下载链接：https://www.anaconda.com/products/individual setup 下载安装Anaconda 在Windows和macOS上按图形化安装界面提示安装即可 在Linux上，使用终端切换到安装包路径，使用sh 安装包进行安装 Linux和macOS用户打开终端, Windows用户在开始菜单打开Anaconda Prompt 创建并进入环境 # 创建一个名字为learn-ai的虚拟环境，-y参数表示默认确认，不加此参数需手动确认。 conda create -n learn-ai -y # 激活learn-ai虚拟环境 conda activate learn-ai 在新环境中安装和OpenCV和TensorFlow（若电脑有独立显卡应安装GPU版本的TensorFlow） 如何在Windows 10操作系统中查看显示卡：按住Win键+X，然后选择设备管理器，在打开的窗口中选择显示适配器。 # 建议按下面的顺序安装 # 安装opencv conda install opencv -y # 安装Tensorflow ## 无独立显卡的电脑使用这条命令 conda install tensorflow -y ## 有独立显卡的电脑使用这条命令 conda install tensorflow-gpu -y # 安装git conda install git Anaconda基本命令概览 命令 操作 举例 conda create -n [环境名字] 创建新的虚拟环境 conda create -n learn-ai conda activate -n [环境名字] 激活虚拟环境 conda activate -n learn-ai conda install [包名] 安装指定包 conda install opencv conda deactivate 退出虚拟环境 conda deactivate conda env list 列出所有虚拟环境 conda env list conda env remove -n [环境名字] 删除指定环境 conda env remove - n learn-ai 4. VSCode（可选） VSCode是微软出品的免费代码编辑软件。在Windows，macOS，Linux上均可以方便安装。下载链接：https://code.visualstudio.com 教学路由器配置 教学的路由器默认设置如下：SSID：AI密码：raspberry管理地址：http://192.168.123.1管理账号：admin管理密码：admin 在树莓派上的操作 我们已经为树莓派配置好了全部环境，软件如Arduino IDE，相关代码等。可以下载封装的镜像文件进行恢复，也可以直接使用我们烧录好的SD卡（推荐）。 1. 镜像恢复 在这里下载最新的恢复镜像和备份恢复软件。 将32G或以上的TF卡插入到读卡器，连接到电脑。 使用Etcher或Win32DiskImager进行镜像恢复。 Etcher 选择镜像文件，和读卡器的盘符，点击Flash Win32DiskImager 选择待恢复镜像和待写入磁盘盘符，然后点按写入 2. 使用显示器连接树莓派 这是最简单的方式，通过HDMI线连接树莓派和显示器即可。 3. 远程连接树莓派（无显示器） （1）连接到路由器并获取局域网地址 树莓派默认连接的SSID是AI，密码是raspberry。如果你的路由器名称和密码不是这个的话，你可以： 有线连接 从路由器的LAN口引出网线，连接到树莓派。打开你的路由器管理页面，查看树莓派分配到的IP地址。 无线连接 修改树莓派的配置文件，使其连接到你现有的WiFi。恢复完成后，在电脑上会出现一个boot分区。 在boot分区创建文件wpa_supplicant.conf，写入以下内容。 country=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\"WiFi名字-不要删掉引号\" psk=\"WiFi密码-不要删掉引号\" key_mgmt=WPA-PSK priority=1 } 远程桌面 远程桌面的协议主要有RDP和VNC。 服务端（树莓派）配置 树莓派默认带有VNC Server服务。也可以安装RDP服务： sudo apt install xrdp systemctl enable xrdp systemctl start xrdp systemctl status xrdp 客户端配置 VNC Viewer是一个跨平台应用，支持多个平台。 Remmina是一个支持多种协议的跨平台客户端。 Microsoft远程桌面 是一个支持RDP协议的客户端，可以在微软Microsoft Store和苹果App Store下载。 其他开源项目如FreeRDP SSH 树莓派默认带有SSH服务。恢复完成后，在电脑上会出现一个boot分区。在boot分区创建文件ssh在Windows上按Win键，然后输入CMD打开命令提示符，在窗口中输入： ssh pi@树莓派的IP地址 输入回车后按提示输入密码：raspberry 树莓派软件环境集成说明 1. 课程项目文件 已经将课程相关文件放置在桌面learn-ai文件夹中。 2. 常用软件 已经配置安装好各类常用软件，如Arduino，VSCode等。 3. Docker（虚拟容器） sudo curl -sL get.docker.com | sed 's/9)/10)/' | sh 4. Nginx（网络服务器） sudo apt install nginx systemctl enable nginx systemctl start nginx systemctl status nginx 5. HomeAssistant（物联网平台） Home Assistant是一个开源的物联网平台，兼容各种物联网协议。可以方便的接入和控制各种设备 # Install hassio dependencies sudo apt-get install apparmor-utils apt-transport-https avahi-daemon ca-certificates curl dbus jq network-manager socat software-properties-common # Install hassio cd ~ curl -sL \"https://raw.githubusercontent.com/home-assistant/hassio-installer/master/hassio_install.sh\" >> hassio_install.sh sudo nano hassio_install.sh --- \"armv7l\") HOMEASSISTANT_DOCKER=\"$DOCKER_REPO/raspberrypi3-homeassistant\" HASSIO_DOCKER=\"$DOCKER_REPO/armhf-hassio-supervisor\" ;; --- sudo bash hassio_install.sh 6. Snowboy（语音助手） # https://github.com/Kitt-AI/snowboy sudo docker pull wupanhao/snowboy:1.0 # 启动镜像 sudo docker run -idt --name=\"rapiro\" --privileged -v /home/pi/rapiro:/rapiro wupanhao/snowboy:1.0 /bin/bash # 进入镜像 sudo docker exec -it rapiro env LANG=C.UTF-8 /bin/bash 7. 麦克风扩展板驱动 git clone https://github.com/waveshare/WM8960-Audio-HAT cd WM8960-Audio-HAT sudo ./install.sh sudo reboot 8. Python相关环境 python2 -m pip list #output python3 -m pip list #output © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter1/第1章简介.html":{"url":"content/chapter1/第1章简介.html","title":"第1章 人工智能初体验","keywords":"","body":"第1章 人工智能初体验 本章主题：体验 学习者通过学习本章内容，将进一步了解人工智能和机器学习的发展历程、相关概念以及主要应用。此外，以样例体验的形式进行学习，学习者将对人工智能在图形图像和语言处理、电子游戏及其他领域的应用产生更加深刻的认识与理解。 本章重点 了解人工智能的基本概念和原理 体验各种神经网络（卷积神经网络，深度神经网络等）的应用 涉及软硬件 网络浏览器 ActionBook在线平台 JupyterHub在线平台 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter1/第1节 初识人工智能.html":{"url":"content/chapter1/第1节 初识人工智能.html","title":"第1节 初识人工智能","keywords":"","body":"第1节 初识人工智能 人工智能（AI）作为新兴技术之一，在日常生活中已经被广泛地应用于教育、医疗、金融、电商等不同领域。本节对人工智能的关键技术和应用场景做简单的介绍。 1. 算法 机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中，经验通常以数据形式存在。因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生模型(model) 的算法。有了算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时，模型会给我们提供对应的判断。 算法是人类智慧的结晶，从算法思想上分类，大概可以包括递推，分治，贪心，动态规划等，如下图所示。 算法在数学，计算机科学，医学等方方面面均有广泛的应用。机器学习可以分为监督学习，无监督学习和强化学习，其中常见的算法如下图所示。 2. 机器学习 机器学习（Machine Learning）是一门专门研究计算机怎样才能模拟或实现人类的学习行为，以获取新的知识或技能，使之不断改善自身的性能的学科。机器学习是人工智能的核心，是使计算机具有智能的根本途径，根据学习模式可以将机器学习分类为监督学习、无监督学习和半监督学习等。机器学习是人工智能研究发展到一定阶段的必然产物。 （1）机器学习的发展简史 二十世纪五十年代到七十年代初，人工智能研究处于推理期，那时人们认为只要能赋予机器逻辑推理能力，机器就具有智能。 随着研究发展，在七十年代中期开始，人工智能研究进入了知识期，要使机器具有智能，就必须设法使机器拥有知识。此期间大量的专家系统面世。 在八十年代，从样例中学习（监督和无监督学习等）的一大主流是符号主义学习。其代表包括决策树(decision tree)和基于逻辑的学习。 九十年代中期之前，从样例中学习的另一主流技术是基于神经网络的连接主义学习。与符主义学习能产生明确的概念表示不同，连接主义学习产生的是黑箱模型。连接主义最大的局限是试错性：学习过程涉及大量参数，而参数的设置缺乏理论指导，主要靠手工调试。 九十年代中期，统计学习(statistical learning)登场。代表技术是支持向量机(support vector machine)。 二十一世纪初，连接主义通过深度学习卷土重来。所谓深度学习，即很多层的神经网络。在涉及语音、图像等复杂对象的应用中，深度学习取得了优越性能。深度学习虽然缺乏严格的理论基础，但是它显著降低了机器学习的门槛，为机器学习的实践带来了便利。 当前时代，互联网和硬件高度发达，人们进入了大数据时代，深度学习取得了大发展。随着物联网、边缘计算、5G网络、IPV6等的发展和普及，相信人工智能会在人类社会发挥更大的作用。 （2）数据集 要进行机器学习，先要有数据。假定我们收集了一批关于西瓜的数据，例如 {色泽=青绿；根蒂=蜷缩；敲声=浊响} {色泽=乌黑；根蒂=稍蜷；敲声=沉闷} {色泽=浅白；根蒂=硬挺；敲声=清脆} 这样的一组数据称为一个数据集(data set)，其中每条记录是关于一个事件或对象的描述，称为一个示例(instance)或样本(sample)。如果把每个样本中的色泽、根蒂和敲声作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可以在这个空间中找到自己的位置。当然，一般来说，维数越多，描述就会越精确。空间中每个点对应一个坐标向量，因此我们也把一个样本称为特征向量(feature vector) （3）训练 从数据中学得模型的过程称为学习(learning) 或训练(training)，这个过程通过执行某个算法来完成。训练过程中使用的数据称为训练数据(training data)，其中每个样本称为一个训练样本(training set)。学得的模型会对应关于数据的某种规律。 例如，如果希望学得一个能帮助我们判断一个西瓜是不是好瓜的模型，仅仅有前面的数据集是不够的。要建立关于预测(prediction)的模型，我们需要过得训练样本的结果信息: 例如{{色泽=青绿；根蒂=蜷缩；敲声=浊响}，好瓜} 这个关于结果的信息（好瓜）称为标记(label)。 （4）分类、回归、聚类、监督与无监督学习 若我们预测的是离散值，例如好瓜、坏瓜，此类学习任务称为分类(classification) 若预测的是连续值，如西瓜成熟度0.95，0.37，此类学习任务称为回归(regression) 我们可以对西瓜做聚类(cluistering)。即将训练集中的西瓜分为若干做，每组称为一个簇(cluster) 例如，算法自动将数据集分成了3簇，用三种颜色代表。每一簇内较大的点代表核心对象，较小的点代表边界点。黑色的点代表离群点或者叫噪声点。 根据训练数据是否拥有标记信息（好瓜），学习任务可划分为两大类：监督学习(supervised learning)和无监督学习(unsuperviserd learning) 分类和回归是监督学习的代表。聚类是无监督学习的代表。 3. 计算机视觉 计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。作为一个科学学科，计算机视觉研究相关的理论和技术，试图建立能够从图像或者多维数据中获取‘信息’的人工智能系统。这里所 指的信息指Shannon定义的，可以用来帮助做一个“决定”的信息。因为感知可以看作是从感官信号中提 取信息，所以计算机视觉也可以看作是研究如何使人工系统从图像或多维数据中“感知”的科学。计算机视觉的主要任务就是通过对采集的图片或视频进行处理以获得相应场景的信息。计算机视觉任务的主要类型有以下几种： （1）物体检测 物体检测是视觉感知的第一步，也是计算机视觉的一个重要分支。物体检测的目标，就是用框去标出物体的位置，并给出物体的类别。物体检测和图像分类不一样，检测侧重于物体的搜索，而且物体检测的目标必须要有固定的形状和轮廓。图像分类可以是任意的目标，这个目标可能是物体，也可能是一些属性或者场景。 （2）物体识别 计算机视觉的经典问题便是判定一组图像数据中是否包含某个特定的物体，图像特征或运动状态。这一问题通常可以通过机器自动解决，但是到目前为止，还没有某个单一的方法能够广泛的对各种情况进行判定：在任意环境中识别任意物体。现有技术能够也只能够很好地解决特定目标的识别，比如简单几何图形识别、人脸识别、印刷或手写文件识别，或者车辆识别。而且这些识别需要在特定的环境中，具有指定的光照，背景和目标姿态要求。 （3）图像分类 一张图像中是否包含某种物体，对图像进行特征描述是物体分类的主要研究内容。一般说来，物体分类算法通过手工特征或者特征学习方法对整个图像进行全局描述，然后使用分类器判断是否存在某类物体。图像分类问题就是给输入图像分配标签的任务，这是计算机视觉的核心问题之一。这个过程往往与机器学习和深度学习不可分割。 （4）物体定位 如果说图像识别解决的是what，那么，物体定位解决的则是where的问题。利用计算视觉技术找到图像中某一目标物体在图像中的位置，即定位。目标物体的定位对于计算机视觉在安防、自动驾驶等领域的应用有着至关重要的意义。 4. 自然语言处理 自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学。因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，所以它与语言学的研究有着密切的联系，但又有重要的区别。自然语言处理并不是一般地研究自然语言，而在于研制能有效地实现自然语言通信的计算机系统，特别是其中的软件系统。因而它是计算机科学的一部分。 自然语言处理（NLP）是计算机科学，人工智能，语言学关注计算机和人类（自然）语言之间的相互作用的领域。从研究内容来看，自然语言处理包括语法分析、语义分析、篇章理解等。从应用角度来看，自然语言处理具有广泛的应用前景。特别是在信息时代，自然语言处理的应用包罗万象，例如：机器翻译、手写体和印刷体字符识别、语音识别及文语转换、信息检索、信息抽取与过滤、文本分类与聚类、舆情分析和观点挖掘等，它涉及与语言处理相关的数据挖掘、机器学习、知识获取、知识工程、人工智能研究和与语言计算相关的语言学研究等。 5. 人机交互 人机交互（Human-Computer Interaction， HCI）是指人与计算机之间使用某种对话语言，以一定的交互方式，为完成确定任务的人与计算机之间的信息交换过程，是人工智能领域的重要的外围技术。人机交互是与认知心理学、人机工程学、多媒体技术、虚拟现实技术等密切相关的综合学科。传统的人与计算机之间的信息交换主要依靠交互设备进行，包括键盘、鼠标、操纵杆、数据服装、眼动跟踪器、位置跟踪器、数据手套、压力笔等输入设备，以及打印机、绘图仪、显示器、头盔式显示器、音箱等输出设备。人机交互技术除了传统的基本交互和图形交互外，还包括语音交互、情感交互、体感交互及脑机交互等技术。人机交互技术领域热点技术的应用潜力已经开始展现，比如智能手机配备的地理空间跟踪技术，应用于可穿戴式计算机、隐身技术、浸入式游戏等的动作识别技术，应用于虚拟现实、遥控机器人及远程医疗等的触觉交互技术，应用于呼叫路由、家庭自动化及语音拨号等场合的语音识别技术，对于有语言障碍的人士的无声语音识别，应用于广告、网站、产品目录、杂志效用测试的眼动跟踪技术，针对有语言和行动障碍人开发的“意念轮椅”采用的基于脑电波的人机界面技术等。 6. 知识图谱 从实际应用的角度出发其实可以简单地把知识图谱理解成多关系图（Multi-relational Graph）。那什么叫多关系图呢？ 学图是由节点（Vertex）和边（Edge）来构成，但这些图通常只包含一种类型的节点和边。但相反，多关系图一般包含多种类型的节点和多种类型的边。比如左下图表示一个经典的图结构，右边的图则表示多关系图，因为图里包含了多种类型的节点和边。这些类型由不同的颜色来标记。 在知识图谱里，我们通常用 “实体（Entity）” 来表达图里的节点、用 “关系（Relation）” 来表达图里的 “边”。实体指的是现实世界中的事物比如人、地名、概念、药物、公司等，关系则用来表达不同实体之间的某种联系，比如人 -“居住在”- 北京、张三和李四是 “朋友”、逻辑回归是深度学习的 “先导知识” 等等。 现实世界中的很多场景非常适合用知识图谱来表达。 比如一个社交网络图谱里，我们既可以有 “人” 的实体，也可以包含 “公司” 实体。人和人之间的关系可以是 “朋友”，也可以是 “同事” 关系。人和公司之间的关系可以是 “现任职” 或者 “曾任职” 的关系。 类似的，一个风控知识图谱可以包含 “电话”、“公司” 的实体，电话和电话之间的关系可以是 “通话” 关系，而且每个公司它也会有固定的电话。 知识图谱的应用 当你看到下面这行文本时会想到什么？ Ronaldo Luís Nazário de Lima 估计绝大多数中国人不明白上面的文本代表什么意思。没关系，我们看看它对应的中文： 罗纳尔多・路易斯・纳萨里奥・德・利马 现在大多数人应该能够明白这是一个外国人的名字。熟悉足球的人可能会知道这是一个巴西足球运动员。 之所以举这样一个例子，是因为，计算机一直面临着这样的困境 —— 无法获取网络文本的语义信息。尽管近些年人工智能得到了长足的发展，在某些任务上取得超越人类的成绩，但离一台机器拥有一个两三岁小孩的智力这样一个目标还有一段距离。这距离的背后很大一部分原因是机器缺少知识。如同上面的例子，机器看到文本的反应和我们看到罗纳尔多葡萄牙语原名的反应别无二致。为了让机器能够理解文本背后的含义，我们需要对可描述的事物 (实体) 进行建模，填充它的属性，拓展它和其他事物的联系，即，构建机器的先验知识。就以罗纳尔多这个例子说明，当我们围绕这个实体进行相应的扩展，我们就可以得到下面这张知识图。 机器拥有了这样的先验知识，当它再次看到 Ronaldo Luís Nazário de Lima，它就会 “想”：“这是一个名字叫 Ronaldo Luís Nazário de Lima 的巴西足球运动员。” 这和我们人类在看到熟悉的事物，会做一些联想和推理是很类似的。 Google 为了提升搜索引擎返回的答案质量，推出了知识图谱概念。有知识图谱的辅助，搜索引擎能够根据用户查询背后的语义信息，返回更准确、更结构化的信息。Google 知识图谱的宣传语 “things not strings” 道出了知识图谱的精髓：不要无意义的字符串，需要文本背后的对象或事物。 我们可以把知识图谱认为是一个知识库。比如在 Google 搜索引擎里输入 “Who is the wife of Bill Gates?”，我们直接可以得到答案 -“Melinda Gates”。这是因为我们在系统层面上已经创建好了一个包含 “Bill Gates” 和 “Melinda Gates” 的实体以及他俩之间关系的知识库。所以，当我们执行搜索的时候，就可以通过关键词提取（\"Bill Gates\", \"Melinda Gates\", \"wife\"）以及知识库上的匹配可以直接获得最终的答案。这种搜索方式跟传统的搜索引擎是不一样的，一个传统的搜索引擎它返回的是网页、而不是最终的答案。我们只能得到包含这个关键词的网页，然后不得不点击进入相关网页查找需要的信息，所以就多了一层用户自己筛选并过滤信息的过程。 7. 云计算与大数据 云计算（cloud computing）是分布式计算的一种，指的是通过网络“云”将巨大的数据计算处理程序分解成无数个小程序，然后，通过多部服务器组成的系统进行处理和分析这些小程序得到结果并返回给用户。云计算早期，简单地说，就是简单的分布式计算，解决任务分发，并进行计算结果的合并。因而，云计算又称为网格计算。通过这项技术，可以在很短的时间内（几秒种）完成对数以万计的数据的处理，从而达到强大的网络服务。“云”实质上就是一个网络，狭义上讲，云计算就是一种提供资源的网络，使用者可以随时获取“云”上的资源，按需求量使用，并且可以看成是无限扩展的，只要按使用量付费就可以，“云”就像自来水厂一样，我们可以随时接水，并且不限量，按照自己家的用水量，付费给自来水厂就可以。从广义上说，云计算是与信息技术、软件、互联网相关的一种服务，这种计算资源共享池叫做“云”，云计算把许多计算资源集合起来，通过软件实现自动化管理，只需要很少的人参与，就能让资源被快速提供。也就是说，计算能力作为一种商品，可以在互联网上流通，就像水、电、煤气一样，可以方便地取用，且价格较为低廉。总之，云计算不是一种全新的网络技术，而是一种全新的网络应用概念，云计算的核心概念就是以互联网为中心，在网站上提供快速且安全的云计算服务与数据存储，让每一个使用互联网的人都可以使用网络上的庞大计算资源与数据中心。 大数据是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。麦肯锡全球研究所给出的定义是：一种规模大到在获取、存储、管理、分析方面大大超出了传统数据库软件工具能力范围的数据集合，具有海量的数据规模、快速的数据流转、多样的数据类型和价值密度低四大特征。大数据技术的战略意义不在于掌握庞大的数据信息，而在于对这些含有意义的数据进行专业化处理。换而言之，如果把大数据比作一种产业，那么这种产业实现盈利的关键，在于提高对数据的“加工能力”，通过“加工”实现数据的“增值”。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter1/第2节 分类和识别—卷积神经网络.html":{"url":"content/chapter1/第2节 分类和识别—卷积神经网络.html","title":"第2节 分类和识别—卷积神经网络","keywords":"","body":"第2节 分类和识别—卷积神经网络 卷积神经网络（Convolutional Neural Networks, CNN）是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习的代表算法之一。 CNN网络的基本结构和体验 卷积神经网络的层级结构包括 数据输入层/ Input layer 卷积计算层/ CONV layer ReLU激励层 / ReLU layer 池化层 / Pooling layer 全连接层 / FC layer 卷积在图像处理中的效果是，通过卷积操作，将图像中的某些特征凸显出来。 不同的卷积核会实现不同的效果池化，或者降采样，就是缩小图片，制作缩略图。 全连接层是一种特殊的卷积，它主要用于加权分类 在左上角方框中写数字来进行可视化CNN体验。 练习1：训练自定义图片分类器 Tensorflow简介 TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。 分类器 图片的计算机存储 图片以像素组合的形式呈现在显示器上。每个像素由3种颜色rgb组成 在计算机上，每个像素用包含rgb三种颜色的数组存储。 特征提取/训练/学习 计算机通过神经网络的方法，通过运算图片的数组，提取不同图像的特征， 这个过程叫做训练。通常，训练的时候要使用大量同类的图片，比如不同的猫的照片，它们有相似的特征。 在线训练 练习2：图像风格迁移 在神经网络之前，图像风格迁移的程序有一个共同的思路：分析某一种风格的图像，给那一种风格建立一个数学或者统计模型，再改变要做迁移的图像让它能更好的符合建立的模型。这样做出来效果还是不错的，但一个很大的缺点：一个程序基本只能做某一种风格或者某一个场景。因此基于传统风格迁移研究的实际应用非常有限。 而 Neural Style 程序通过输入一张代表内容的图片和一张代表风格的图片，使用深度学习网络输出一张融合了这个风格和内容的新作品。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-16 "},"content/chapter1/第3节 无中生有—生成对抗网络.html":{"url":"content/chapter1/第3节 无中生有—生成对抗网络.html","title":"第3节 无中生有—生成对抗网络","keywords":"","body":"第3节 无中生有—生成对抗网络 生成对抗网络（GAN, Generative Adversarial Networks）由Ian Goodfellow等于2014年提出。GANs是一类生成模型，从字面意思不难猜到它会涉及两个“对手”，伪造者（Generator）和警察（Discriminator）。伪造者总想着制造出能够以假乱真的钞票，而警察则试图用更先进的技术甄别真假钞票。两者在博弈过程中不断升级自己的技术。 练习：图片转视频 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-16 "},"content/chapter1/第4节 藏头诗，对对联—循环神经网络.html":{"url":"content/chapter1/第4节 藏头诗，对对联—循环神经网络.html","title":"第4节 藏头诗，对对联—循环神经网络","keywords":"","body":"第4节 藏头诗，对对联—循环神经网络 RNN（Recurrent Neural Network）是一类用于处理序列数据的神经网络。首先我们要明确什么是序列数据，摘取百度百科词条：时间序列数据是指在不同时间点上收集到的数据，这类数据反映了某一事物、现象等随时间的变化状态或程度。这是时间序列数据的定义，当然这里也可以不是时间，比如文字序列，但总归序列数据有一个特点——后面的数据跟前面的数据有关系。 练习：利用循环神经网络生成古诗词 1. 训练（可跳过） 2. 生成藏头诗 本地练习（选做） 1.打开项目文件夹learn-ai/codes/chapter2/part4_RNN/01_PoetAI 其中， poetry.txt内包含了大量的古诗词 poet_rnn.py用来训练模型 poet_rnn_outpu.py用来生成古诗词 2.打开Anaconda Prompt，执行： conda activate learn-ai python poet_rnn.py 执行后将会开始进行模型训练。 3.待模型训练完毕后，会在当前目录下生成模型文件poetry.module-49 使用VS Code编辑器打开poet_rnn_output.py，在最后一行： print(gen_poetry_with_head_and_type(\"深度学习\", 7)) 将会生成以深度学习四个字开头的七言藏头诗。尝试将文字替换为其他，7可以替换为5，即生成五言诗。保存后执行： python poet_rnn_output.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-16 "},"content/chapter1/第5节 玩游戏—强化学习算法.html":{"url":"content/chapter1/第5节 玩游戏—强化学习算法.html","title":"第5节 玩游戏—强化学习算法","keywords":"","body":"第5节 玩游戏—强化学习算法 DeepMind《Playing Atari with Deep Reinforcement Learning》提出了强化学习算法（DQN），DQN使用卷积神经网络作为价值函数来拟合Q-learning中的动作价值，这是第一个直接从原始像素中成功学习到控制策略的深度强化学习算法。DQN 模型的核心就是卷积神经网络，使用Q-learning 来训练，其输入为原始像素，输出为价值函数。在不改变模型的架构和参数的情况下，DQN在七个Atari2600游戏上，击败了之前所有的算法，并在其中三个游戏上，击败了人类最佳水平。 练习1：Flappy Bird 1.打开项目文件夹learn-ai/codes/chapter2/part6_DQN/DeepLearningFlappyBird 2.打开Anaconda Prompt，执行： conda activate learn-ai python deep_q_network.py 执行后将会开始进行模型训练 3.使用预先训练好的模型： python deep_q_network_trained.py 练习2：进化算法超级马里奥 这种学习方式称之为神经网络进化拓扑结构（NeuroEvolution of Augmenting Topologies，简称NEAT） 实际进化过程中，超级马里奥并不会进行预测以改变其行动。通过进行不同的尝试，而不是做其“应该”做的事情，这样每次都会产生新的点子。当一个点子成功后，就会被记住，反之则被作废。就这样，超级马里奥在经历了34尝试后，完全通关了！当然，如果重新运行的话，这套AI机会肯定可以找到一条不同但不会更加成功的线路。 1.打开项目文件夹learn-ai/codes/chapter1/part6_DQN/SuperMario 2.双击打开EmuHawk.exe 3.载入游戏文件 点击左上角的File——Open ROM，然后选择项目目录下的Super Mario World(USA).sfc 4.载入游戏存档文件 点击左上角的File——Load State——Load Named State，然后选择Lua目录下的DP1.State 5.载入算法文件 点击左上角的Tool——Tool Box，选择Lua Console。在新窗口中点击Script——Open Script，选择项目目录下的neatevolve.lua 6.观察游戏的自我进化过程 思考游戏进化的过程和生物进化的异同 练习3：头脑游戏—学习你喜欢的颜色 思考一个数组，它从0到255。一个游标，在中间的位置上。一个黄灯和一个绿灯。一个按钮，与游标相连。 前提设定： 数字每隔1秒在一个随机的位置出现，如果出现在游标左侧，则绿灯亮，如果在游标右侧，则黄灯亮。即黄灯还是绿灯亮完全是随机的。 数组喜欢被你按按钮。 上帝的推动：“你”来了，你更喜欢绿色，这个简单的机器会理解你么？ 在每次亮灯时，如果亮了绿灯，你就按一下按钮，表示喜欢。如果亮黄灯，就什么都不做。 数组发现它每次亮绿灯，都会得到奖励（按按钮），本能决定增大绿色的面积，也就是将游标右移，这样落在绿色的概率就更大了。于是，每次它都将游标向右移动1格。 经过一段时间，绿色出现的次数越来越多，它学会了，你的奖励产生了效果。 结语： 超级马里奥的终极目标是在屏幕上向右移动最远的距离，数组游标的终极目标就是不断被按按钮，人类的终极目标是否是将基因一代一代的传递下去呢？ 为了这些终极目标，我们学会了趋利避害，一切有利于达成目标的活动都被保留了下来。即使有些时候它甚至是一种迷信： “沃兹尼亚克发明了一个能够发射出电视机信号的口袋装置。他会带着这个装置走进一个房间，比如宿舍，大家都在那里看电视，而沃兹尼亚克则会悄悄地按下口袋装置的按钮，用静电干扰电视屏幕，让画面变得模糊。只要有人站起来去拍电视机，沃兹尼亚克就会松开按钮，电视屏幕就又恢复清晰。最后，沃兹尼亚克甚至让同学认为，要想恢复画质，必须单脚站立扶着天线，或者摸电视机顶部。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-16 "},"content/chapter1/第6节 你问我答—知识图谱.html":{"url":"content/chapter1/第6节 你问我答—知识图谱.html","title":"第6节 你问我答—知识图谱","keywords":"","body":"第6节 你问我答—知识图谱 知识图谱是由 Google 公司在 2012 年提出来的一个新的概念。从学术的角度，我们可以对知识图谱给一个这样的定义：知识图谱本质上是语义网络（Semantic Network）的知识库。 知识图谱在线体验 这是一个集自然语言处理，统计机器学习和知识图谱，有关医药领域的初级自动问答系统。该问答系统可以解析输入的自然语言问句生成相应的后台查询指令，进一步请求后台基于TDB知识库相关服务，进而得到问题的结果。源代码地址： © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-16 "},"content/chapter2/第2章简介.html":{"url":"content/chapter2/第2章简介.html","title":"第2章 人工智能软硬件基础","keywords":"","body":"第2章 人工智能软硬件基础 本章主题：Linux和开源硬件 学习者通过学习本章内容，了解Python基本语法，了解Linux基本操作，会用Liunx搭建较为复杂的Web服务。为后续的项目学习打好基础。 本章重点 Linux基本操作练习，Web服务搭建练习。 涉及软硬件 网络浏览器 ActionBook在线平台 JupyterHub在线平台 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter2/第1节 Python语言基础.html":{"url":"content/chapter2/第1节 Python语言基础.html","title":"第1节 Python语言","keywords":"","body":"第1节 Python语言基础 Python是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。Python的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。 内容提要 了解Python语言特点 了解Python语言的基本语法 会使用pip工具进行Python包管理 Python特点 Python是一种解释型语言： 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。 Python是交互式语言： 这意味着，您可以在一个Python提示符>>> 后直接执行代码。 Python是面向对象语言：这意味着Python支持面向对象的风格或代码封装在对象的编程技术。 Python是初学者的语言：Python对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到浏览器再到游戏。 Python发展历史 Python是由Guido van Rossum在八十年代末和九十年代初，在荷兰国家数学和计算机科学研究所设计出来的。Python本身也是由诸多其他语言发展而来的,这包括ABC、Modula-3、C、C++、Algol-68、SmallTalk、Unix shell和其他的脚本语言等等。 像Perl语言一样，Python源代码同样遵循GPL(GNU General Public License)协议。现在Python是由一个核心开发团队在维护，Guido Van Rossum仍然占据着至关重要的作用，指导其进展。 Python 2.7被确定为最后一个Python 2.x版本，其已于2020年1月1日终止支持。 Python包管理工具—pip pip是一个通用的Python包管理工具，提供了对Python包的查找，下载，安装，卸载等功能。 使用pip pip命令 功能 备注 install 安装软件包 pip install [package name] download 下载软件包 uninstall 卸载软件包 pip uninstall [package name] list 列表列出已安装的软件包 pip list show 显示已安装软件包的信息 pip show [package name] check 检查已安装的软件包是否具有兼容的依赖项 search 搜索PyPI查找软件包 help 显示帮助命令 Python基本语法 关键字 关键字也称保留字，是被语言保护起来具有特殊含义的词，不能用于起名字。查看Python的语言的所有关键字（用Python自带的IDLE执行下面两句代码） # 查看关键字 >>> import keyword >>> keyword.kwlist ['False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield'] 基本词法单位 基本词法单位包括常量、变量、关键字、运算符、表达式、函数、语句、类等。 常量：是指初始化（第一次赋予值）后保持固定不变的值。例如：3.14，'Hello!'，False，这是4个不同类型的常量。在Python中没有命名常量，通常用一个不改变值的变量代替。比如：Pi=3.14 通常用于定义圆周率常数π。 标识符：用于不同的的词法单位，通俗的讲就是名字。标识符可以作为变量、函数、类的名字。合法的标识符必须遵守以下规则： 由一串字符组成，字符可以是任意字母、数字、下划线、汉字，但这些字符中的开头不能是数字。 不能与关键字同名。 标识符中唯一能够使用的标点符号是下划线，不能含有其他标点符号（包含：空格、括号、引号、逗号、斜线、反斜线、冒号、句号、问号等）。 变量：是指在运行的过程中值可以被修改的量。变量的名称除了必须符合标识符的构成规则外，要尽量遵循一些约定俗成的规范。以下划线开头的变量在Python中有特殊的含义，所以自定义名称时，一般不用下划线作为开头字符。此外，Python是严格区分大小写字母的。也就是说，Score和score会被认为是两个不同的名字。 运算符：指常量/变量之间进行何种运算。 表达式：由常量、变量加运算符构成。一个表达式可能包含多次多种运算，与数学表达式在形式上很接近。例如：1+2、2*(x+y)、0 函数：是相对独立的功能单位，可执行一定的任务。 语句：是由函数、表达式调用组成的。另外，各种控制结构也属于语句，例如： if语句、for语句。 类：是同一类事物的抽象。我们处理的数据都可以看做数据对象。Python是面向对象的程序设计语言，它是一个事物的静态特征（属性）和动态行为（方法）封装在一个结构里，称之为对象。 书写格式 缩进：使用缩进来区分代码块的级别。Python语言中没有采用花括号或begin...end等来分隔代码块，而是使用冒号和代码缩进来区分代码之间的层次。代码缩进是一种语法规则，错误的缩进可能导致代码的含义完全不同。建议使用在缩进代码前输入4个空格来表示代码缩进，不推荐其他数量的空格或使用制表符的方式来完成缩进。 分号：Python允许在行尾加分号，但不建议加分号，也不要用分号将两条命令放在同一行中。建议每一条命令单独一行。 长语句行：除非遇到长的导入模块语句或者注释里的URL，建议不宜超过80个字符。对于超长语句，允许但不提倡使用反斜杠连接行，建议在需要的地方使用圆括号来连接行。 # 不推荐写法 year1 = 2016 if year1 % 4 == 0 and year1 % 100 != 0 or \\ year1 % 400 == 0: print(year1,\"是闰年！\") else: print(year1,\"不是闰年！\") # 推荐写法 year2 = 2018 if (year2 % 4 == 0 and year2 % 100 != 0 or year2 % 400 == 0): print(year2,\"是闰年！\") else: print(year2,\"不是闰年！\") 括号：不建议使用不必要的括号，除非用于实现行连，否则不要在返回语句或者条件语句中使用括号，例如： # x两侧的括号多余 if (x): foo() # x两侧的括号多余 if not (x): foo() # x两侧的括号多余 return (x) 空行：变量定义、类定义以及函数定义之间可以空两行。类内部的方法定义之间，类定义与第一个方法之间，建议一行。函数或方法中，如果有必要，可以空一行。 空格：对于赋值(=)、比较（==,,!=,<>,=,in,not in,is,is not）、布尔（and,or,not）等运算符，在运算符两边各加一个空格，可以使代码更清晰。而对于算数运算符，可以按照自己的习惯决定，但建议运算符两侧保持一致。例如： #不推荐写法 x==1 #推荐写法 x == 1 Python文件的执行 Python文件以.py为后缀。一般在终端里，通过python test.py的方式来运行Python文件。 练习 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter2/第2节 Linux基本操作.html":{"url":"content/chapter2/第2节 Linux基本操作.html","title":"第2节 Linux基本操作","keywords":"","body":"第2节 Linux基本操作 树莓派运行的Raspberry Pi OS操作系统是一个Linux的发行版本，我们需要了解Linux的基本概念和操作。 内容提要 了解Linux终端 体验Linux终端的基本操作 学会Linux终端下的文件的基本操作 学会Linux终端下Nano编辑器 背景知识 1. 终端 终端（Terminal）也称终端设备，是计算机网络中处于网络最外围的设备，主要用于用户信息的输入以及处理结果的输出。在此处为Linux操作系统用于用户输入信息和输出信息的窗口，也是人机交流的窗口。 2. Shell Shell 是一个程序，同时它又是一种程序设计语言。作为命令语言，它交互式解释和执行用户输入的命令或者自动地解释和执行预先设定好的一连串的命令；作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。 在后边的学习中我们只会用到Shell命令，并且通过这些命令与Linux内核沟通，让树莓派执行我们想要的操作。 Linux目录结构 在Linux系统中，目录被组织成一个单根倒置树结构，文件系统从根目录开始，用/来表示。路径用/来进行分割（windows中使用\\来分割）。 目录名称 功能 / 根目录，位于Linux文件系统目录结构的顶层，一般根目录下只存放目录，不要存放文件 /bin 提供用户使用的基本命令， 存放二进制命令，不允许关联到独立分区 /boot 用于存放引导文件,内核文件,引导加载器 /sbin 管理类的基本命令，不能关联到独立分区，OS启动时会用到的程序 /lib 存放系统在启动时依赖的基本共享库文件以及内核模块文件 /lib64 存放64位系统上的辅助共享库文件 /etc 系统配置文件存放的目录，该目录存放系统的大部分配置文件和子目录，不建议在此目录下存放可执行文件 /home 普通用户主目录，当新建账户时，都会分配在此，建议单独分区，并分配额外空间用于存储数据 /root 系统管理员root的宿主目录 /media 便携式移动设备挂载点目录 /mnt 临时文件系统挂载点 /dev 设备（device）文件目录，存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，存放连接到计算机上的设备 /opt 第三方应用程序的安装位置 /srv 服务启动之后需要访问的数据目录，存放系统上运行的服务用到的数据 /tmp 存储临时文件， 任何人都可以访问,重要数据一定不要放在此目录下 /usr 应用程序存放目录，/usr/bin 存放保证系统拥有完整功能而提供的应用程序， /usr/share 存放共享数据，/usr/lib 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件，/usr/local 存放软件升级包，第三方应用程序。 /var 放置系统中经常要发生变化的文件，如日志文件 /proc 用于输出内核与进程信息相关的虚拟文件系统，目录中的数据都在内存中 /sys 用于输出当前系统上硬件设备相关的虚拟文件系统 /selinux 存放selinux相关的信息安全策略等信息 常用的Linux命令 可以使用[命令] --help获得详细使用说明。如ls --help 1. 基本文件操作 命令 操作 举例 ls 显示文件和目录列表(list) ls -a 显示隐藏文件 pwd 显示当前工作目录(print working directory) touch 创建空文件 touch test.bin mkdir 创建目录 mkdir testfolder cp 复制文件或目录 cp test.bin testfolder/test.bin.copy mv 移动文件或目录或改名 mv testfolder /usr/foldertest rm 删除文件或目录 rm -r /usr/folder cat 显示文件内容 cat test.bin tar 打包或解压文件或目录 tar -cf test.tar.gz test.bin 压缩tar -xf test.tar.gz解压 2. 树莓派上的软件管理工具apt 命令 操作 apt update 更新软件源 apt upgrade 更新已安装的软件版本 apt dist-upgrade 更新系统 apt install [软件名] 安装软件 apt remove [软件名] 移除软件而保留配置 apt purge [软件名] 彻底移除软件 apt autoremove 自动卸载不需要的软件包 apt-cache search [软件名] 搜索指定名称的软件包 apt-cache show [软件名] 获取包的相关信息，如说明、大小、版本 apt source [软件名] 下载软件包的源代码 apt clean 清理无用软件包 apt autoclean 清理无用软件包 3. 使用文本编辑器nano编辑文件 命令 操作 nano -c test.bin 打开文件并显示行号 sudo nano test.bin 使用管理员权限打开文件 Ctrl + O 保存 Ctrl + X 退出 4. 其他常见命令 命令 操作 Tab键 自动补齐 man [命令] 查看命令使用手册 ifconfig 查看当前网路连接状态以及IP地址 ping [IP地址]/[URL] 检测与某个IP地址是否连通 sudo raspi-config 打开树莓派配置界面 只针对树莓派系统 date 查看当前系统时间 ps -ax 显示当前运行的进程 kill -9 [进程号] 关闭某个进程 top 实时显示各个进程对资源的占用情况 passwd 设置用户密码 groups 显示当前用户所属组 clear 清空终端屏幕 uname -m 显示机器的处理器架构 which [命令] 在系统中搜索命令以确定该命令是否存在 shutdown -r now 重启系统 shutdown -h now 关机 练习：文件操作 尝试完成下面的题目。在下面的交互终端中进行练习。相关命令的说明见下表。 切换目录到/usr，新建一个名为hello_linux.bin的新文件，和一个名为linux_Home的文件夹 将hello_linux.bin的文件复制一份到linux_Home文件夹中，并把文件改名为.hello_linux.bin.back 用文字编辑器打开.hello_linux.bin.back，输入一段话The Raspberry Pi is a tiny and affordable computer that you can use to learn programming through fun, practical projects. 压缩linux_Home文件夹为linux.tar.gz，并将其移动到用户目录下 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter2/第3节 搭建网络服务.html":{"url":"content/chapter2/第3节 搭建网络服务.html","title":"第3节 搭建网络服务","keywords":"","body":"第3节 搭建网络服务 我们在后面的章节中会接触到很多和网络相关的内容，比如第三章的小车控制，是开发板作为服务器，使用手机等访问服务器，对小车进行运动控制，接收服务器传来的小车摄像头画面等。第六章通过物联网平台，控制机器人的姿态、语音交互、各种传感器数据的读取和处理等。 内容提要 知道OSI网络模型 会安装简单的网络服务器 体验静态博客系统，积木编程服务的搭建 安装配置基于MySQL，PHP，Nginx的博客系统（选做） OSI七层网络模型 OSI（Open System Interconnect），即开放式系统互联。 一般都叫OSI参考模型，是ISO（国际标准化组织）组织在1985年研究的网络互连模型。是互联网最基本也是重要的知识。 ISO为了更好的使网络应用更为普及，推出了OSI参考模型。其含义就是推荐所有公司使用这个规范来控制网络。这样所有公司都有相同的规范，就能互联了。 OSI七层模型的划分 OSI定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），即ISO开放互连系统参考模型。如下图。 每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI的服务定义详细说明了各层所提供的服务。某一层的服务就是该层及其下各层的一种能力，它通过接口提供给更高一层。各层所提供的服务与这些服务是怎么实现的无关。 传输层协议：TCP、UDP 顾名思义，传输层主要的功能是传递信息。传输层建立了主机端到端的链接，我们通常说的，TCP UDP就是在这一层。端口号即是这里的“端”。端是由应用层来决定的。 我们在后面章节接触到的机器人或小车，我们也是通过TCP协议，通过访问IP地址和端口号，来与它们交换信息的。 应用层协议：HTTP、FTP、SMB 网络中的计算机是通过IP地址来代表其身份的，IP地址（公网IP）能表示某台特定的计算机，但是一台计算机上可以同时提供很多个服务，如数据库服务、FTP服务、Web服务等，我们就通过端口号来区别相同计算机所提供的这些不同的服务，如常见的端口号21表示的是FTP服务，端口号23表示的是Telnet服务端口。端口号80和443是http常用的端口。同学们可以在浏览器的地址栏尝试输入、，观察有无区别。一般来说，网址或IP地址后面如果不输入特定端口，默认是80端口。 Web服务器Apache与Nginx Apache是Apache软件基金会下的一个项目—Apache HTTP Server Project，Nginx同样也是一款开源的HTTP服务器软件。HTTP服务器软件本质上也是一种应用程序——它通常运行在服务器之上，绑定服务器的IP地址并监听某一个端口来接收并处理HTTP请求，这样客户端（一般来说是 IE, Firefox，Chrome这样的浏览器）就能够通过HTTP协议来获取服务器上的网页、文档、音频、视频等等资源。 练习1：使用Nginx发布网页 我们后面使用的树莓派，运行的是Linux的一个重要的发行版Debian。在Debian操作系统，通过终端可以很方便地安装和部署Nginx服务器。 在树莓派上安装Nginx 打开终端 运行命令sudo apt install nginx 安装完毕后，运行sudo systemctl enable nginx，sudo systemctl status nginx 打开浏览器，输入树莓派的IP地址，看看是不是打开了一个Nginx的说明页呢，这就表示我们安装成功了。其他同学可以通过访问你的树莓派IP地址，来看到你发布的内容了。网站的搭建是不是非常简单呢？ 在Windows上安装Nginx 搭建Scratch与Blockly编程平台 这只可爱的小猫就是Scratch的吉祥物。Blockly和Scratch都是开源的网络程序。Scratch比Blockly更早诞生，到了Scratch 3.0，Scratch开始使用Blockly进行构建。我们可以比像部署WordPress或Typecho更容易来在服务器上部署Blockly和Scratch。 上图是Blockly的一个Demo。通过它，我们可以用积木的方式来控制小车和机器人、灯、甚至是电视机和空调。在后面的学习中，我们将深入地了解它们。 Node.js和LMNP 简介 练习2：使用Gitbook发布个人网站（选做） 同学们如果对搭建个人网站感兴趣，可以了解一下以下网站系统，WordPress是基于PHP和MySQL的一个个人博客网站系统，Typecho是一个较为轻量级的个人博客网站系统。 本在线课程使用的是Gitbook服务。 Gitbook文件结构 _book： 为编译好的静态站点 content：课程文件目录 node_moudles：gitbook 插件等文件 book.json：配置文件，主要用于添加插件和插件配置信息 SUMMARY.md：gitbook 目录和文档架构，在 content 中更改文件名称或增加减少文件需要在SUMMARY.md中同步改动 安装和初始化 安装 node.js。推荐使用nvm安装 打开终端，执行curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.36.0/install.sh | bash 安装 gitbook npm install gitbook-cli -g 建立工作文件夹 在~路径下使用mkdir命令新建一个名叫mygitbook的文件夹，并用cd命令切换到这个文件夹 初始化 gitbook init 在使用 gitbook init 之后本地会生成两个文件 README.md 和 SUMMARY.md ，这两个文件都是必须的，一个为介绍，一个为目录结构。 编辑README.md 还记得nano命令么？用它编辑README文件，随便写几句话然后保存。 gitbook使用Markdown语法书写。Markdown 是一种文本格式。你可以用它来控制文档的显示。使用 markdown，你可以创建粗体的文字，斜体的文字，添加图片，并且创建列表等等。基本上来讲，Markdown 就是普通的文字加上 # 或者 * 等符号。详细语法可参看这里。 本地预览 gitbook serve 执行这个命令后，可以按照提示打开地址，如http://localhost:4000地址查看你的站点。按Ctrl+C结束任务。 发布电子书 gitbook build 该命令会在当前文件夹中生成 _book 文件夹，这个文件夹中的内容就是静态网页版电子书。 在Nginx配置文件中正确配置此文件夹的路径，就可以通过Web服务访问到你的站点了。执行完下面的操作后，打开浏览器访问http://localhost:8000，邀请其他同学通过http://你的IP地址:8000访问你的站点吧。如果你的IP地址是公网IP，那么世界上的任何人都可以通过它来访问你的站点了。 # 获取当前地址，这会输出`/home/你的用户名/mygitbook` pwd # Nginx配置 sudo nano /etc/nginx/conf.d/mygitbook.conf ## 输入以下内容 server{ listen 8000; server_name _; root /home/你的用户名/mygitbook/_book; index index.html; } ## 保存后退出nano，然后执行 sudo nginx -s reload 安装插件（选做） gitbook拥有很多插件，使用这些插件，可以为站点增加不同的功能。 在 book.json 的 \"plugins\" 字段中添加需要安装的插件名称 打开 terminal 切换到 gitbook 项目路径 运行命令 gitbook install，程序会自动按照 book.json 中的配置安装插件 练习3：使用Typecho发布个人网站（选做） 在运行Ubuntu 20.04或Linux Mint 20的操作系统上执行以下命令。 环境安装 sudo apt install nginx sudo apt install mysql-server sudo apt install php sudo apt install php-fpm sudo apt install php-mysql php-gd php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-snmp php-soap 启动服务 sudo systemctl enable mysql sudo systemctl enable nginx sudo systemctl enable php7.4-fpm mysql配置 # mysql安装后，切换到root用户，可以直接用mysql命令登陆，没有密码。 # 如果你不知道或未设置root密码，使用以下命令为root用户指定一个密码。 sudo passwd root # 切换到root用户 su root #进入mysql mysql # mysql8修改密码 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456'; # 创建数据库 CREATE DATABASE typecho; PHP-fpm配置 cd /etc/php/7.4/fpm/pool.d cat www.conf |grep fpm.sock # 找到isten = /run/php/php7.4-fpm.sock nginx配置 # 删除默认配置文件 sudo rm /etc/nginx/site-enabled/default # 在此处增加配置文件：/etc/nginx/conf.d/typecho.conf server { listen 80; server_name _; root /home/niji/www/typecho; index index.php index.html; location ~ \\.php$ { include snippets/fastcgi-php.conf; # 此行填写上一步找到的路径 fastcgi_pass unix:/run/php/php7.4-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; } } location / { try_files $uri $uri/ /index.php$is_args$args; } error_page 404 /404.html; location = /40x.html{ } error_page 500 502 503 504 /50x.html; location = /50x.html{ } # 保存后重新加载Nginx配置 sudo nginx -s reload 获取typecho代码 cd ~ # 为网站创建目录 mkdir -p www/typecho cd www # 下载并解压源码 wget http://typecho.org/downloads/1.1-17.10.30-release.tar.gz tar -xzvf 1.1-17.10.30-release.tar.gz mv 1.1-17.10.30-release typecho # 为目录设置正确的用户权限 chown -R www-data:www-data typecho 安装typecho 访问网址 ，按提示进行安装 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter2/第4节 认识开源硬件.html":{"url":"content/chapter2/第4节 认识开源硬件.html","title":"第4节 认识开源硬件","keywords":"","body":"第4节 认识开源硬件 开源（open source）这个词，指的是事物规划为可以公开访问的，因此人们可以修改并分享。如今，开源概念包括开源项目、产品，或是自发倡导并欢迎开放变化、协作参与、快速原型、公开透明、精英体制以及面向社区开发的原则。 内容提要 知道开源到概念，了解主要的开源协议 了解开源硬件的概念和分类 了解开源硬件的基本操作 什么是开源 开放源代码（Open source code）也称为源代码公开，指的是一种软件发布模式。一般的软件仅可取得已经过编译的二进制可执行档，通常只有软件的作者或著作权所有者等拥有程序的原始码。有些软件的作者会将原始码公开，被公开的原始程序代码称为开放源代码。开放源代码软件源于自由软件开源运动，简称开源软件。是指那些源代码公开，可以被自由使用、复制、修改和再发布的一系列软件的集合。由此得出开源软件的几个特点，即： 代码自由使用并可再发行 开源软件发行时其源代码要一并发行 允许他人对既有的源码进行修改并再次发布 原始创作者保证源代码的完整性 不歧视程序在任何领域内的使用 基于源程序的新产品也要遵循同样的开源许可协议等 开源许可协议 自由软件/开源软件是自由的，免费的，源代码开放的，可自由下载安装和使用。同时，为了维护作者和贡献者的合法权利，保证这些软件不被一些商业机构或个人窃取，影响软件的发展，开源社区开发出了各种的开源许可协议，如：GPL协议，COPYLEFT协议，LGPL协议，Apache License协议，BSD协议 。 重点介绍GPL协议，其授予程序接受人以下权利： 以任何目的运行此程序的自由 以学习程序工作机理为目的，对程序进行修改的自由(能得到源代码是前提) 再发行复制件的自由 改进此程序，并公开发布改进的自由 例如：全球所有搭载Android操作系统的手机， 其操作系统部分要遵循一定的开源协议，因为Android操作系统的内核是Linux，而Linux正是基于开源许可协议GPL协议的操作系统，所以，以它为核心的Android也要遵循同样的GPL协议。 开源硬件的分类 主控板 开源硬件中有一部分根据其功能作用，称之为主控板。而主控板上的核心正是能够运行程序代码的“小电脑”，它能将我们的想法，也就是程序转换为其上引脚电信号的变化，通过这些变化的电信号来达成我们的想法。 外设和传感器 外设包括舵机，云台，电机，扩展板等，也包括摄像头，麦克风等人工智能套件。 传感器包括超声波传感器，电磁传感器，温湿度传感器等。 主要的开源硬件 树莓派 Arduino ESP8266 Arduino电机扩展板 此扩展板搭载了两颗L293DD电机驱动芯片和独立的稳压电路，可通过DC插头给该扩展板提供外部5V-12V电源，2颗L293DD电机驱动芯片可驱动4个直流电机，为小车平台提供了驱动基础。由于直流电机可通过电流的方向来改变转向，即可通过互换直流电机的两根引线来改变电机的运转方向。 Arduino Nano扩展板 此扩展板为引脚和电源扩展板，即把体积较小的Arduino Nano的所有引脚都印出来，并对每个引脚都配有供电引脚(VCC和GND)，同时配有5mmDC接口，可接7-12V电源给arduino nano供电，且每个数字引脚都符合舵机控制线的定义，可以直接接入舵机。此扩展板与Arduino Nano的组合状态如下图： NodeMcu电机扩展板 此电机扩展板集成一颗L293DD直流电机驱动芯片，可以同时驱动两路直流电机，同时将NodeMcu开发板的所有引脚印出来，并对每个引脚配有电源(VCC和GND)插针，可直接入舵机，并可为需要5V或3.3V电源的设备供电，同时也可以通过VIN接线端子输入5V电源，Power开关可控制外部电源的通断。 NodeMcu与此扩展板组合状态如下图所示： NodeMcu电机扩展板的外部接线 树莓派电机扩展板 此电机扩展板通过I2C接口接入树莓派，通过I2C总线芯片外挂两颗直流电机驱动芯片，可同时驱动4个直流电机，同时又引出了单独的一组I2C总线接口，除此之外，此扩展板带有4个标准舵机PWM输出接口，可以控制4路舵机。由于该扩展板为大功率输出板，所以板上带有独立外部供电接口，使用此驱动板控制电机时需要外接5V-12V电源，否则不能正常工作。 此电机扩展板与树莓派组合状态如下图: 舵机 如上图所示,舵机是一种由直流电动机，减速齿轮组，角度控制器和动力输出轴组成的一种动力提供机械，主要作用是根据控制信号使动力输出轴转动一定角度。通常使用舵机来控制一些车船模型，以及机器人等。 舵机有3条线，其定义见下表：|颜色|作用| :-:|:-: |黄色|控制信号(PWM)输入线| |红色|5V供电线(电源正极)| |GND|电源负极| 注：第一根黄色线为信号线，需要为其输入PWM(脉冲宽度调制)信号才能使舵机正常工作。如下图所示： 即在一个脉冲循环内，高电平持续时间占总循环时间的比率(占空比)越大，舵机转动的角度就越大。 直流电机 小车直流电机也叫TT电机，单个电机由一个直流马达和苏联减速齿轮构成，通过控制直流马达的正反转控制方向，控制直流马达的转速来控制速度。在实际使用时可通过调换两条引出线在驱动板的位置来更改旋转方向。 超声波测距传感器 超声波测距传感器(如下图所示)通过发出超声波(频率为20000Hz的声波)，再被阻挡物体表面反射，反射的超声波又被接收装置接收，然后按下方照公式计算出来：距离 = 声速 x 发出超声波到被接收返回的时间 / 2 超声波测距传感器的接口有4根引脚，基本定义为：|名称|作用| :-:|:-:| |VCC|5V供电接口(电源正极)| |Trig|触发控制信号输入| |Echo|回响信号输出| |GND|电源负极| DHT22温湿度传感器 DHT22温湿度传感器也称AM2302，是一款含有已校准数字信号输出的温湿度复合传感器，湿度量程范围0~99.9%RH，精度±2%RH，而温度量程范围是-40℃~80℃，精度±0.5℃。DHT22传感器也是单总线传感器，即其输出的数据通过一个引脚即可输出，其接口定义如下表所示：|名称|作用| :-:|:-:| |VCC(+)|5V供电接口(电源正极)| |out|信号输出引脚| |GND(-)|电源负极| 电磁传感器 电磁铁是给绕在铁质内芯的线圈通电而产生磁力，而断电后磁力消失的装置。其控制接口定义如下表所示： |名称|作用| :-:|:-: |S(signal)|开关控制信号：高电平产生磁力；低电平磁力消失| |+(5V)|电源正极| |-(GND)|电源负极| 以Arduino UNO为例，电磁铁的接线方法如下图： ESP32-Cam无线摄像头 ESP32-Cam是以ESP32芯片为计算核心，并搭载原生WiFi控制器的无线摄像头。它能够根据用户烧录的程序代码，使用户在连接它wifi名称的电脑网页端看到摄像头拍摄的实时视频，如下图所示： 由于此模块已提前烧录好程序，且其在小组局域网中的IP地址也已固定下来，所以在使用时只需按照下图连接电源线，稍等片刻，在同局域网电脑的浏览器中输入该摄像头的IP地址，按回车即可： © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-16 "},"content/chapter3/第3章简介.html":{"url":"content/chapter3/第3章简介.html","title":"第3章 小白的诞生","keywords":"","body":"第3章 硬件基础—智能小白 本章主题：了解硬件操作 主要使用ESP8266提供Web服务，来控制电机、舵机、传感器等，实现远程遥控、控制机械臂抓取、远程视频监控等功能。可以通过积木编程的方式来对小车的功能进行编程。 本章重点 了解开源硬件和电路、网络的基础知识 掌握一定的通过开源硬件解决实际问题的能力 涉及软硬件 ESP8266，ESP32-CAM 小车套件（可3D打印） 舵机，灰度传感器、超声波传感器等 自行开发的物联网控制平台 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter3/第1节 小白的心脏—ESP8266开发板.html":{"url":"content/chapter3/第1节 小白的心脏—ESP8266开发板.html","title":"第1节 小白的心脏—ESP8266开发板","keywords":"","body":"第1节 小白的心脏—ESP8266开发板 熟悉操作ESP8266的步骤。包括功能提出和实现，硬件连接，上传的参数调节和html文件在本地服务器中的打开，传感器数据的实时呈现等，并使用chart.js来绘制实时变化曲线。这部分主要包括两种传感器的读取：温湿度传感器和超声波传感器 活动目标 了解物联网的基本概念 了解使用开发板读取传感器的基本原理 熟悉使用Arduino IDE烧录固件的操作流程 背景知识：物联网 原理图 传感器-->小白: WiFi/GPIO 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.提交执行动作请求，如“前进” 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 ESP8266是WiFi串口模块，功能简单来讲就是：从WiFi接收到数据，串口输出；从串口接收数据，WiFi输出数据。 通过自带的GPIO口连接传感器，传感器将环境数据转化为电信号发送给ESP8266读取、处理并输出。 硬件准备 硬件清单 ESP8266主板 温湿度传感器（型号为DHT11或DHT22） 超声波传感器（型号为HC-SR04） 杜邦线、数据线 实验1：简单温湿度数据读取 1.硬件连接 2.烧录程序到开发板 打开项目文件夹learn-ai/codes/chapter3/part1_Sensor/ESP8266_dht11_http 将ESP8266通过数据线连接到电脑 使用Arduino IDE打开文件ESP8266_dht11_http.ino 记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 3.读取温湿度传感器数据 打开路由器管理地址，ESP8266此时应该已经加入到了局域网中，查看ESP8266获取到的路由器地址 在浏览器中打开ESP8266获取到的局域网地址，查看温湿度传感器的读数 通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 实验2：温湿度实时变化曲线绘制 1.硬件连接 2.烧录程序到开发板 打开项目文件夹learn-ai/codes/chapter3/part1_Sensor/ESP8266_dht11_http_chartjs 将ESP8266通过数据线连接到电脑 使用Arduino IDE打开文件 ESP8266_dht11_http_chartjs.ino 记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 3.读取温湿度传感器实时曲线 打开路由器管理地址，ESP8266此时应该已经加入到了局域网中，查看ESP8266获取到的路由器地址 在浏览器中打开ESP8266获取到的局域网地址，查看温湿度传感器的读数 通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 实验3：超声波距离测量 1.硬件连接 2.烧录程序到开发板 打开项目文件夹learn-ai/codes/chapter3/part1_Sensor/ESP8266_ultrasonic_http 将ESP8266通过数据线连接到电脑 使用Arduino IDE打开文件 ESP8266_ultrasonic_http.ino 记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 3.超声波传感器数据读取 打开路由器管理地址，ESP8266此时应该已经加入到了局域网中，查看ESP8266获取到的路由器地址 在浏览器中打开ESP8266获取到的局域网地址，查看距离传感器的读数 通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter3/第2节 无线控制—遥控小车.html":{"url":"content/chapter3/第2节 无线控制—遥控小车.html","title":"第2节 无线控制—遥控小车","keywords":"","body":"第2节 无线控制—遥控小车 使用ESP8266开发板，组装并遥控一辆小车，通过网页端发送命令来遥控它 活动目标 了解HTTP通信概念 体验使用开发板控制电机 学会使用ip地址访问服务器 背景知识：电机 电机一般用作小车的动力系统。当电机接上正向电压时，电机会正转，当电机接上反向电压时，电机会反转。当电机接上的电压不同时，电机转动的速度也会有所不同。由于开发板能提供给小车的电压有限，所以我们通常不会直接将电机接在开发板上，而是会找一块电机驱动扩展板。 原理图 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.提交执行动作请求，如“前进” 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 硬件清单 小车套件(底盘和夹层，电机，车轮，万向轮，铜柱等) ESP8266开发板 电机扩展板 杜邦线，数据线 移动电源 实验：WiFi小车 1.硬件连接 将两个车轮分别与电机相连 使用理线带，将电机和万向轮固定在底盘上 使用铜柱，增加一层夹层 将ESP8266开发板和电机扩展板如图相连，将电机连接到图示位置。 使用数据线连接ESP8266开发板和移动电源，将移动电源置于小车夹层并加以固定 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part2_WiFiCar/ESP8266_wificar_http 2).将ESP8266通过数据线连接到电脑3).使用Arduino IDE打开文件ESP8266_wificar_http.ino4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 5).点击工具菜单，选择ESP8266 Sketch Data Upload,会自动将项目目录下的data文件夹上传到ESP8266开发板上 3.开始无线控制 1).打开路由器管理地址，ESP8266此时应该已经加入到了局域网中，查看ESP8266获取到的路由器地址2).将ESP8266与电脑连接断开，连接到移动电源上3).在浏览器中打开ESP8266获取到的局域网地址，通过点击上下左右按钮或键盘的光标键来控制小车4).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter3/第3节 汽车人小白—机械臂.html":{"url":"content/chapter3/第3节 汽车人小白—机械臂.html","title":"第3节 汽车人小白—机械臂","keywords":"","body":"第3节 汽车人小白—机械臂 使用ESP8266，通过网页端发送命令，控制多个舵机 活动目标 了解舵机的基本概念 了解使用开发板控制动力设备的基本原理 熟悉使用Arduino IDE烧录固件的操作流程 背景知识：舵机 伺服电机通常被称为舵机，它是一种带有输出轴的小装置。当我们向伺服器发送一个控制信号时，输出轴就可以转到特定的位置。只要控制信号持续不变，伺服机构就会保持轴的角度位置不改变。如果控制信号发生变化，输出轴的位置也会相应发生变化。日常生活中，舵机常被用于遥控飞机、遥控汽车、机器人等。 舵机内部的控制电路、电位计（可变电阻器）和电机均被连接到电路板上。控制电路通过电位计可监控舵机的当前角度。 其工作流程为：控制信号 → 控制电路板 → 电机转动 → 齿轮组减速 → 舵盘转动 → 位置反馈电位计 → 控制电路板反馈。 1.脉冲宽度调制（PWM） 脉冲宽度调制，英文名Pulse Width Modulation，缩写为PWM，它是通过对一系列脉冲的宽度进行调制，等效出所需要的波形，对模拟信号电平进行数字编码。 2.占空比 占空比是指在一个周期内，信号处于高电平的时间占据整个信号周期的百分比。 上图信号一个周期的时间为4ms，其中高电平时间为1ms。占空比为： 原理图 舵机机械臂->小白: GPIO 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.提交执行舵机角度请求 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 硬件清单 ESP8266主板 电机扩展板 esp12E Motor Shield 舵机 杜邦线、数据线 机械臂和零件 实验：机械臂 1.硬件连接 此处表示舵机连接到了D0口，最多可以连9个舵机（D0-D9） 黄色-信号D（DATA） 红色-正极V（VCC） 棕色-负极G（GND） 2.烧录程序到开发板 1).打开项目文件夹learn-ai/codes/chapter3/part3_ServoArm/ESP8266_servoarm_http 2).将ESP8266通过数据线连接到电脑 3).使用Arduino IDE打开文件ESP8266_servoarm_http.ino 4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 5).点击工具菜单，选择ESP8266 Sketch Data Upload,会自动将项目目录下的data文件夹上传到ESP8266开发板上 3.开始机械臂控制 1).打开路由器管理地址，ESP8266此时应该已经加入到了局域网中，查看ESP8266获取到的路由器地址2).将ESP8266与电脑连接断开，连接到移动电源上 3).在浏览器中打开ESP8266获取到的局域网地址，通过拖动滑块来控制机械臂 4).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter3/第4节 视物而行—远程视频救援.html":{"url":"content/chapter3/第4节 视物而行—远程视频救援.html","title":"第4节 视物而行—远程视频救援","keywords":"","body":"第4节 视物而行—远程视频救援 也许，你会希望在小车上装一个摄像头，这样就可以身临其境的遥控它了。ESP32是ESP8266的升级版本。拥有更强的处理能力，能够很好的处理实时视频和音频等数据。通过本部分来为小车增加实时视频的功能 活动目标 确定活动方向并提出需要解决的问题 了解esp32的功能及引脚并熟练了解实验步骤 按照操作步骤实际操作并完成小车实时摄像等相关功能 对实验进行总结，并分析遇到的问题 背景知识：ESP32 esp32是一系列低成本，低功耗的片上 微控制器系统，集成了Wi-Fi和双模蓝牙。esp32包括双核和单核变体，包括内置天线开关，功率放大器，低噪声接收放大器，滤波器和电源管理模块。 原理图 舵机机械臂->小白: GPIO 摄像头->小白: WiFi 小白->手机浏览器: 1.建立局域网服务器 手机浏览器-->小白: 2.通过WiFi访问控制界面 手机浏览器-->小白: 3.查看实时画面，提交控制请求 小白->手机浏览器: 4.服务器响应请求，让小白的动力系统执行 硬件清单 esp32主板 ov2640摄像头 USB转TTL编程器 杜邦线 双自由度舵机云台 实验：远程救援车 1.硬件连接 注意：IO0口需要和它边上的GND口用一根杜邦线连接到一起，这样才可以正常上传代码 2.烧录程序到开发板esp32 1).打开项目文件夹learn-ai/codes/chapter3/part4_FirstAid/esp32_camerawebserver 2).将上图连接好后，将USB转TTL编程器插入电脑3).使用Arduino IDE打开文件esp32_camerawebserver.ino4).配置esp32的上传环境如下图所示： 5).上传完毕后，保持USB连接在电脑上。将IO0口需要和它边上的GND口杜邦线拔掉，按一下esp32主板上面的reset键 3.烧录程序到开发板ESP8266 1).打开项目文件夹learn-ai/codes/chapter3/part4_FirstAid/ESP8266_firstaid_http 2).将ESP8266通过数据线连接到电脑 3).使用Arduino IDE打开文件ESP8266_firstaid_http.ino 4).记得把前面的环境准备部分再次确认，将环境正确配置，然后点击上传按钮进行上传 5.点击工具菜单，选择ESP8266 Sketch Data Upload,会自动将项目目录下的data文件夹上传到ESP8266开发板上 4.远程视频救援控制 1).打开路由器管理地址，esp32此时应该已经加入到了局域网中，查看esp32和ESP8266获取到的路由器地址2).在浏览器中打开esp32获取到的局域网地址，在左侧最下方选择Start Stream 3).访问救援控制页面，将esp32的ip地址填入对应位置 4).通过内网转发技术，同学们在家里可以打开这里来查看老师手边传感器的实时读数。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter4/第4章简介.html":{"url":"content/chapter4/第4章简介.html","title":"第4章 机器视觉","keywords":"","body":"第4章 机器视觉—自动追踪小车大白 本章主题：机器视觉 从机器视觉出发，让学生理解机器视觉的相关概念和原理，辨别OpenCV和深度学习的异同点。使用OpenCV来处理视觉信号，并通过蓝牙或串口来将处理过的视觉信号发送给小车，从而实现物体追踪，人脸追踪，智能机械臂抓取等功能。 学生通过使用Python，完成信息采集：爬虫、多文件处理；信息处理：训练采集的数据，形成分类器，从而让计算机视觉系统能够对特定的物体进行分辨。 本章重点 了解计算机视觉的相关概念和原理 了解OpenCV和深度学习的关系和区别 了解Python在图像处理方面的一些基本操作 了解模式识别，会训练分类器，并使用开源硬件来对图像处理结果做简单的反馈 涉及软硬件 树莓派、Arduino 舵机、CSI摄像头、电磁传感器 小车套件 3D打印机 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter4/第1节 借我一双慧眼吧.html":{"url":"content/chapter4/第1节 借我一双慧眼吧.html","title":"第1节 借我一双慧眼吧","keywords":"","body":"第1节 借我一双慧眼吧 OpenCV的全名是Open Source Computer Vision Library。它是一个计算机视觉库，通过使用它，可以对计算机图像进行各种各样的处理。 从茹毛饮血的蛮荒，到钢筋水泥的城市，人类逐步将自身能力投射到计算机上。无论是计算能力，还是记忆能力，计算机的如今表现都堪称卓越。但仅拥有这些还远远不够，我们期待计算机可以做得更多。一部风靡全球《星际穿越》激起了无数人对探索浩瀚宇宙奥秘的渴望，也让许多人记住了Tars这个聪明可爱、幽默风趣的智能机器人。人工智能主题的好莱坞电影一直广受影迷们的喜爱，人类用无尽的想象力和炫目的特技构筑了一个又一个无比精彩的未来世界，令人如痴如醉。不过，回到现实，计算机科学家们的行动力却看似远远赶不上电影艺术家们的想象力，电影终归是电影，要研发出一个像Tars一样能看懂周围世界、听懂人类语言、并和人类进行流畅对话的智能机器人，我们要走的路还有很长。 长时间来，让计算机能看、能听、能说一直是我和计算机界同行们孜孜以求的目标。耕耘在计算机视觉领域十余年，赋予计算机一双慧眼，让它也能看懂这个多彩的世界，一直是激励着我在这条充满挑战的道路上前行的重要力量。虽然计算机暂时还无法像电影中所展现的那般智能，但已经取得了很多令人惊喜的成绩。在这篇文章中，我将就如何让计算机能“看”懂世界这个主题，为大家介绍计算机视觉的基本概念、这个领域面临的挑战、一些带来重要突破的技术并展望未来的演进趋势。 世界如何在我们眼中形成 对人类而言，“认人”似乎是与生俱来的本能，刚出生几天的婴儿就能模仿父母的表情；它赋予我们只凭极少细节就分辨彼此的能力，借着暗淡灯光我们仍能认出走廊那端的朋友。然而，这项对人类而言轻而易举的能力，对计算机而言却举步维艰。过去很长一段时间，计算机视觉技术徘徊不前，在进一步探求前，不如先谈谈我们是如何用眼睛观察世界的。 相信大家都在中学的物理课上尝过小孔成像的原理。不过人的眼睛要比小孔成像复杂得多，当我们观察物体时，每秒大约扫视3次，并有1次驻留。当视网膜的感光体感受到蜡烛的轮廓，一个被称为中央凹的区域其实是以扭曲变形的形式记录下蜡烛的形状。 那么问题来了，为何我们看到的世界既未扭曲也没有变形呢？很简单，因为人类拥有大脑皮层这个万能的“转换器”，它将我们的视觉神经捕捉到的信号转换为真实的形象。这个“转换器”可简化理解为四个区域，生物学家将它们分别称为V1、V2、V4和IT区。V1区的神经元，只针对整个视觉区域中很小的一部分做出反应，例如，某些神经元发现一条直线，就变得异常活跃。这条直线可以是任何事物的一部分，也许是桌边，也许是地板，也许是这篇文章某个字符的笔划。眼睛每扫视一次，这部分神经元的活动就可能发生快速变化。 奥秘出现在大脑皮层顶层的IT区，生物学家发现，物体在视野的任何地方出现（例如一张脸），某些神经元会一直处于固定的活跃状态中。也就是说，人类的视觉辨识是从视网膜到IT区，神经系统从能识别细微特征，到逐渐变为能识别目标。如果计算机视觉也可以拥有一个“转换器”，那么计算机识别的效率将大为提高，人眼视觉神经的运作为计算机视觉技术的突破提供了启迪。 计算机为何总是“雾里看花” 尽管人眼识别的奥秘已经被逐步揭开，但直接应用于计算机上却非易事。我们会发现计算机识别总是在“雾里看花”，一旦光线、角度等发生变化，计算机难以跟上环境的节奏，就会误识。对计算机而言，识别一个在不同环境下的人，还不如识别在同一环境下的两个人来得简单。这是因为最初研究者试图将人脸想象为一个模板，用机器学习的方法掌握模板的规律。然而人脸虽然看起来是固定的，但角度、光线、打扮不同，样子也有差别，都令简单的模板难以匹配所有人脸。 因此，人脸识别的核心问题在于，如何让计算机忽略同一个人的内部差异，又能发现两个人之间的分别，即让同一个人相似，不同的人有别。 对人工神经网络的引进是计算机视觉超越模板识别的关键。然而人类尚且未完全掌握神经的运作机制时，又该如何引导计算机进步呢？人工神经网络在1960年代就已萌芽，初期理论只固定在简单的模型之上，即生物课上的“输入-隐层-输出”模型。在介绍神经的工作原理时，老师们一般都会简单告知是外界刺激接触到输入神经元，输入神经元再链接其他部分形成隐层，最后通过输出神经元表现出来。这些神经元的链接强度并不相同，就像不同乐谱的强弱高低不同，人工神经网络就是依靠这些神经元之间不同的链接强度，学会将输入方式映射到输出上。 不过“乐谱”只是静止不动的，而且只能从“输入走向输出”，不存在反向呈现。也就是说如果人静止不动，计算机也许可以通过这一原理读出，但这在现实生活中不可能实现。1980年代末期，用于人工神经网络的“反向传播算法”发明，它能将输出单元的错误传回输入单元，并记住它。这种方法令人工神经网络能从大量训练样本中学习统计规律，对未知事件做出预测。不过与大脑的复杂及层级结构相比，这种只包含一个隐层的神经网络构造还显得微不足道。 深层神经网络为计算机“拨云见日” 2006年，多伦多大学教授Geoffrey Hinton在深层神经网络的训练上取得了突破。一方面，他证明了多隐层的人工神经网络具备更优异的特征学习能力，另一方面能通过逐层初始化克服此前一直困扰研究者的训练难题——基本原理是先通过大量无监督数据保证网络初始化，再用有监督数据在初始化好的或者是预训练的网络上优化调整。 受到这些因素的启发，如今的人脸或图像识别研究，大多基于CNN（Convolution Neural Networks）原理。CNN可以被视为一种逐层扫描的“机器”。第一层检测边缘、角点、平坦或不平坦的区域，这一层几乎不包含语义信息；第二层基于第一层检测的结果进行组合，并将组合传递给下一层，以此类推。多层扫描之下，累加准确率，计算机就在向前文提及的“让同一个人相似，不同的人有别”这一目标迈进。 CNN的学名为带有卷积结构的深度神经网络，这一网络识别物体还可分为两个步骤：图像分类和物体检测。在第一个阶段，计算机首先识别出物体的种类，例如人、动物或其他物品；第二个阶段，计算机获取物品在图像中的精确位置——这两个阶段分别回答了“是什么”和“在哪里”两个问题。微软的智能聊天机器人“小冰”具有辨识狗的品种的能力即是CNN的典型示例。首先，需要搭建一个好几层深度卷积网络。第一层跟人类视觉系统的定义很像，用来对一些小的边缘或者小的色块做一些检测；第二层会把这些小的结构组成大的结构，如狗腿和狗的眼睛；依次向上进行组织，最后就能鉴别出狗的种类来。其次，需要往这个带有卷积结构的深度神经网络里投入很多的图，训练系统识狗的准确度。 2013年，加州大学伯克利分校的研究者们提出了一种称为叫R-CNN方式（Region-based CNN）的物体检测方法，具有很高的识别准确度，它将每张图像分为多个窗口或个子区，在每个子区域应用神经网络进行分类。但其主要缺陷在于，对于实时检测，算法过慢。为了在一张图片上检测几个物体，整个神经网络可能需要运算上千次。 在微软亚洲研究院，视觉计算组的研究员们实现了一种称为空间金字塔聚合（Spatial Pyramid Pooling，SPP）的新算法，通过在内部特征识别，而不是每个区域从头检测，对整个图片只做一次计算。利用这种新算法，在不损失准确度的前提下，物体检测速度有了上百倍的提升。在2014年ImageNet大规模视觉识别挑战赛中，微软亚洲研究院采用SPP算法的系统取得了分类第三名和检测第二名的成绩。目前，这项技术已经成功转化进入OneDrive中。采用了这项技术后，OneDrive可以自动为上传的图片添加标签。同时，用户输入关键词，就可以搜索与之相对应的图片。 展望未来 计算机视觉和人类共舞 如果单纯识别面部，而不考虑发型和身体的其他部分，人类的正确率约为97.5%，而计算机目前则能达到99%以上。这是否意味着计算机已经胜过了人类？不是，因为我们不只观察面部，身材和体态都有助于我们认出对方。在复杂光照的真实环境下，人能够更智能地选择这些分支帮助自己决策，而计算机在这方面则要逊色许多。不过，如果数据量庞大，或者面对陌生的脸孔，计算机又更强大些。如果能够各扬其长，歌词中所唱的“借我一双慧眼吧”或许将会实现。 人类通过不断发明的新技术来替代旧技术去更高效和经济地完成任务。在计算机视觉领域亦是如此，我们开发更便捷人脸识别用于门禁系统，以替代手动的输入用户名和密码——Xbox One利用红外相机设计的人脸识别系统就颇受用户好评。 除上述人类自身也能做到的识别功能外，计算机视觉还可应用在那些人类能力所限，感觉器官不能及的领域和单调乏味的工作上——在微笑瞬间自动按下快门，帮助汽车驾驶员泊车入位，捕捉身体的姿态与电脑游戏互动，工厂中准确地焊接部件并检查缺陷，忙碌的购物季节帮助仓库分拣商品，离开家时扫地机器人清洁房间，自动将数码照片进行识别分类……或许在不久的将来，超市电子秤就能辨别出蔬菜的种类；门禁系统能分辨出带着礼物的朋友，抑或手持撬棒的即将行窃的歹徒；可穿戴设备和手机帮助我们识别出镜头中的任何物体并搜索出相关信息。更奇妙的是，它还能超越人类双眼的感官，用声波、红外线来感知这个世界，观察云层的汹涌起伏预测天气，监测车辆的运行调度交通，甚至突破我们的想象，帮助理论物理学家分析超过三维的空间中物体运动。 活动1：远程监控和自动避障 原理图 摄像头\\n机械臂\\n超声波传感器->大白\\n树莓派: CSI/USB/GPIO 大白\\n树莓派-->手机客户端: WiFi Note right of 大白\\n树莓派: 处理超声波传感器数据\\n接收客户端控制指令 手机客户端->大白\\n树莓派: 发送请求给服务器，让小绿的动力系统执行 硬件准备 智能车套件 树莓派及扩展板 两自由度舵机云台 CSI摄像头 热熔胶枪 硬件连接 组装小车 将树莓派及电机扩展板固定到小车上 将摄像头固定到舵机云台上，并将云台固定到小车上 将树莓派连接到移动电源，通电 避障小车启动 1.使用远程桌面连接到树莓派 Windows；按开始+R，输入mstsc，回车。在新的窗口中输入树莓派的IP地址。在新的窗口中输入树莓派的用户名pi和密码raspberry macOS:打开VNC viewer，输入树莓派的IP地址。在新的窗口中输入树莓派的用户名pi和密码raspberry 2.打开终端，输入cd ~/Desktop/learn-ai/codes/chapter4/part1_ObstacleAvoid/ObstacleAvoid 3.输入python run.py 4.在浏览器中输入树莓派IP 5.通过前后左右和舵机控制按钮来遥控小车。使用self_driving按钮来进行自动避障 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter4/第2节 大白智能分拣.html":{"url":"content/chapter4/第2节 大白智能分拣.html","title":"第2节 大白智能分拣","keywords":"","body":"第2节 大白智能分拣 使用OpenCV来识别圆形物体，若识别到则发送串口指令给Arduino。Arduino控制机械臂和电磁铁进行抓取 训练大白认识圆形 利用霍夫变换来进行圆环检测。一个圆环需要3个参数来确定，所以进行圆环检测的累加器必须是三维的，这样效率就会很低，因此OpenCV使用了霍夫梯度法这个巧妙的方法，来使用边界的梯度信息，从而提升计算的效率。 OpenCV中进行霍夫圆环检测的函数： cv2.HoughCircles(image, method, dp, minDist, circles=None, param1=None, param2=None, minRadius=None, maxRadius=None) 本例中使用的具体参数： cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT , 1, 100, param1=100, param2=100, minRadius=50,maxRadius=200) 参数解释： image：8位，单通道图像。如果使用彩色图像，需要先转换为灰度图像。 method：定义检测图像中圆的方法。目前唯一实现的方法是cv2.HOUGH_GRADIENT。 dp：累加器分辨率与图像分辨率的反比。dp获取越大，累加器数组越小。例如，如果dp= 1时，累加器和输入图像具有相同的分辨率。如果dp=2，累加器便有输入图像一半那么大的宽度和高度。 minDist：为霍夫变换检测到的圆的圆心之间的最小距离，即让我们的算法能明显区分的两个不同圆之间的最小距离。这个参数如果太小的话，多个相邻的圆可能被错误地检测成了一个重合的圆。反之，这个参数设置太大的话，某些圆就不能被检测出来了。 param1：有默认值100。它是method设置的检测方法的对应的参数。对当前唯一的方法霍夫梯度法，它表示传递给canny边缘检测算子的高阈值，而低阈值为高阈值的一半。 param2：也有默认值100。它是method设置的检测方法的对应的参数。对当前唯一的方法霍夫梯度法，它表示在检测阶段圆心的累加器阈值。它越小的话，就可以检测到更多根本不存在的圆，而它越大的话，能通过检测的圆就更加接近完美的圆形了。 minRadius：默认值0，表示圆半径的最小值。单位是像素。 maxRadius：也有默认值0，表示圆半径的最大值。单位是像素。 示例： 原始图像： 处理后图像： 会自动抓取硬币的机械臂 视觉图像经由OpenCV处理后，如果识别到圆形，就通过串口将信息发送给Arduino，Arduino接收到信号后，控制云台舵机转动，并通过电磁铁将圆形物品分拣处理 原理图 摄像头\\n机械臂\\n电磁传感器->大白\\n树莓派: CSI/USB/GPIO 大白\\n树莓派-->传送带: 摄像头实时监测 Note right of 大白\\n树莓派: OpenCV处理摄像头数据\\n发送指令给机械臂和电磁传感器 硬件准备 大白 Arduino CSI摄像头 摄像头桌面支架 待检测的圆形金属物体（任选） 硬件连接 将烧录好程序的Arduino通过USB连接到树莓派 电磁传感器连接到pin5，两个舵机连接到3和4 用乐高制作传送带和摄像头支架参考活动，将待检测的物体放置在传送带上，使传送带缓慢转动 USB摄像头垂直固定在传送带顶部，使之能够看到传送带上的物体 启动智能分拣系统 1.使用远程桌面或HDMI视频输出连接到树莓派 2.打开终端，输入cd ~/Desktop/learn-ai/codes/chapter4/part2_AutoSort/AutoSort 3.输入python classifier.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter4/第3节 大白自动追踪.html":{"url":"content/chapter4/第3节 大白自动追踪.html","title":"第3节 大白自动追踪","keywords":"","body":"第3节 大白自动追踪 通过拍照、爬虫等方式获取待训练图片，使用python进行简单的文件处理，用OpenCV训练后，可实现对特定物体的识别和追踪 级联分类器简介 目前图像检测方法主要分为两大类，基于知识和基于统计。 以人脸检测来说，基于知识的人脸检测方法主要包括：模板匹配，人脸特征，形状与边缘，纹理特征，颜色特征。 基于统计的人脸检测方法主要包括：主成分分析与特征脸法，神经网络模型，隐马尔可夫模型，支持向量机，Adaboost算法。 基于知识的方法将人脸看成不同特征的特定组合，即通过人脸的眼睛、嘴巴、鼻子、耳朵等特征及其组合关系来检测人脸。 基于统计的方法将人脸看成统一的二维像素矩阵，通过大量的样本构建人脸子空间，通过相似度的大小来判断人脸是否存在。 OpenCV采用的级联分类器，可以理解为将采用Adaboost算法构建的若干分类器串联起来，即级联。只有通过所有分类器后才识别为检测正确。这样可以提高检测的准确度。 OpenCV提供了若干已经提前训练好的级联分类器供使用，包括人体、人脸、猫咪等。 示例：识别猫脸 核心代码： String catFileName = \"~/opencv/build/etc/haarcascades/haarcascade_frontalcatface.xml\" CascadeClassifier catclassifier 结果： 活动1：人脸分类器：追着人跑的大白 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->Arduino: 串口指令 Note right of 大白\\n树莓派: OpenCV处理摄像头数据（级联分类器）\\n发送指令给Arduino 硬件准备 大白车 Arduino CSI摄像头 待识别的人或猫的照片（电子或纸质打印任选） 硬件连接 将烧录好程序的Arduino通过USB连接到树莓派 启动追踪小车 1.使用远程桌面或HDMI视频输出连接到树莓派 2.打开终端，输入cd ~/Desktop/learn-ai/codes/chapter4/part3_AutoTrack/AutoTrack 3.输入python tracker.py 4.将待识别的物体（人脸或猫）在车前移动，观察车的追踪行为 活动2：训练新的分类器 通过收集大量样本图片，可以训练自定义的分类器，可以识别任意的物体。 1.环境准备 在Windows桌面上执行： 新建一个文件夹，重命名为待检测的物体名称（英文），比如检测移动电源，就命名为yidongdianyuan 进入文件夹，再新建两个文件夹，分别命名为p和n，p代表positive（正样本），n代表negative（负样本） 获取分类器图形化训练软件，下载安装。 获取图片批量处理软件,解压即可，主程序为MtPcl.exe 获取示例数据集 2.收集负样本 训练样本包括正样本和负样本。正样本，通俗点说，就是图片中只有你需要的目标。而负样本的图片只要其中不含有目标就可以了。但需要说明的是，负样本也并非随便选取的。 例如，需要检测的目标是汽车，那么正样本就应该是仅仅含有汽车的图片，而负样本显然不能是一些包含天空的，海洋的，风景的图片。因为最终训练分类器的目的是检测汽车，而汽车应该出现在马路上。也就是说，分类器最终检测的图片应该是那些包含马路，交通标志，建筑物，广告牌，汽车，摩托车，三轮车，行人，自行车等在内的图片。很明显，这里的负样本应该是包含摩托车、三轮车、自行车、行人、路面、灌木丛、花草、交通标志、广告牌等。 Adaboost方法是机器学习中的一个经典算法，而机器学习算法的前提条件是，测试样本和训练样本独立同分布。所谓的独立同分布，可以简单理解为：训练样本要和最终的应用场合非常接近或者一致。否则，基于机器学习的算法并不能保证算法的有效性。此外，足够的训练样本（至少得几千张正样本、几千张负样本）也是保证训练算法有效性的一个前提条件。 使用网络浏览器或各种方法，收集各种图片，但是不能包含待检测的物体（移动电源）。保存在n文件夹中。数量为数十个为宜。 3.收集正样本 正样本就是想要识别出来的物体。尽可能排除无关物体的干扰（图片中无其他物体） 使用手机，拍摄待识别的物体，并将其存储在p文件夹。数量在10个以上为宜。 4.图片预处理 这一步骤调整正负样本的图片分辨率。 打开MtPcl.exe，选择添加文件夹，选择p文件夹 选择右侧修改尺寸，高度设置为480，勾选保持原图比例。然后选择下面的覆盖原图。点击保存。 点击清空，并对n文件夹执行相同的操作 5.训练分类器 打开Cascade-Trainer-GUI 点击Browse，选择包含n和p的文件夹 路径中不能包含中文 单击Common选项卡，调整第一项Number of Stages，选择10获得更快的训练速度，如果效果不明显可以逐渐增大，但是训练速度会显著增加。 修改宽度和高度为20，30。使宽高比和待处理的文件相同。 点击Start开始训练 训练成功后，在原文件夹中会增加一个classifier文件夹，里面的cascade.xml就是训练成功的级联分类器。 6.测试 选择Test选项卡，点击右上角Browse，选择上一步的cascade.xml 输入设置，选择Single Image，测试图片可以是包含多个目标物体的图片或截图 选择输出方式为Result Image in a Folder，并指定路径 点击Start，最小检测阈值输入10，10；最大检测阈值输入800，800（可以不断调整以取得最好的效果） 检测效果 活动3：应用新的分类器 将cascade.xml通过U盘拷贝到树莓派的路径下 打开终端，执行： cd ~/Desktop/learn-ai/codes/chapter4/part3_AutoTrack/AutoTrack python tracker_my_object.py 大白将会跟随训练的物体进行移动。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter5/第5章简介.html":{"url":"content/chapter5/第5章简介.html","title":"第5章 深度学习","keywords":"","body":"第5章 深度学习—无人驾驶小车老白 本章主题：深度学习、无人驾驶 这部分基于树莓派以及一些开源软件构建。树莓派从摄像头模块获取输入，然后通过无线方式发送获得的图像数据到电脑，电脑通过之前训练好的神经网络对输入的图像数据预测小车接下来的动作，然后发送这些预测动作的控制指令到树莓派控制小车的程序中。小车根据这些获得的指令实现自动驾驶。 现有的Caffe、TensorFlow等工具箱已经很好地实现CNN模型，但这些工具箱需要的硬件资源比较多，不利于初学者实践和理解。本章使用NumPy来构建卷积神经网络（Convolutional Neural Network,CNN）模型，通过对驾驶数据的采集和训练，实现无人驾驶。 本章重点 掌握无人驾驶数据采集及训练的基本方法 会灵活地在无人驾驶系统中训练和应用分类器 涉及软硬件 树莓派、摄像头 小车套件 OpenCV © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter5/第1节 更加专业的视觉系统.html":{"url":"content/chapter5/第1节 更加专业的视觉系统.html","title":"第1节 更加专业的视觉系统","keywords":"","body":"第1节 更加专业的视觉系统 准备硬件，搭建小车。按照操作步骤进行小车的动力和视觉系统的测试。完成测试后，即可正式进入无人驾驶过程。 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->客户端: WiFi Note right of 大白\\n树莓派: HTTP协议传送摄像头数据 硬件准备 硬件清单 树莓派 树莓派电机扩展板 CSI摄像头 超声波传感器 小车套件 硬件连接 将超声波传感器连接到树莓派上 Trig——GPIO 23 Echo——GPIO 24 VCC和GND接到扩展板的Vin和GND插口 执行测试 电机测试 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer #也可以使用autojump工具快速跳转，比如想访问computer路径， #只需输入`j c`并回车即可（需要之前通过cd命令访问过） #如果执行文件报错\"Permission Denied\"，尝试在执行命令的最前面加上sudo sudo python3 drive_api.py -s 150 //-s 150作为可选的参数，来指定行驶速度。可选范围是0-256 2.打开树莓派上的网络浏览器，在地址栏输入路由器管理地址，查看树莓派的IP地址3.在浏览器地址栏输入树莓派IP:81/drive例如（192.168.123.100:81/drive） 4.在打开的界面上按键盘上的上下左右方向键来测试小车5.测试完毕后，在终端输入ctrl + c来结束当前任务 摄像头测试 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd test python3 stream_server_test.py 2.新建一个终端窗口 3.在新的终端窗口中输入以下命令，如果有正常的视频画面输出，则测试通过 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py 4.在终端输入ctrl + c来结束当前任务 超声波传感器测试 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd test python3 ultrasonic_server_test.py 2.新建一个终端窗口 3.在新的终端窗口中输入以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 ultrasonic_server_test.py 4.在终端输入ctrl + c来结束当前任务 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter5/第2节 无人驾驶数据采集、训练与测试.html":{"url":"content/chapter5/第2节 无人驾驶数据采集、训练与测试.html","title":"第2节 无人驾驶数据采集、训练与测试","keywords":"","body":"第2节 无人驾驶数据采集、训练与测试 搭建起车道，然后运行相应的收集数据的程序，按下键盘方向键控制小车行驶，每按一次方向键，程序就会记录下一帧相应的图像。让小车平均遍历自动驾驶中可能出现的各种情况，按‘q‘退出数据采集，然后再运行相应的模型训练程序训练自动驾驶神经网络。最后使用训练好的神经网络模型在跑道上进行测试。 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->客户端: WiFi Note right of 大白\\n树莓派: HTTP协议传送摄像头数据\\n神经网络收集和训练数据 硬件准备 硬件清单 纸 胶带 硬件搭建-跑道 地面颜色为纯色，与所用纸张的颜色对比度应较大 跑道的宽度稍大于车的宽度 可以把拐弯处的弯度设计得稍大一些 采集驾驶数据 1.打开终端，执行以下命令 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 collect_training_data.py 2.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py 3.开始采集 顺利执行后会出现两个窗口，上面的是摄像头的画面，下面的是操作区。 将鼠标焦点移到箭头所指的工作区上。 把小车放置在跑道上，点击键盘上下左右光标控制小车。 通过键盘控制，让小车在跑道上正确的绕行数圈（3圈左右即可） 训练结束后，确定焦点仍在工作区上，点击键盘q退出训练，程序会自动保存驾驶数据 训练驾驶数据 1.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 model_training.py 2.得到模型 模型文件在~/Desktop/learn-ai/chapter5/SelfDrivingCar/computer/saved_model/nn_model.xml 开始无人驾驶 根据训练好的神经网络模型，现在我们可以实现自动驾驶 1.打开终端 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 rc_drive_nn_only.py 2.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter5/第3节 红灯停绿灯行—识别交通信号.html":{"url":"content/chapter5/第3节 红灯停绿灯行—识别交通信号.html","title":"第3节 红灯停绿灯行—识别交通信号","keywords":"","body":"第3节 红灯停绿灯行—识别交通信号 在上一章我们采用机器学习的方法制作了级联分类器来识别物体。这一部分通过深度学习的方法来训练识别特定物体 原理图 摄像头->大白\\n树莓派: CSI/USB 大白\\n树莓派-->客户端: WiFi Note right of 大白\\n树莓派: HTTP协议传送摄像头数据\\n神经网络收集和训练数据\\n应用级联分类器处理交通信号 识别交通信号 1.打开终端 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 rc_driver.py 2.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py 本节已经使用训练好的级联分类器，可以识别STOP交通信号牌。 当识别后，小车会自动停止。 识别超声波信号 在现有的基础上，只需要再新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 ultrasonic_client.py 把障碍物放到车前，车是不是自动停止了呢？ 使用自己的分类器 通过修改rc_drive.py文件，我们也可以使用上一章中训练的级联分类器。也可以训练新的分类器，比如其他交通信号。 1.放置分类器 通过文件管理器，将上次训练的级联分类器xml文件复制到如下位置 2.编辑自动驾驶文件，引用自己的分类器 cd ~/Desktop/learn-ai/codes/chapter5/self_driving_car cd computer # cp命令复制一个新的文件，防止对原来文件改动造成错误 sudo cp rc_driver.py rc_driver_my_object.py sudo nano -c rc_driver_my_object.py 在箭头处，仿照上面的语法，尝试添加自己的分类器引用。 完成后，按Ctrl+X，然后按Y确认并回车，来退出文本编辑器。 3.新建终端，重复上一节的操作，开始无人驾驶 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd computer python3 rc_drive_my_object.py 4.新建一个终端窗口 cd ~/Desktop/learn-ai/codes/chapter5/SelfDrivingCar cd raspberryPi python3 stream_client.py © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter6/第6章简介.html":{"url":"content/chapter6/第6章简介.html","title":"第6章 物联网","keywords":"","body":"第6章 综合进阶—机器人小绿 本章主题：机器人 小绿是一个使用3D打印制作外壳，使用舵机作为动力部分，使用树莓派作为控制中枢的智能机器人。作为物联网的一个节点，实现多种物联网功能，包括网页遥控：通过自行开发的物联网平台来对它进行遥控；语音助手：可以通过自己训练的热词来进行唤醒、通过语音来控制机器人执行各种动作；控制其他设备：比如控制前几个章节的小车，读取各种传感器的数据等；人脸解锁：通过实时的人脸识别和红外线发射装置，实现人脸解锁，也可以通过Google Assistant、Siri、Alexa等远程控制；实时姿态模仿：通过单目摄像头拍摄实时画面，采用OpenPose姿态识别软件进行处理，将关节姿态数据通过蓝牙或串口传递给机器人，机器人进行实时的姿态模仿。 本章重点 了解物联网的基本概念和原理 会通过物联网和开源硬件制作较为复杂的综合机器人系统 涉及软硬件 树莓派、ESP8266、安卓手机 麦克风阵列、舵机、摄像头 3D打印机 OpenPose、OpenCV © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter6/第1节 小绿的一小步，我们的一大步.html":{"url":"content/chapter6/第1节 小绿的一小步，我们的一大步.html","title":"第1节 小绿的一小步，我们的一大步","keywords":"","body":"第1节 小绿的一小步，我们的一大步 小绿通过移动电源即可供电。接通电源后，访问小绿的ip地址，试着让小绿迈出第一步吧 原理图 小绿->手机浏览器: 1.建立局域网服务器 手机浏览器-->小绿: 2.通过WiFi访问控制界面 手机浏览器-->小绿: 3.发送请求给服务器，如“前进” 小绿->手机浏览器: 4.服务器响应请求，让小绿的动力系统执行 组装小绿 小绿的外壳是3D打印而成。将舵机固定在关节处。然后将舵机都接在主控板上就可以了。是不是很简单呢？ 小绿的3D打印源文件在learn-ai/assets/3D Models/green 小绿共需要9个舵机，每个胳膊2个共4个，每条腿2个共4个，还有1个在颈部。 按顺序将舵机用螺丝刀固定在3D打印件上，完成组装。注意将舵机的线都引向中间。 烧录程序到开发板（选做） 程序烧录过程略，程序源文件见learn-ai/codes/chapter6/part2_FirstStep/greenrobot 小绿迈出第一步 1.将小绿连接到移动电源 2.查看ip地址 使用浏览器打开路由器管理地址，查找小绿的ip地址 3.访问测试地址 在浏览器中打开小绿ip地址/test 4.正确连接舵机 逐个将舵机的线连接到基于ESP8266芯片的Wemos D1开发板扩展板上。从0到11共12个槽位都可以。按照下面的对应关系将小绿的舵机连接到正确的槽位上，并进行测试。 小绿的不同部位与槽位的对应关系如下：此面为正面 位置 槽位 位置 槽位 左手 D5 右手 D4 左脚 D9 右肩 D2 左腿 D7 右腿 D6 左肩 D3 右脚 D8 5.访问小绿ip地址 最后，终于可以让小绿迈出第一步了！ 使用blockly积木控制小绿 打开learn-ai/codes/chapter6/part2_FirstStep/robot_diy_blockly/index.html，通过积木拖拽控制小绿 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter6/第2节 “小绿，跳舞！”制作自己的语音助手.html":{"url":"content/chapter6/第2节 “小绿，跳舞！”制作自己的语音助手.html","title":"第2节 “小绿，跳舞！”制作自己的语音助手","keywords":"","body":"第2节 “小绿，跳舞！”制作自己的语音助手 通过深度学习的方式训练自己的声音模型，制作自己的语音助手，用语音来控制小绿的行动。 原理图 麦克风阵列->树莓派: GPIO 树莓派-->小绿: WiFi Note right of 树莓派: 处理麦克风语音数据\\n如“前进”、“跳舞” 树莓派-->小绿: 发送处理结果 Note right of 小绿: 动作执行 树莓派-->小白: WiFi Note right of 树莓派: 处理麦克风语音数据\\n如“左转”、“停车” 树莓派-->小白: 发送处理结果 Note right of 小白: 动作执行 树莓派-->RGB彩灯: 使用MQTT传递指令\\n“开灯”、“关灯” 硬件准备 1.连接麦克风扩展板 通过对齐GPIO将扩展板固定在树莓派上 2.连接扬声器 将扬声器通过3.5mm耳机线连接到麦克风扩展板 3.设置基于ESP8266的RGB彩灯 使用基于WS2812的RGB彩灯，ESP8266通过MQTT（一种物联网轻量级通讯协议）与HomeAssistant通信 程序烧录过程略，程序源文件见~/Desktop/learn-ai/codes/chapter6/part3_VoiceAssistant/mqttlight 接通电源，使用杜邦线将彩灯的Data接到ESP8266的D3，GND和VCC分别接到对应位置 4.通过HDMI或ssh或远程桌面连接到树莓派 参数配置 rapiro项目文件夹在~目录下 参数配置时，可以使用命令行文本编辑工具nano或vim Nano：用法是nano 文件名。退出时候按ctrl+w，需要保存按y,否则按n，然后按回车。 Vim：用法是vi 文件名。先按insert键，然后进行输入。要退出vi编辑器，按esc键，然后输入:wq，回车 1.调用参数配置~/rapiro/config.yaml # 在http://yuyin.baidu.com/注册语音识别应用，获取ak、sk和id baidu_yuyin: api_key: 'qW5HLj4Ks6DfsCV2K9If5O80' secret_key: '37riCUCmGj1lfrhaGcyu11wWqCjvZbZR' app_id: '9217941' homeassistant: url: 'http://localhost' port: '8123' password: 'welcome' # 在http://www.turingapi.com/注册机器人，获取key tuling: key: 'be4efe7298b24d0d8c9b5542dd56671a' 2.机器人网络配置~/rapiro/opiro.py #!coding:utf-8 import os import time import requests class rapiro: def __init__(self,ip): #把双引号里的地址替换为小绿的ip地址 self.ip = \"http://192.168.123.184\" self.actions = { \"停止\":'/otto-home', \"小绿前进\":'/otto-walk', \"小绿后退\":'/otto-walk-back', \"小绿挥手\":'/wave-hands', \"小绿左转\":'/otto-turn', \"小绿右转\":'/otto-turn-right', \"\"\" 适用于小白的命令 \"小白前进\":'/get?command=forward' \"小白后退\":'/get?command=backward' \"\"\" } def get(self,url): r = requests.get(self.ip+url) print(r.text) def do(self,action): method = self.actions.get(action,None) if(method): self.get(method) print(\"rapiro \" + action) def isValid(self,text): for key in self.actions.keys(): if(key in text): return key return None if __name__ == '__main__': #把双引号里的地址替换为小绿的ip地址 rap = rapiro('http://192.168.123.184') action = rap.isValid('前进') print(action) if action: rap.do(action) #rap.do(\"前进\") time.sleep(4) rap.do(\"挥手\") time.sleep(4) rap.do(\"停止\") 3.核心文件配置~/rapiro/server.py …… # 第84行 把引号里的地址替换为小绿的ip地址 rap = rapiro('http://192.168.123.184') …… 4.关键词触发优化~/rapiro/handle.py #!coding:utf-8 from rapiro import * rap = rapiro() def handle(str): # 仿照下一行的格式，补充更多的关键词，优化小绿的智力 # 如果语句命令中包含关键词，则将会识别为对应的机器人指令 cmds = [\"前进\",\"后退\",\"左转\",\"右转\",\"停止\"] for cmd in cmds: if(cmd in str): rap.do(cmd) break 5.声音设备配置~/.asoundrc # 使用`aplay -l`和`arecord -l`查看wm8960soundcard对应的card和device号码。 # 例如，如果aplay对应的card和device分别是1和0， # 则在playback.pcm处的双引号内填入`hw:1,0`， # arecord则在capture.pcm处填写。 pcm.!default { type asym playback.pcm { type plug slave.pcm \"hw:1,0\" } capture.pcm { type plug slave.pcm \"hw:1,0\" } } 6.语音助手设置~/homeassistant/configuration.yaml …… …… …… conversation: intents: # 意图类型（名称），以及对应的语法匹配规则 OpenLight: - 打开{item}灯 - 把{item}灯打开 CloseLight: - 关上{item}灯 - 关闭{item}灯 intent_script: # 意图类型（名称） OpenLight: # speech返回 speech: text: 已打开{{ item }}灯 # 执行动作 action: service: light.turn_on data_template: entity_id: > {% if item==\"教室\" %} light.classroom_light_rgb {% endif %} CloseLight: speech: text: 已关闭{{ item }}灯 action: service: light.turn_off data_template: entity_id: > {% if item==\"教室\" %} light.classroom_light_rgb {% endif %} mqtt: broker: 127.0.0.1 port: 1883 light: - platform: mqtt name: \"Classroom Light RGB\" state_topic: \"classroom/rgb1/light/status\" command_topic: \"classroom/rgb1/light/switch\" brightness_state_topic: \"classroom/rgb1/brightness/status\" brightness_command_topic: \"classroom/rgb1/brightness/set\" rgb_state_topic: \"classroom/rgb1/rgb/status\" rgb_command_topic: \"classroom/rgb1/rgb/set\" state_value_template: \"{{ value_json.state }}\" brightness_value_template: \"{{ value_json.brightness }}\" rgb_value_template: \"{{ value_json.rgb | join(',') }}\" qos: 0 payload_on: \"ON\" payload_off: \"OFF\" optimistic: false 训练自己的语音模型 语音唤醒模型的训练是基于深度神经网络的训练。采用神经网络作为特征提取器，把声波信息转化为多维特征向量输入到深度神经网络（DNN）中，进行训练，得到模型。 嘿，Siri！ OK，Google！ 小爱同学！ 小度小度！ 这些是主流的语音助手的唤醒词。小绿也有自己的唤醒词。 当我们呼唤他小绿的时候，他就会回应。这是因为已经提前训练好的识别文件green.pmbl 当然，我们可以训练自己独特的唤醒词。你想要叫他什么？叫什么都可以~只需要稍微的训练一下，得到一个识别文件就可以了。 1.登陆网址叫我的机器人什么好呢 你需要有一个GitHub账号，然后在右上角选择Login with GitHub 登陆后的界面： 2.Create Hotword 3.选择右下角的Record my voice 4.录制3个样本后，点击右下角的按钮进行模型训练 在左侧选择你的性别和年龄段，这是为了更加准确的调整模型。 然后在右侧说出唤醒词，通过调整灵敏度，逐渐调节到最优状态。然后点击Save and download 5.将下载好的模型文件放在项目文件夹 可以命名为myrobot.pmbl 启动小绿的语音助手系统 //先启动HomeAssistant sudo docker start home-assistant //启动小绿 cd ~/rapiro python server.py green.pmdl //或者使用自己训练的myrobot.pmbl //python server.py myrobot.pmbl 对着麦克风说小绿，听到提示音后，说出你的问题。 你可以说今天的天气怎么样？、讲个笑话、小绿前进/后退/跳舞、小白前进/左转/停车、把灯打开/关闭等。 试着用你的唤醒词来叫醒机器人吧 与苹果家庭或谷歌家庭融合，使用Siri和Google Assistant来控制设备 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/chapter6/第3节 使用物联网制作人脸解锁.html":{"url":"content/chapter6/第3节 使用物联网制作人脸解锁.html","title":"第3节 使用物联网制作人脸解锁","keywords":"","body":"第3节 使用物联网制作人脸解锁 原理图 摄像头-->树莓派: WiFi Note right of 树莓派: HomeAssistant处理人脸数据匹配 树莓派-->语音合成: 播放识别结果 树莓派-->红外发射器: 发送处理结果 红外发射器-->大门\\n电灯\\n空调\\n电视\\n……: 红外信号 硬件清单 树莓派 安卓手机 红外发射器 具有红外遥控器的大门/灯/空调/电视/…… 硬件准备 摄像头和扬声器 在安卓手机上下载安装IP摄像头和Kodi两个app 将安卓手机连接到教学WiFi，通过路由器查询记录手机的ip地址 打开IP摄像头app，进行设置后点击最下面的开启服务器，记录下视频服务的地址和端口 Kodi是为了通过安卓手机的扬声器远程播放声音 红外发射器 安卓手机安装智慧家app，对博联RM Pro红外发射器进行初始化设置，连接到教学WiFi，然后通过路由器查询记录ip地址和mac地址 HomeAssistant的启动 1.启动HomeAssistant sudo docker start home-assistant 启动大概需要1分钟 2.访问HomeAssistant 树莓派ip:8123，选择API密码登陆，密码welcome 配置HomeAssistant（configuration.yaml） sudo docker exec -it home-assistant env LANG=C.UTF-8 /bin/bash vi configuration.yaml # 按insert键，然后进行输入 # 退出vi编辑器先按esc键，然后输入:wq，回车 # 退出bash环境输入exit，回车 1.基础配置 group: !include groups.yaml automation: !include automations.yaml script: !include scripts.yaml scene: !include scenes.yaml # 如果希望能够从iOS或macOS中的家庭应用来管理，增加下面这一行。 homekit: …… …… …… 2.Kodi和摄像头配置 …… …… …… # 在host处填入安卓平板的ip地址 media_player: - platform: kodi host: 192.168.123.194 # android_ip_webcam: # - host: 192.168.123.194 # port: 8090 # ffmpeg: # camera: # - platform: ffmpeg # name: Camera # input: -rtsp_transport tcp -i rtsp://192.168.123.29:8554/live # camera: # - platform: rpi_camera # camera: # - platform: local_file # name: camera01 # file_path: /share/motion/lastsnap.jpg camera: - platform: mjpeg mjpeg_url: http://192.168.123.218:8080/?action=stream # mjpeg_url: http://192.168.123.59:8088/?action=snapshot 3.红外发射配置 …… …… …… # 在host和mac处填入红外发射器的ip和mac地址 switch: - platform: broadlink host: 192.168.123.107 mac: '78:0F:77:5A:26:85' timeout: 15 switches: door: friendly_name: \"大门\" command_on: 'eAY0AC8PEAAB2xAuLw8QLi8PEC4vDxEuLw8QLi8QEC4vEBEuLw8vDy8QEC4vDxEuLw8RLi8QEC4AAAAA' command_off: 'eAY0AC8PEAAB2xAuLw8QLi8PEC4vDxEuLw8QLi8QEC4vEBEuLw8vDy8QEC4vDxEuLw8RLi8QEC4AAAAA' 访问http://HomeAssistant的ip地址:8123 点击左下角的第一个服务按钮，然后选择switch.broadlink_learn_command 点击Call Service，这时博联红外发射器的前端会出现小红点。用遥控器要学习的按键对着小红点按下去，小红点消失 点击左下角的第二个状态按钮，找到类似下图的内容，将最后的一长串代码复制到配置文件的对应位置即可 4.人脸识别和tts配置 …… …… …… # 正确填写下面的参数 # 百度人脸识别注册：https://cloud.baidu.com/product/face sensor: - platform: baidu_face api_key: \"tHjWWiNXlQLFNT2SdrNPWwH3\" secret_key: \"LXHQ5kP6GYewzOqFL1umrK4mfljx3W4r\" group_list: \"['normal_group']\" camera_entity_id: \"camera.mjpeg_camera\" token: \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiI0NjBjMjFlM2NiZjY0YTliYTdjZTFjMzVhNDYzY2I2YiIsImlhdCI6MTU3ODU0NjU3OSwiZXhwIjoxODkzOTA2NTc5fQ.rUDysZx983VxFJPj4cq5gynlNa3A7HO5zd8H9FxTHAQ\" # liveness: \"NORMAL\" # name: \"ren lian shi bie\" # port: 8123 # pic_url: \"网络、本地图片地址\" scan_interval: 1 # image_processing: # - platform: baidu_face_indentify # app_id: '11478116' # api_key: 'tHjWWiNXlQLFNT2SdrNPWwH3' # secret_key: 'LXHQ5kP6GYewzOqFL1umrK4mfljx3W4r' # snapshot_filepath: '/home/pi/images/' # resize: 0 # detect_top_num: 3 # ha_url: 'http://192.168.123.201:8123' # # ha_password: 'welcome' # scan_interval: 1 # source: # - entity_id: camera.mjpeg_camera # name: faceRec # 百度TTS注册：https://cloud.baidu.com/product/speech/tts tts: - platform: baidu app_id: 9217941 api_key: qW5HLj4Ks6DfsCV2K9If5O80 secret_key: 37riCUCmGj1lfrhaGcyu11wWqCjvZbZR #person：声音（0：女，1：男，3：特殊声音，4：特殊声音，缺省0） person: 4 #speed：语速0-9（缺省5） speed: 5 #pitch：语调0-9（缺省5） pitch: 5 #volume：音量0-15（缺省5） volume: 15 5.人脸注册 将照片传到HomeAssistant目录下的uploadpics目录下 选择注册人脸服务进行注册 依照此格式填写： {\"user_info\":\"乔碧萝\",\"image\":\"/config/uploadpics/zhangcuihua.jpg\",\"uid\":\"tank\"} user_info为用户标识，识别出人脸时候系统会显示这个名称 uid用于查找删除人脸数据 image为上传照片的路径 注册成功后会弹出提示 可对注册的人脸进行颜值检测 依照此格式填写： {\"image\":\"/config/uploadpics/zhangcuihua.jpg\"} 检测成功会返回结果 6.自动化配置 automations.yaml …… …… …… # 当检测到人脸（人脸识别结果大于0），就执行tts和开关操作。 - id: baiduface alias: face_indentify trigger: - entity_id: sensor.ren_lian_shi_bie platform: state to: 'True' action: - data_template: entity_id: media_player.kodi message: > {% if states.sensor.ren_lian_shi_bie.attributes[\"user_id\"] == \"chy01\" %} 你好，陈虹宇！ {% elif states.sensor.ren_lian_shi_bie.attributes[\"user_id\"] == \"sjc\" %} 你好，宿金超！ {% endif %} service: tts.baidu_say service: switch.turn_on data: - entity_id: switch.door 执行人脸解锁 将安卓手机放置在大门边上 可以将另一个大的显示器放在边上，全屏实时显示手机拍摄的实时画面 当人靠近手机摄像头的时候，如果能够正确识别，则会播放语音问候，并执行红外线开关操作 在这个基础上，可以扩展出各种其他的应用，基本过程就是通过正确的人脸识别，触发其他物联网操作。 比如在教室门口识别到教师后，就自动执行打开投影仪、放下投影幕布，拉上窗帘等一系列上课操作。 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-22 "},"content/chapter6/第4节 物联网进阶—执行自动化操作.html":{"url":"content/chapter6/第4节 物联网进阶—执行自动化操作.html","title":"第4节 物联网进阶—执行自动化操作","keywords":"","body":"第4节 物联网进阶—执行自动化操作 https://github.com/nijisakai/TeachableMachine_with_MQTT_and_HomeAssistant © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-11-10 "},"content/chapter6/第5节 唱跳rap—小绿实时姿态模仿.html":{"url":"content/chapter6/第5节 唱跳rap—小绿实时姿态模仿.html","title":"第5节 唱跳rap—小绿实时姿态模仿","keywords":"","body":"第5节 唱跳rap—小绿实时姿态模仿 卡内基梅隆大学（Carnegie Mellon University）的研究人员开发了一个身体跟踪系统，并命名为OpenPose。该系统能实时跟踪人的肢体运动，包括手和脸部。它使用计算机视觉和机器学习技术来处理视频帧，甚至可以同时跟踪多个人的运动。 姿态检测的应用 对标准化体育动作进行建模，通过视频方式对运动员实时动作进行比对分析，可实现动作规范指标化。同时，还可以对运动员运动量进行统计分析，科学指导体育训练教学。 小绿通过OpenPose模仿人类动作 原理图 摄像头-->PC/树莓派: WiFi/USB PC/树莓派-->小绿: WiFi Note right of PC/树莓派: OpenPose处理帧画面，计算姿态角度 PC/树莓派-->小绿: 发送处理结果 Note right of 小绿: 动作执行 活动1：模仿视频文件中的人物动作 1.将小绿通电 2.在电脑上打开Anaconda Prompet， conda activate learn-ai //Windows cd C:\\learn-ai\\codes\\chapter6\\part5_OpenPose //macOS cd ~/Desktop/learn-ai/codes/chapter6/part5_OpenPose python OpenPoseVideo.py OpenPoseVideo.py核心代码： …… //这部分指定输入源为文件夹下的`sample_video.mp4` input_source = \"sample_video.mp4\" cap = cv2.VideoCapture(input_source) #cap = cv2.VideoCapture(0) hasFrame, frame = cap.read() …… //这部分将各个关节的姿态通过反三角函数转化为角度数据发送给舵机 POSE_PAIRS2 = [ { \"servo\":2,\"pair\":[2,3] ,\"trim\":0 ,\"factor\":-1 , 'angle':-1,'rangle':-1 } ,{ \"servo\":3,\"pair\": [5,6] , \"trim\": 180 ,\"factor\":-1 , 'angle':-1,'rangle':-1} ] POSE_PAIRS2.extend( [ { \"servo\":4,\"pair\":[3,4] ,\"trim\":0 ,\"factor\":-1 , 'angle':-1,'rangle':-1} ,{ \"servo\":5,\"pair\": [6,7] , \"trim\": 180 ,\"factor\":-1 , 'angle':-1,'rangle':-1} ]) for idx,item in enumerate(POSE_PAIRS2): partA = item['pair'][0] partB = item['pair'][1] # print(points[partB]) if points[partA] and points[partB]: angle = int(atan2( points[partB][0]-points[partA][0] , points[partB][1]-points[partA][1])/pi*180) print((item['servo'],angle)) # angle = limitTo(angle,10,170) print((item['servo'],angle)) item['rangle'] = angle if(item['servo'] %2 == 0 and angle > 90): angle = angle - 360 elif(item['servo'] %2 != 0 and angle 3.运行代码后将会在电脑窗口中看到实时的姿态，同时小绿也会跟随视频中的人物姿态运动。 活动2：实时姿态模仿 1.将小绿通电 2.在电脑上打开Anaconda Prompet， conda activate learn-ai //Windows cd C:\\learn-ai\\codes\\chapter6\\part5_OpenPose //macOS cd ~/Desktop/learn-ai/codes/chapter6/part5_OpenPose python OpenPoseRealtimeVideo.py 3.运行代码后将会在电脑窗口中看到连接电脑的USB摄像头的实时画面。画面中的人物姿态将会实时的传递给小绿。试试挥挥手，看看小绿模仿的怎么样 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-28 "},"content/codes/下载.html":{"url":"content/codes/下载.html","title":"项目资料下载","keywords":"","body":"资料下载 课程讲义、源代码及相关资源，请点击这里来下载 账号： 密码： Arduino恢复说明 Windows 仅限北京师范大学课程人工智能与STEM教育教学学习使用 © 北京师范大学智慧学习研究院 all right reserved，powered by Gitbook修订时间： 2020-10-26 "}}